{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCylon with Pytorch\n",
    "\n",
    "Here we use PyClon DATA API to load the data and pass it to do MNIST training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from pyclon import Table\n",
    "from pyclon.csv import csv_reader\n",
    "from pycylon.util.benchutils import benchmark_with_repitions\n",
    "from pycylon.util.data.DataManager import MiniBatcher\n",
    "from pyarrow import Table as PyArrowTable\n",
    "from pyarrow import Tensor as ArrowTensor\n",
    "import time\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor as TorchTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data\n",
    "\n",
    "## Reference\n",
    "\n",
    "Get the data from [Here](https://www.kaggle.com/oddrationale/mnist-in-csv/)\n",
    "\n",
    "## Place Data\n",
    "\n",
    "Place the data in the relative path \n",
    "\n",
    "```bash\n",
    "data/mnist/full/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train File Path : /home/vibhatha/data/mnist/full/mnist_train.csv\n",
      "Test File Path : /home/vibhatha/data/mnist/full/mnist_test.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Configurations\n",
    "'''\n",
    "'''\n",
    "## Reference\n",
    "\n",
    "Get the data from [Here](https://www.kaggle.com/oddrationale/mnist-in-csv/)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "Configurations\n",
    "'''\n",
    "\n",
    "'''\n",
    "## Place Data\n",
    "\n",
    "Place the data in the relative path\n",
    "\n",
    "Assume the data is your\n",
    "/home/<your_username>/data/mnist/full/\n",
    "'''\n",
    "\n",
    "'''\n",
    "File Configurations\n",
    "'''\n",
    "username = getpass.getuser()\n",
    "base_path: str = \"/home/{}/data/mnist\".format(username)\n",
    "train_file_name: str = \"mnist_train.csv\"\n",
    "test_file_name: str = \"mnist_test.csv\"\n",
    "train_file_path: str = os.path.join(base_path, train_file_name)\n",
    "test_file_path: str = os.path.join(base_path, test_file_name)\n",
    "delimiter: str = \",\"\n",
    "\n",
    "'''\n",
    "Timing Configurations:\n",
    "\n",
    "'''\n",
    "reps: int = 10\n",
    "time_data_loading: int = 0\n",
    "time_cntb_to_arrowtb: int = 0\n",
    "time_pyarwtb_to_numpy: int = 0\n",
    "time_numpy_to_arrowtn: int = 0\n",
    "time_numpy_to_torchtn: int = 0\n",
    "time_type: str = \"ms\"\n",
    "\n",
    "'''\n",
    "Check Data Files\n",
    "'''\n",
    "\n",
    "print(\"Train File Path : {}\".format(train_file_path))\n",
    "print(\"Test File Path : {}\".format(test_file_path))\n",
    "\n",
    "assert os.path.exists(train_file_path) == True\n",
    "assert os.path.exists(test_file_path) == True\n",
    "\n",
    "'''\n",
    "Global Vars\n",
    "'''\n",
    "\n",
    "tb_train: Table = None\n",
    "tb_test: Table = None\n",
    "tb_train_arw: PyArrowTable = None\n",
    "tb_test_arw: PyArrowTable = None\n",
    "train_npy: np.ndarray = None\n",
    "test_npy: np.ndarray = None\n",
    "train_arrow_tensor: ArrowTensor = None\n",
    "test_arrow_tensor: ArrowTensor = None\n",
    "train_torch_tensor: TorchTensor = None\n",
    "test_torch_tensor: TorchTensor = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading Average Time : 1595.735348 ms\n",
      "Twisterx Table to PyArrow Table Average Time : 90.0644588 ms\n",
      "Pyarrow Table to Numpy Average Time : 393.98261579999996 ms\n",
      "Numpy to Arrow Tensor Average Time : 0.2995937 ms\n",
      "Numpy to Torch Tensor Average Time : 1.7053149 ms\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "load To Cylon Tables\n",
    "'''\n",
    "\n",
    "\n",
    "@benchmark_with_repitions(repititions=reps, time_type=time_type)\n",
    "def load_data_to_cn_tables():\n",
    "    tb_train: Table = csv_reader.read(train_file_path, delimiter)\n",
    "    tb_test: Table = csv_reader.read(test_file_path, delimiter)\n",
    "    return tb_train, tb_test\n",
    "\n",
    "\n",
    "'''\n",
    "If some pre-processing to do, do it here...\n",
    "Join, shuffle, partition, etc\n",
    "'''\n",
    "\n",
    "\n",
    "@benchmark_with_repitions(repititions=reps, time_type=time_type)\n",
    "def convert_cn_table_to_arrow_table():\n",
    "    tb_train_arw: PyArrowTable = Table.to_arrow(tb_train)\n",
    "    tb_test_arw: PyArrowTable = Table.to_arrow(tb_test)\n",
    "    return tb_train_arw, tb_test_arw\n",
    "\n",
    "\n",
    "@benchmark_with_repitions(repititions=reps, time_type=time_type)\n",
    "def covert_arrow_table_to_numpy():\n",
    "    train_npy: np.ndarray = tb_train_arw.to_pandas().to_numpy()\n",
    "    test_npy: np.ndarray = tb_test_arw.to_pandas().to_numpy()\n",
    "    return train_npy, test_npy\n",
    "\n",
    "\n",
    "@benchmark_with_repitions(repititions=reps, time_type=time_type)\n",
    "def convert_numpy_to_arrow_tensor():\n",
    "    train_arrow_tensor = ArrowTensor.from_numpy(train_npy)\n",
    "    test_arrow_tensor = ArrowTensor.from_numpy(test_npy)\n",
    "    return train_arrow_tensor, test_arrow_tensor\n",
    "\n",
    "\n",
    "@benchmark_with_repitions(repititions=reps, time_type=time_type)\n",
    "def convert_numpy_to_torch_tensor():\n",
    "    train_torch_tensor: TorchTensor = torch.from_numpy(train_npy)\n",
    "    test_torch_tensor: TorchTensor = torch.from_numpy(test_npy)\n",
    "    return train_torch_tensor, test_torch_tensor\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "time_data_loading, (tb_train, tb_test) = load_data_to_cn_tables()\n",
    "time_cntb_to_arrowtb, (tb_train_arw, tb_test_arw) = convert_cn_table_to_arrow_table()\n",
    "time_pyarwtb_to_numpy, (train_npy, test_npy) = covert_arrow_table_to_numpy()\n",
    "time_numpy_to_arrowtn, (train_arrow_tensor, test_arrow_tensor) = convert_numpy_to_arrow_tensor()\n",
    "time_numpy_to_torchtn, (train_torch_tensor, test_torch_tensor) = convert_numpy_to_torch_tensor()\n",
    "\n",
    "print(\"Data Loading Average Time : {} {}\".format(time_data_loading, time_type))\n",
    "print(\"Cylon Table to PyArrow Table Average Time : {} {}\".format(time_cntb_to_arrowtb, time_type))\n",
    "print(\"Pyarrow Table to Numpy Average Time : {} {}\".format(time_pyarwtb_to_numpy, time_type))\n",
    "print(\"Numpy to Arrow Tensor Average Time : {} {}\".format(time_numpy_to_arrowtn, time_type))\n",
    "print(\"Numpy to Torch Tensor Average Time : {} {}\".format(time_numpy_to_torchtn, time_type))\n",
    "\n",
    "print(\"===========================================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "\n",
    "'''\n",
    "Splitting Image Data and Target\n",
    "'''\n",
    "\n",
    "train_data = train_npy[:, 1:785]\n",
    "train_target = train_npy[:, 0]\n",
    "train_target = np.reshape(train_target, (train_target.shape[0], 1))\n",
    "\n",
    "test_data = test_npy[:, 1:785]\n",
    "test_target = test_npy[:, 0]\n",
    "test_target = np.reshape(test_target, (test_target.shape[0], 1))\n",
    "\n",
    "'''\n",
    "Generating Minibatches\n",
    "'''\n",
    "\n",
    "train_data = MiniBatcher.generate_minibatches(data=train_data, minibatch_size=100)\n",
    "train_target = MiniBatcher.generate_minibatches(data=train_target, minibatch_size=100)\n",
    "\n",
    "test_data = MiniBatcher.generate_minibatches(data=test_data, minibatch_size=100)\n",
    "test_target = MiniBatcher.generate_minibatches(data=test_target, minibatch_size=100)\n",
    "\n",
    "'''\n",
    "Data reshaping to match the network config (using original image size)\n",
    "'''\n",
    "\n",
    "train_data = np.reshape(train_data, (train_data.shape[0], train_data.shape[1], img_size, img_size))\n",
    "train_target = np.reshape(train_target, (train_target.shape[0], train_target.shape[1]))\n",
    "\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], img_size, img_size))\n",
    "test_target = np.reshape(test_target, (test_target.shape[0], test_target.shape[1]))\n",
    "\n",
    "'''\n",
    "Convert Data from Numpy to Torch.Tensor\n",
    "'''\n",
    "\n",
    "train_data = torch.from_numpy(train_data)\n",
    "train_target = torch.from_numpy(train_target)\n",
    "\n",
    "test_data = torch.from_numpy(test_data)\n",
    "test_target = torch.from_numpy(test_target)\n",
    "\n",
    "#########################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sequential Training Algorithm\n",
    "'''\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(file_path=None, stat=\"\"):\n",
    "    \"\"\"\n",
    "    saving the program timing stats\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    fp = open(file_path, mode=\"a+\")\n",
    "    fp.write(stat + \"\\n\")\n",
    "    fp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://www.mikulskibartosz.name/how-to-display-a-progress-bar-in-jupyter-notebook/\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress: int=1, message:str=''):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"[{0}] Progress: [{1}] {2:.1f}%\".format(message, \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch(fn,\n",
    "           train_data=None, train_target=None,\n",
    "           test_data=None, test_target=None,\n",
    "           do_log=False):\n",
    "    \"\"\" Initialize the distributed environment.\n",
    "    :param fn: training function\n",
    "    :param backend: Pytorch Backend\n",
    "    :param train_data: training data\n",
    "    :param train_target: training targets\n",
    "    :param test_data: testing data\n",
    "    :param test_target: testing targets\n",
    "    :param do_log: boolean status to log\n",
    "    \"\"\"\n",
    "    # dist.init_process_group(backend, rank=rank, world_size=size)\n",
    "    # Setting CUDA FOR TRAINING\n",
    "    # use_cuda = torch.cuda.is_available()\n",
    "    # device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    total_communication_time = 0\n",
    "\n",
    "    local_training_time = time.time()\n",
    "\n",
    "    model = fn(train_data=train_data, train_target=train_target, do_log=False)\n",
    "\n",
    "    local_training_time = time.time() - local_training_time\n",
    "\n",
    "    local_testing_time = time.time()\n",
    "\n",
    "    predict(model=model, device=device, test_data=test_data, test_target=test_target, do_log=do_log)\n",
    "\n",
    "    local_testing_time = time.time() - local_testing_time\n",
    "    print(\"Total Training Time : {}\".format(local_training_time))\n",
    "    print(\"Total Testing Time : {}\".format(local_testing_time))\n",
    "    save_log(\"/tmp/torch_mnist_seq_stats.csv\",\n",
    "             stat=\"{},{},{},{}\".format(1, local_training_time, total_communication_time, local_testing_time))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, device, test_data=None, test_target=None, do_log=False):\n",
    "    \"\"\"\n",
    "    testing the trained model\n",
    "    :rtype: None return\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in zip(test_data, test_target):\n",
    "            # total_samples = total_samples + 1\n",
    "            count = count + 1\n",
    "            val1 = len(data)\n",
    "            val2 = len(test_data)\n",
    "            total_samples = (val1 * val2)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = np.reshape(data, (data.shape[0], 1, data.shape[1], data.shape[2])) / 128.0\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target.long(), reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            if (do_log):\n",
    "                print(count, len(data), len(test_data), data.shape, output.shape, correct, total_samples)\n",
    "\n",
    "    test_loss /= (total_samples)\n",
    "    local_accuracy = 100.0 * correct / total_samples\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, total_samples,\n",
    "        local_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data=None, train_target=None, do_log=False):\n",
    "    \"\"\"\n",
    "    training the MNIST model\n",
    "    :param int world_rank: current processor rank (MPI rank)\n",
    "    :param int world_size: number of processes (MPI world size)\n",
    "    :param tensor train_data: training data as pytorch tensor\n",
    "    :param tensor train_target: training target as pytorch tensor\n",
    "    :param boolean do_log: set logging\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    torch.manual_seed(1234)\n",
    "    model = Net()\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=0.01, momentum=0.5)\n",
    "\n",
    "    num_batches = train_data.shape[1]\n",
    "\n",
    "    if (do_log):\n",
    "        print(\"Started Training\")\n",
    "    total_data = len(train_data)\n",
    "    epochs = 5\n",
    "    total_steps = epochs * total_data\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        count = 0\n",
    "        for data, target in zip(train_data, train_target):\n",
    "            data = np.reshape(data, (data.shape[0], 1, data.shape[1], data.shape[2])) / 128.0\n",
    "            count = count + 1\n",
    "            result = '{0:.4g}'.format((count / float(total_steps)) * 100.0)\n",
    "            # for terminal\n",
    "            #print(\"Progress {}% \\r\".format(result), end='\\r')\n",
    "            # for jupyter notebooks\n",
    "            update_progress(progress=count / total_data, message='Epoch ' + str(epoch))\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            # this comes with data loading mechanism use target or target.long()\n",
    "            # depending on network specifications.\n",
    "            target = target.long()\n",
    "            loss = F.nll_loss(output, target)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch ', epoch, ': ', epoch_loss / num_batches)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Progress: [####################] 100.0%\n",
      "Epoch  4 :  0.9679643042944371\n",
      "\n",
      "Test set: Average loss: 0.0840, Accuracy: 9740/10000 (97%)\n",
      "\n",
      "Total Training Time : 269.24440574645996\n",
      "Total Testing Time : 2.2946836948394775\n"
     ]
    }
   ],
   "source": [
    "do_log = False\n",
    "\n",
    "# initialize training\n",
    "launch(fn=train,\n",
    "       train_data=train_data,\n",
    "       train_target=train_target,\n",
    "       test_data=test_data,\n",
    "       test_target=test_target,\n",
    "       do_log=do_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}