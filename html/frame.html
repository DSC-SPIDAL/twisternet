<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>frame API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>frame</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">##
# Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##


from __future__ import annotations
from typing import Hashable, List, Dict, Optional, Sequence, Union
from copy import copy
from collections.abc import Iterable
import pycylon as cn
import numpy as np
import pandas as pd
import pyarrow as pa
from pycylon import Series
from pycylon.index import RangeIndex, CategoricalIndex
from pycylon.io import CSVWriteOptions
from pycylon.io import CSVReadOptions
import pycylon.data as pcd

from pycylon import CylonContext

DEVICE_CPU = &#34;cpu&#34;


# Data loading Functions
def read_csv(filepath: str, use_threads=True,  names=None, sep=&#34;,&#34;, block_size: int = 1 &lt;&lt; 20, skiprows=0, ignore_emptylines=True, na_values=None):
    &#34;&#34;&#34;
    Read a comma-separated values (csv) file into DataFrame.

    Parameters
    ----------
    filepath : A valid str path to the file
    sep : str, default ,
        Delimiter to use. 
    names : array-like, optional
        List of column names to use. If the file contains a header row,
        then you should explicitly pass ``header=0`` to override the column names.
        Duplicates in this list are not allowed.
    block_size : int, default 1MB
        Arrow block size to be used when chunking the final Cylon table
    skiprows : int, optional, default 0
        Line numbers to skip (0-indexed) or number of lines to skip (int)
        at the start of the file.
    ignore_emptylines: bool, default True
        Whether to keep or ignore empty lines in the csv file
    na_values : list-like, optional
        Additional strings to recognize as NA/NaN.
    &#34;&#34;&#34;
    read_config = CSVReadOptions().use_threads(
        use_threads).block_size(block_size).with_delimiter(sep).skip_rows(skiprows)

    if ignore_emptylines:
        read_config.ignore_emptylines()

    if na_values is not None:
        read_config.na_values(na_values)

    if names is not None:
        read_config.use_cols(names)

    table = pcd.csv.read_csv(CylonContext(
        config=None, distributed=False), filepath, read_config)

    return DataFrame(table)


class CylonEnv(object):

    def __init__(self, config=None, distributed=True) -&gt; None:
        self._context = CylonContext(config, distributed)
        self._distributed = distributed
        self._finalized = False

    @property
    def context(self) -&gt; CylonContext:
        return self._context

    @property
    def rank(self) -&gt; int:
        return self._context.get_rank()

    @property
    def world_size(self) -&gt; int:
        return self._context.get_world_size()

    @property
    def is_distributed(self) -&gt; bool:
        return self._distributed

    def finalize(self):
        if not self._finalized:
            self._finalized = True
            self._context.finalize()

    def barrier(self):
        self._context.barrier()

    def __del__(self):
        &#34;&#34;&#34;
        On destruction of the application, the environment will be automatically finalized
        &#34;&#34;&#34;
        self.finalize()


class GroupByDataFrame(object):
    def __init__(self, df: DataFrame, by=None) -&gt; None:
        super().__init__()
        self.df = df
        self.by = by
        self.by_diff = set(df.columns) - set(by)

    def __do_groupby(self, op_dict) -&gt; DataFrame:
        return DataFrame(self.df.to_table().groupby(self.by, op_dict))

    def __apply_on_remaining_columns(self, op: str) -&gt; DataFrame:
        op_dict = {}
        for c in self.by_diff:
            op_dict[c] = op
        return self.__do_groupby(op_dict)

    def min(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply min operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;min&#34;)

    def max(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply max operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;max&#34;)

    def sum(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply sum operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;sum&#34;)

    def count(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply count operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;count&#34;)

    def mean(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply mean operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;mean&#34;)

    def std(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply standard deviation operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;std&#34;)

    def agg(self, dic: dict) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply different aggregation operations on each remainign column
        which has not been used for grouping

        Args:
            dic : A dictionary specifying aggregation operation for each column
        &#34;&#34;&#34;
        return self.__do_groupby(dic)


class DataFrame(object):

    def __init__(self, data=None, index=None, columns=None, copy=False):
        &#34;&#34;&#34;
        Construct a Cylon DataFrame

        Parameters
        ----------
        data : Python list, ndarray, Pandas Dataframe, Arrow Table or a Cylon Table
        columns : Optional set of column names
        copy : By default, Cylon will try not to copy data when constructing a datframe from ndarray, 
            Pandas Dataframe, Arrow Table or a Cylon Table. This behavior can be forcefully overridden by setting this flag.

        Returns
        -------
        DataFrame
        &#34;&#34;&#34;
        self._index = None
        self._columns = []

        self._table = self._initialize_dataframe(
            data=data, index=index, columns=columns, copy=copy)

        # temp workaround for indexing requirement of dataframe api
        self._index_columns = []

        self._device = DEVICE_CPU

    def to_cpu(self):
        &#34;&#34;&#34;
        Move the dataframe from it&#39;s current device to random access memory
        &#34;&#34;&#34;
        pass

    def to_device(self, device=None):
        &#34;&#34;&#34;
        Move the dataframe from it&#39;s current device to the specified device
        &#34;&#34;&#34;
        pass

    def is_cpu(self):
        return self._device == DEVICE_CPU

    def is_device(self, device):
        return self._device == device

    def _change_context(self, env: CylonEnv):
        &#34;&#34;&#34;
        This is a temporary function to make the DataFrame backed by a Cylon Table with a different context.
        This should be removed once C++ support Tables which are independent from Contexts
        &#34;&#34;&#34;
        self._table = self._initialize_dataframe(
            data=self._table.to_arrow(), index=self._index, columns=self._columns, copy=False, context=env.context)
        return self

    def _initialize_dataframe(self, data=None, index=None, columns=None, copy=False, context=CylonContext(config=None, distributed=False)):
        rows = 0
        cols = 0
        self._table = None
        if copy:
            data = self._copy(data)

        if isinstance(data, List):
            # load from List or np.ndarray
            if isinstance(data[0], List):
                rows = len(data[0])
                cols = len(data)
                if not columns:
                    columns = self._initialize_columns(
                        cols=cols, columns=columns)
                return cn.Table.from_list(context, columns, data)
            elif isinstance(data[0], np.ndarray):
                # load from List of np.ndarray
                cols = len(data)
                rows = data[0].shape[0]
                if not columns:
                    columns = self._initialize_columns(
                        cols=cols, columns=columns)
                return cn.Table.from_numpy(context, columns, data)
            else:
                # load from List
                rows = len(data)
                cols = 1
                if not columns:
                    columns = self._initialize_columns(
                        cols=cols, columns=columns)
                return cn.Table.from_list(context, columns, data)
        elif isinstance(data, pd.DataFrame):
            # load from pd.DataFrame
            rows, cols = data.shape
            if columns:
                from pycylon.util.pandas.utils import rename_with_new_column_names
                columns = rename_with_new_column_names(data, columns)
                data = data.rename(columns=columns, inplace=True)
            return cn.Table.from_pandas(context, data)
        elif isinstance(data, dict):
            # load from dictionary
            _, data_items = list(data.items())[0]
            rows = len(data_items)
            return cn.Table.from_pydict(context, data)
        elif isinstance(data, pa.Table):
            # load from pa.Table
            rows, cols = data.shape
            return cn.Table.from_arrow(context, data)
        elif isinstance(data, Series):
            # load from PyCylon Series
            # cols, rows = data.shape
            # columns = self._initialize_columns(cols=cols, columns=columns)
            return NotImplemented
        elif isinstance(data, cn.Table):
            if columns:
                from pycylon.util.pandas.utils import rename_with_new_column_names
                columns = rename_with_new_column_names(data, columns)
                data = data.rename(columns=columns)
            return data
        else:
            raise ValueError(f&#34;Invalid data structure, {type(data)}&#34;)

    def _initialize_dtype(self, dtype):
        raise NotImplemented(
            &#34;Data type forcing is not implemented, only support inferring types&#34;)

    def _initialize_columns(self, cols, columns):
        if columns is None:
            return [str(i) for i in range(cols)]
        else:
            if isinstance(columns, Iterable):
                if len(columns) != cols:
                    raise ValueError(f&#34;data columns count: {cols} and column names count &#34;
                                     f&#34;{len(columns)} not equal&#34;)
                else:
                    return columns

    def _initialize_index(self, index, rows):
        if index is None:
            self._index = RangeIndex(start=0, stop=rows)
        else:
            if isinstance(index, CategoricalIndex):
                # check the validity of provided Index
                pass
            elif isinstance(index, RangeIndex):
                # check the validity of provided Index
                pass

    def _copy(self, obj):
        return copy(obj)

    @property
    def shape(self):
        return self._table.shape

    @property
    def columns(self) -&gt; List[str]:
        return self._table.column_names

    def to_pandas(self) -&gt; pd.DataFrame:
        return self._table.to_pandas()

    def to_numpy(self, order: str = &#39;F&#39;, zero_copy_only: bool = True, writable: bool = False) -&gt; \
            np.ndarray:
        return self._table.to_numpy(order=order, zero_copy_only=zero_copy_only,
                                    writable=writable)

    def to_arrow(self) -&gt; pa.Table:
        return self._table.to_arrow()

    def to_dict(self) -&gt; Dict:
        return self._table.to_pydict()

    def to_table(self) -&gt; cn.Table:
        return self._table

    def to_csv(self, path, csv_write_options: CSVWriteOptions):
        self._table.to_csv(path=path, csv_write_options=csv_write_options)

    def __getitem__(self, item) -&gt; DataFrame:
        &#34;&#34;&#34;
            This method allows to retrieve a subset of a DataFrane by means of a key
            Args:
                key: a key can be the following
                     1. slice i.e dataframe[1:5], rows 1:5
                     2. int i.e a row index
                     3. str i.e extract the data column-wise by column-name
                     4. List of columns are extracted
                     5. PyCylon DataFrame
            Returns: PyCylon DataFrame

            Examples
            --------
            &gt;&gt;&gt; data = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]
            &gt;&gt;&gt; df: DataFrame = DataFrame(data)

            &gt;&gt;&gt; df1 = df[1:3]
                col-1  col-2  col-3
                    0      2      6     10
                    1      3      7     11
                    2      4      8     12

            &gt;&gt;&gt; df2 = df[&#39;col-1&#39;]
                   col-1
                0      1
                1      2
                2      3
                3      4

            &gt;&gt;&gt; df3 = df[[&#39;col-1&#39;, &#39;col-2&#39;]]
                   col-1  col-2
                0      1      5
                1      2      6
                2      3      7
                3      4      8

            &gt;&gt;&gt; df4 = df &gt; 3
                     col-1  col-2  col-3
                0    False   True   True
                1    False   True   True
                2    False   True   True
                3     True   True   True

            &gt;&gt;&gt; df5 = df[tb4]
                    col-1  col-2  col-3
                0    NaN      5      9
                1    NaN      6     10
                2    NaN      7     11
                3    4.0      8     12

            &gt;&gt;&gt; df8 = df[&#39;col-1&#39;] &gt; 2
                   col-1  col-2  col-3
                0      3      7     11
                1      4      8     12

        &#34;&#34;&#34;
        if isinstance(item, slice) or isinstance(item, int) or isinstance(item, str) or \
                isinstance(item, List):
            return DataFrame(self._table.__getitem__(item))
        elif isinstance(item, DataFrame):
            return DataFrame(self._table.__getitem__(item.to_table()))

    def __setitem__(self, key, value):
        &#39;&#39;&#39;
            Sets values for a existing dataframe by means of a column
            Args:
                key: (str) column-name
                value: (DataFrame) data as a single column table

            Returns: PyCylon DataFrame

            Examples
            --------
            &gt;&gt;&gt; df
                   col-1  col-2  col-3
                0      1      5      9
                1      2      6     10
                2      3      7     11
                3      4      8     12


            &gt;&gt;&gt; df[&#39;col-3&#39;] = DataFrame([[90, 100, 110, 120]])
                   col-1  col-2  col-3
                0      1      5     90
                1      2      6    100
                2      3      7    110
                3      4      8    120

            &gt;&gt;&gt; df[&#39;col-4&#39;] = DataFrame([190, 1100, 1110, 1120]])
                    col-1  col-2  col-3  col-4
                0      1      5     90    190
                1      2      6    100   1100
                2      3      7    110   1110
                3      4      8    120   1120
        &#39;&#39;&#39;

        if isinstance(key, str) and isinstance(value, DataFrame):
            self._table.__setitem__(key, value.to_table())
        else:
            raise ValueError(f&#34;Not Implemented __setitem__ option for key Type {type(key)} and &#34;
                             f&#34;value type {type(value)}&#34;)

    def __repr__(self):
        return self._table.__repr__()

    def __eq__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
                Equal operator for DataFrame
                Args:
                    other: can be a numeric scalar or a DataFrame

                Returns: PyCylon DataFrame

                Examples
                --------

                &gt;&gt;&gt; df
                       col-1  col-2  col-3
                    0      1      5      9
                    1      2      6     10
                    2      3      7     11
                    3      4      8     12

                &gt;&gt;&gt; df[&#39;col-1&#39;] == 2
                       col-1
                    0  False
                    1   True
                    2  False
                    3  False

                &gt;&gt;&gt; df == 2
                       col-1  col-2  col-3
                    0  False  False  False
                    1   True  False  False
                    2  False  False  False
                    3  False  False  False

                &#39;&#39;&#39;
        return DataFrame(self._table.__eq__(other))

    def __ne__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Not equal operator for DataFrame
        Args:
            other: can be a numeric scalar or DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df3 = df[&#39;col-1&#39;] != 2
               col-1
            0   True
            1  False
            2   True
            3   True

        &gt;&gt;&gt; df4 = df != 2
               col-1  col-2  col-3
            0   True   True   True
            1  False   True   True
            2   True   True   True
            3   True   True   True
        &#39;&#39;&#39;

        return DataFrame(self._table.__ne__(other))

    def __lt__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Lesser than operator for DataFrame
        Args:
            other: can be a numeric scalar or DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; tb
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; tb3 = tb[&#39;col-1&#39;] &lt; 2
               col-1
            0   True
            1  False
            2  False
            3  False

        &gt;&gt;&gt; tb4 = tb &lt; 2
               col-1  col-2  col-3
            0   True  False  False
            1  False  False  False
            2  False  False  False
            3  False  False  False
        &#39;&#39;&#39;

        return DataFrame(self._table.__lt__(other))

    def __gt__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Greater than operator for DataFrame
        Args:
            other: can be a numeric scalar or DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df3 = df[&#39;col-1&#39;] &gt; 2
                col-1
            0  False
            1  False
            2   True
            3   True

        &gt;&gt;&gt; df4 = df &gt; 2
               col-1  col-2  col-3
            0  False   True   True
            1  False   True   True
            2   True   True   True
            3   True   True   True
        &#39;&#39;&#39;

        return DataFrame(self._table.__gt__(other))

    def __le__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Lesser than or equal operator for DataFrame
        Args:
            other: can be a numeric scalar or DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; tb
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df3 = df[&#39;col-1&#39;] &lt;= 2
                col-1
            0   True
            1   True
            2  False
            3  False

        &gt;&gt;&gt; df4 = df &lt;= 2
               col-1  col-2  col-3
            0   True  False  False
            1   True  False  False
            2  False  False  False
            3  False  False  False
        &#39;&#39;&#39;
        return DataFrame(self._table.__le__(other))

    def __ge__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Greater than or equal operator for DataFrame
        Args:
            other: can be a numeric scalar or DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12


        &gt;&gt;&gt; df3 = df[&#39;col-1&#39;] &gt;= 2
               col-1
            0  False
            1   True
            2   True
            3   True

        &gt;&gt;&gt; df4 = df &gt;= 2
               col-1  col-2  col-3
            0  False   True   True
            1   True   True   True
            2   True   True   True
            3   True   True   True
        &#39;&#39;&#39;

        return DataFrame(self._table.__ge__(other))

    def __or__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Or operator for DataFrame
        Args:
            other: PyCylon DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df1
               col-1  col-2
            0  False   True
            1   True   True
            2  False  False
            3   True  False

        &gt;&gt;&gt; df2
                col-1  col-2
            0   True  False
            1   True   True
            2  False  False
            3  False   True

        &gt;&gt;&gt; df_or = df1 | df2
               col-1  col-2
            0   True   True
            1   True   True
            2  False  False
            3   True   True
        &#39;&#39;&#39;

        return DataFrame(self._table.__or__(other.to_table()))

    def __and__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        And operator for DataFrame
        Args:
            other: PyCylon DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df1
               col-1  col-2
            0  False   True
            1   True   True
            2  False  False
            3   True  False

        &gt;&gt;&gt; df2
                col-1  col-2
            0   True  False
            1   True   True
            2  False  False
            3  False   True

        &gt;&gt;&gt; df_or = df1 &amp; df2
               col-1  col-2
            0  False  False
            1   True   True
            2  False  False
            3  False  False
        &#39;&#39;&#39;

        return DataFrame(self._table.__and__(other.to_table()))

    def __invert__(self) -&gt; DataFrame:
        &#39;&#39;&#39;
         Invert operator for DataFrame

         Returns: PyCylon DataFrame

         Examples
         --------
         &gt;&gt;&gt; df
                col-1  col-2
            0  False   True
            1   True   True
            2  False  False
            3   True  False

        &gt;&gt;&gt; ~df
               col-1  col-2
            0   True  False
            1  False  False
            2   True   True
            3  False   True
         &#39;&#39;&#39;

        return DataFrame(self._table.__invert__())

    def __neg__(self) -&gt; DataFrame:
        &#39;&#39;&#39;
         Negation operator for DataFrame

         Returns: PyCylon DataFrame

         Examples
         --------
         &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

         &gt;&gt;&gt; -df
               col-1  col-2  col-3
            0     -1     -5     -9
            1     -2     -6    -10
            2     -3     -7    -11
            3     -4     -8    -12
         &#39;&#39;&#39;

        return DataFrame(self._table.__neg__())

    def __add__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
         Add operator for DataFrame
         Args:
             other: scalar numeric

         Returns: PyCylon DataFrame

         Examples
         --------
        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df + 2
               col-1  col-2  col-3
            0      3      7     11
            1      4      8     12
            2      5      9     13
            3      6     10     14
         &#39;&#39;&#39;
        return DataFrame(self._table.__add__(other))

    def __sub__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
         Subtract operator for DataFrame
         Args:
             other: scalar numeric

         Returns: PyCylon DataFrame

         Examples
         --------
        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df - 2
               col-1  col-2  col-3
            0     -1      3      7
            1      0      4      8
            2      1      5      9
            3      2      6     10
         &#39;&#39;&#39;
        return DataFrame(self._table.__sub__(other))

    def __mul__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
         Multiply operator for DataFrame
         Args:
             other: scalar numeric

         Returns: PyCylon DataFrame

         Examples
         --------
        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df * 2
               col-1  col-2  col-3
            0      2     10     18
            1      4     12     20
            2      6     14     22
            3      8     16     24
         &#39;&#39;&#39;

        return DataFrame(self._table.__mul__(other))

    def __truediv__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
         Element-wise division operator for DataFrame
         Args:
             other: scalar numeric

         Returns: PyCylon DataFrame

         Examples
         --------
        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df / 2
               col-1  col-2  col-3
            0    0.5    2.5    4.5
            1    1.0    3.0    5.0
            2    1.5    3.5    5.5
            3    2.0    4.0    6.0
         &#39;&#39;&#39;

        return DataFrame(self._table.__truediv__(other))

    def drop(self, column_names: List[str]) -&gt; DataFrame:
        &#39;&#39;&#39;
        drop a column or list of columns from a DataFrame
        Args:
            column_names: List[str]

        Returns: PyCylon DataFrame

        Examples
        --------

        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df.drop([&#39;col-1&#39;])
               col-2  col-3
            0      5      9
            1      6     10
            2      7     11
            3      8     12
        &#39;&#39;&#39;

        return DataFrame(self._table.drop(column_names))

    def fillna(self, fill_value) -&gt; DataFrame:
        &#39;&#39;&#39;
        Fill not applicable values with a given value
        Args:
            fill_value: scalar

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0    1.0    5.0    9.0
            1    NaN    6.0   10.0
            2    3.0    NaN   11.0
            3    4.0    8.0    NaN

        &gt;&gt;&gt; df.fillna(0)
               col-1  col-2  col-3
            0      1      5      9
            1      0      6     10
            2      3      0     11
            3      4      8      0
        &#39;&#39;&#39;
        # Note: Supports numeric types only
        return DataFrame(self._table.fillna(fill_value))

    def where(self, condition: DataFrame = None, other=None) -&gt; DataFrame:
        &#39;&#39;&#39;
        Experimental version of Where operation.
        Replace values where condition is False
        Args:
            condition: bool DataFrame
            other: Scalar

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df.where(df &gt; 2)
                col-1  col-2  col-3
            0    NaN      5      9
            1    NaN      6     10
            2    3.0      7     11
            3    4.0      8     12

        &gt;&gt;&gt; df.where(df &gt; 2, 10)
               col-1  col-2  col-3
            0     10      5      9
            1     10      6     10
            2      3      7     11
            3      4      8     12
        &#39;&#39;&#39;
        if condition is None:
            raise ValueError(&#34;Condition must be provided&#34;)
        return DataFrame(self._table.where(condition, other))

    def isnull(self) -&gt; DataFrame:
        &#39;&#39;&#39;
        Checks for null elements and returns a bool DataFrame
        Returns: PyCylon DataFrame

        Examples
        --------

        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0    1.0    5.0    9.0
            1    NaN    6.0   10.0
            2    3.0    NaN   11.0
            3    4.0    8.0    NaN

        &gt;&gt;&gt; df.isnull()
                col-1  col-2  col-3
            0  False  False  False
            1   True  False  False
            2  False   True  False
            3  False  False   True

        &#39;&#39;&#39;
        return DataFrame(self._table.isnull())

    def isna(self) -&gt; DataFrame:
        &#39;&#39;&#39;
        Check for not applicable values and returns a bool DataFrame
        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0    1.0    5.0    9.0
            1    NaN    6.0   10.0
            2    3.0    NaN   11.0
            3    4.0    8.0    NaN

        &gt;&gt;&gt; df.isna()
                col-1  col-2  col-3
            0  False  False  False
            1   True  False  False
            2  False   True  False
            3  False  False   True
        &#39;&#39;&#39;
        return DataFrame(self._table.isnull())

    def notnull(self) -&gt; DataFrame:
        &#39;&#39;&#39;
        Check the not null values and returns a bool DataFrame
        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0    1.0    5.0    9.0
            1    NaN    6.0   10.0
            2    3.0    NaN   11.0
            3    4.0    8.0    NaN

        &gt;&gt;&gt; df.notnull()
               col-1  col-2  col-3
            0   True   True   True
            1  False   True   True
            2   True  False   True
            3   True   True  False
        &#39;&#39;&#39;

        return ~self.isnull()

    def notna(self) -&gt; DataFrame:
        &#39;&#39;&#39;
        Checks for not NA values and returns a bool DataFrame
        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0    1.0    5.0    9.0
            1    NaN    6.0   10.0
            2    3.0    NaN   11.0
            3    4.0    8.0    NaN

        &gt;&gt;&gt; df.notna()
               col-1  col-2  col-3
            0   True   True   True
            1  False   True   True
            2   True  False   True
            3   True   True  False
        &#39;&#39;&#39;

        return ~self.isnull()

    def rename(self, column_names):
        &#39;&#39;&#39;
        Rename a DataFrame with a column name or column names
        Args:
            column_names: dictionary or full list of new column names

        Returns: None

        Examples
        --------
        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df.rename({&#39;col-1&#39;: &#39;col_1&#39;})
               col_1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df.rename([&#39;c1&#39;, &#39;c2&#39;, &#39;c3&#39;])
               c1  c2  c3
            0   1   5   9
            1   2   6  10
            2   3   7  11
            3   4   8  12
        &#39;&#39;&#39;
        self._table.rename(column_names)

    def add_prefix(self, prefix: str) -&gt; DataFrame:
        &#39;&#39;&#39;
        Adding a prefix to column names
        Args:
            prefix: str

        Returns: PyCylon DataFrame with prefix updated

        Examples
        --------

        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df.add_prefix(&#39;old_&#39;)
               old_c1  old_c2  old_c3
            0       1       5       9
            1       2       6      10
            2       3       7      11
            3       4       8      12

        &#39;&#39;&#39;

        return DataFrame(self._table.add_prefix(prefix))

    # Indexing

    def set_index(
        self, keys, drop=True, append=False, inplace=False, verify_integrity=False
    ):
        &#34;&#34;&#34;
        Set the DataFrame index using existing columns.
        Set the DataFrame index (row labels) using one or more existing
        columns or arrays (of the correct length). The index can replace the
        existing index or expand on it.
        Parameters
        ----------
        keys : label or array-like or list of labels/arrays
            This parameter can be either a single column key, a single array of
            the same length as the calling DataFrame, or a list containing an
            arbitrary combination of column keys and arrays. Here, &#34;array&#34;
            encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and
            instances of :class:`~collections.abc.Iterator`.
        drop : bool, default True
            Delete columns to be used as the new index.
        append : bool, default False
            Whether to append columns to existing index.
        inplace : bool, default False
            If True, modifies the DataFrame in place (do not create a new object).
        verify_integrity : bool, default False
            Check the new index for duplicates. Otherwise defer the check until
            necessary. Setting to False will improve the performance of this
            method.
        Returns
        -------
        DataFrame or None
            Changed row labels or None if ``inplace=True``.
        See Also
        --------
        DataFrame.reset_index : Opposite of set_index.
        DataFrame.reindex : Change to new indices or expand indices.
        DataFrame.reindex_like : Change to same indices as other DataFrame.
        Examples
        --------
        &gt;&gt;&gt; df = pd.DataFrame({&#39;month&#39;: [1, 4, 7, 10],
        ...                    &#39;year&#39;: [2012, 2014, 2013, 2014],
        ...                    &#39;sale&#39;: [55, 40, 84, 31]})
        &gt;&gt;&gt; df
           month  year  sale
        0      1  2012    55
        1      4  2014    40
        2      7  2013    84
        3     10  2014    31
        Set the index to become the &#39;month&#39; column:
        &gt;&gt;&gt; df.set_index(&#39;month&#39;)
               year  sale
        month
        1      2012    55
        4      2014    40
        7      2013    84
        10     2014    31
        Create a MultiIndex using columns &#39;year&#39; and &#39;month&#39;:
        &gt;&gt;&gt; df.set_index([&#39;year&#39;, &#39;month&#39;])
                    sale
        year  month
        2012  1     55
        2014  4     40
        2013  7     84
        2014  10    31
        Create a MultiIndex using an Index and a column:
        &gt;&gt;&gt; df.set_index([pd.Index([1, 2, 3, 4]), &#39;year&#39;])
                 month  sale
           year
        1  2012  1      55
        2  2014  4      40
        3  2013  7      84
        4  2014  10     31
        Create a MultiIndex using two Series:
        &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
        &gt;&gt;&gt; df.set_index([s, s**2])
              month  year  sale
        1 1       1  2012    55
        2 4       4  2014    40
        3 9       7  2013    84
        4 16     10  2014    31
        &#34;&#34;&#34;
        # todo this is not a final implementation
        index_keys = []
        index_keys.extend(keys)

        if append:
            for c in self._index_columns:
                if not c in index_keys:
                    index_keys.append(c)

        if inplace:
            self._index_columns = index_keys
            self._table.set_index(index_keys, drop=drop)
            return None
        else:
            new_df = DataFrame(self._table)
            new_df._table.set_index(index_keys, drop=drop)
            new_df._index_columns = index_keys
            return new_df

    def reset_index(  # type: ignore[misc]
        self,
        level: Optional[Union[Hashable, Sequence[Hashable]]] = ...,
        drop: bool = ...,
        inplace: False = ...,
        col_level: Hashable = ...,
        col_fill=...,
    ) -&gt; DataFrame:
        # todo this is not a final implementation
        self._index_columns = []
        self._table.reset_index(drop=drop)
        return self

    # Combining / joining / merging

    def join(self, other: DataFrame, on=None, how=&#39;left&#39;, lsuffix=&#39;l&#39;, rsuffix=&#39;r&#39;,
             sort=False, algorithm=&#34;sort&#34;, env: CylonEnv = None) -&gt; DataFrame:
        &#34;&#34;&#34;
        Join columns with other DataFrame either on index or on a key
        column. Efficiently Join multiple DataFrame objects by index at once by
        passing a list.

        Parameters
        ----------
        other : DataFrame, Series with name field set, or list of DataFrame
            Index should be similar to one of the columns in this one. If a
            Series is passed, its name attribute must be set, and that will be
            used as the column name in the resulting joined DataFrame
        on : column name, tuple/list of column names, or array-like
            Column(s) in the caller to join on the index in other,
            otherwise joins index-on-index. If multiples
            columns given, the passed DataFrame must have a MultiIndex. Can
            pass an array as the join key if not already contained in the
            calling DataFrame. Like an Excel VLOOKUP operation
        how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;}, default: &#39;left&#39;
            How to handle the operation of the two objects.
            * left: use calling frame&#39;s index (or column if on is specified)
            * right: use other frame&#39;s index
            * outer: form union of calling frame&#39;s index (or column if on is
              specified) with other frame&#39;s index, and sort it
              lexicographically
            * inner: form intersection of calling frame&#39;s index (or column if
              on is specified) with other frame&#39;s index, preserving the order
              of the calling&#39;s one
        lsuffix : string
            Suffix to use from left frame&#39;s overlapping columns
        rsuffix : string
            Suffix to use from right frame&#39;s overlapping columns
        sort : boolean, default False
            Order result DataFrame lexicographically by the join key. If False,
            the order of the join key depends on the join type (how keyword)
        algorithm: {&#39;sort&#39;, &#39;hash&#39;}, default: &#39;sort&#39;
            The algorithm that should be used to perform the join between two tables.
        Notes
        -----
        on, lsuffix, and rsuffix options are not supported when passing a list
        of DataFrame objects
        Examples
        --------
        &gt;&gt;&gt; caller
            A key
        0  A0  K0
        1  A1  K1
        2  A2  K2
        3  A3  K3
        4  A4  K4
        5  A5  K5

        &gt;&gt;&gt; other
            B key
        0  B0  K0
        1  B1  K1
        2  B2  K2
        Join DataFrames using their indexes.
        &gt;&gt;&gt; caller.join(other, lsuffix=&#39;_caller&#39;, rsuffix=&#39;_other&#39;)
        &gt;&gt;&gt;     A key_caller    B key_other
            0  A0         K0   B0        K0
            1  A1         K1   B1        K1
            2  A2         K2   B2        K2
            3  A3         K3  NaN       NaN
            4  A4         K4  NaN       NaN
            5  A5         K5  NaN       NaN
        If we want to join using the key columns, we need to set key to be
        the index in both caller and other. The joined DataFrame will have
        key as its index.
        &gt;&gt;&gt; caller.set_index(&#39;key&#39;).join(other.set_index(&#39;key&#39;))
        &gt;&gt;&gt;      A    B
            key
            K0   A0   B0
            K1   A1   B1
            K2   A2   B2
            K3   A3  NaN
            K4   A4  NaN
            K5   A5  NaN
        Another option to join using the key columns is to use the on
        parameter. DataFrame.join always uses other&#39;s index but we can use any
        column in the caller. This method preserves the original caller&#39;s
        index in the result.
        &gt;&gt;&gt; caller.join(other.set_index(&#39;key&#39;), on=&#39;key&#39;)
        &gt;&gt;&gt;     A key    B
            0  A0  K0   B0
            1  A1  K1   B1
            2  A2  K2   B2
            3  A3  K3  NaN
            4  A4  K4  NaN
            5  A5  K5  NaN
        See also
        --------
        DataFrame.merge : For column(s)-on-columns(s) operations
        Returns
        -------
        joined : DataFrame
        &#34;&#34;&#34;
        left_on = on
        if left_on is None:
            left_on = self._index_columns

        right_on = other._index_columns

        if left_on is None or len(left_on) == 0:
            raise ValueError(
                &#34;The column to join from left relation is no specified. Either provide &#39;on&#39; or set indexing&#34;)

        if right_on is None or len(right_on) == 0:
            raise ValueError(
                &#34;The &#39;other&#39; relation doesn&#39;t have index columns specified.&#34;)

        if env is None:
            joined_table = self._table.join(table=other._table, join_type=how,
                                            algorithm=algorithm,
                                            left_on=left_on, right_on=right_on,
                                            left_prefix=lsuffix, right_prefix=rsuffix)
            return DataFrame(joined_table)
        else:
            # attach context
            self._change_context(env=env)
            other._change_context(env=env)

            joined_table = self._table.distributed_join(table=other._table, join_type=how,
                                                        algorithm=algorithm,
                                                        left_on=left_on, right_on=right_on,
                                                        left_prefix=lsuffix, right_prefix=rsuffix)
            return DataFrame(joined_table)

    def merge(self,
              right: DataFrame,
              how=&#34;inner&#34;,
              algorithm=&#34;sort&#34;,
              on=None,
              left_on=None,
              right_on=None,
              left_index=False,
              right_index=False,
              sort=False,
              suffixes=(&#34;_x&#34;, &#34;_y&#34;),
              copy=True,
              indicator=False,
              validate=None,
              env: CylonEnv = None) -&gt; DataFrame:
        &#34;&#34;&#34;
        Merge DataFrame with a database-style join.
        The join is done on columns or indexes. If joining columns on
        columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes
        on indexes or indexes on a column or columns, the index will be passed on.
        When performing a cross merge, no column specifications to merge on are
        allowed.

        Parameters
        ----------
        right : DataFrame or named Series
            Object to merge with.
        how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;, &#39;cross(Unsupported)&#39;}, default &#39;inner&#39;
            Type of merge to be performed.
            * left: use only keys from left frame, similar to a SQL left outer join;
            preserve key order.
            * right: use only keys from right frame, similar to a SQL right outer join;
            preserve key order.
            * outer: use union of keys from both frames, similar to a SQL full outer
            join; sort keys lexicographically.
            * inner: use intersection of keys from both frames, similar to a SQL inner
            join; preserve the order of the left keys.
            * cross: creates the cartesian product from both frames, preserves the order
            of the left keys.
            .. versionadded:: 1.2.0
        on : label or list
            Column or index level names to join on. These must be found in both
            DataFrames. If `on` is None and not merging on indexes then this defaults
            to the intersection of the columns in both DataFrames.
        left_on : label or list, or array-like
            Column or index level names to join on in the left DataFrame. Can also
            be an array or list of arrays of the length of the left DataFrame.
            These arrays are treated as if they are columns.
        right_on : label or list, or array-like
            Column or index level names to join on in the right DataFrame. Can also
            be an array or list of arrays of the length of the right DataFrame.
            These arrays are treated as if they are columns.
        left_index : bool, default False
            Use the index from the left DataFrame as the join key(s). If it is a
            MultiIndex, the number of keys in the other DataFrame (either the index
            or a number of columns) must match the number of levels.
        right_index : bool, default False
            Use the index from the right DataFrame as the join key. Same caveats as
            left_index.
        sort(Unsupported) : bool, default False
            Sort the join keys lexicographically in the result DataFrame. If False,
            the order of the join keys depends on the join type (how keyword).
        suffixes : list-like, default is (&#34;_x&#34;, &#34;_y&#34;)
            A length-2 sequence where each element is optionally a string
            indicating the suffix to add to overlapping column names in
            `left` and `right` respectively. Pass a value of `None` instead
            of a string to indicate that the column name from `left` or
            `right` should be left as-is, with no suffix. At least one of the
            values must not be None.
        copy(Unsupported) : bool, default True
            If False, avoid copy if possible.
        indicator(Unsupported) : bool or str, default False
            If True, adds a column to the output DataFrame called &#34;_merge&#34; with
            information on the source of each row. The column can be given a different
            name by providing a string argument. The column will have a Categorical
            type with the value of &#34;left_only&#34; for observations whose merge key only
            appears in the left DataFrame, &#34;right_only&#34; for observations
            whose merge key only appears in the right DataFrame, and &#34;both&#34;
            if the observation&#39;s merge key is found in both DataFrames.
        validate(Unsupported) : str, optional
            If specified, checks if merge is of specified type.
            * &#34;one_to_one&#34; or &#34;1:1&#34;: check if merge keys are unique in both
            left and right datasets.
            * &#34;one_to_many&#34; or &#34;1:m&#34;: check if merge keys are unique in left
            dataset.
            * &#34;many_to_one&#34; or &#34;m:1&#34;: check if merge keys are unique in right
            dataset.
            * &#34;many_to_many&#34; or &#34;m:m&#34;: allowed, but does not result in checks.
        Returns
        -------
        DataFrame
            A DataFrame of the two merged objects.
        See Also
        --------
        merge_ordered : Merge with optional filling/interpolation.
        merge_asof : Merge on nearest keys.
        DataFrame.join : Similar method using indices.
        Notes
        -----
        Support for specifying index levels as the `on`, `left_on`, and
        `right_on` parameters was added in version 0.23.0
        Support for merging named Series objects was added in version 0.24.0
        Examples
        --------
        &gt;&gt;&gt; df1 = DataFrame({&#39;lkey&#39;: [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;],
        ...                     &#39;value&#39;: [1, 2, 3, 5]})
        &gt;&gt;&gt; df2 = DataFrame({&#39;rkey&#39;: [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;],
        ...                     &#39;value&#39;: [5, 6, 7, 8]})
        &gt;&gt;&gt; df1
            lkey value
        0   foo      1
        1   bar      2
        2   baz      3
        3   foo      5
        &gt;&gt;&gt; df2
            rkey value
        0   foo      5
        1   bar      6
        2   baz      7
        3   foo      8

        Merge df1 and df2 on the lkey and rkey columns. The value columns have
        the default suffixes, _x and _y, appended.

        &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;)
        lkey  value_x rkey  value_y
        0  foo        1  foo        5
        1  foo        1  foo        8
        2  foo        5  foo        5
        3  foo        5  foo        8
        4  bar        2  bar        6
        5  baz        3  baz        7

        Merge DataFrames df1 and df2 with specified left and right suffixes
        appended to any overlapping columns.

        &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;,
        ...           suffixes=(&#39;_left&#39;, &#39;_right&#39;))
        lkey  value_left rkey  value_right
        0  foo           1  foo            5
        1  foo           1  foo            8
        2  foo           5  foo            5
        3  foo           5  foo            8
        4  bar           2  bar            6
        5  baz           3  baz            7

        Merge DataFrames df1 and df2, but raise an exception if the DataFrames have
        any overlapping columns.

        &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;, suffixes=(False, False))
        Traceback (most recent call last):
        ...
        ValueError: columns overlap but no suffix specified:
            Index([&#39;value&#39;], dtype=&#39;object&#39;)

        &gt;&gt;&gt; df1 = DataFrame({&#39;a&#39;: [&#39;foo&#39;, &#39;bar&#39;], &#39;b&#39;: [1, 2]})
        &gt;&gt;&gt; df2 = DataFrame({&#39;a&#39;: [&#39;foo&#39;, &#39;baz&#39;], &#39;c&#39;: [3, 4]})
        &gt;&gt;&gt; df1
            a  b
        0   foo  1
        1   bar  2

        &gt;&gt;&gt; df2
            a  c
        0   foo  3
        1   baz  4

        &gt;&gt;&gt; df1.merge(df2, how=&#39;inner&#39;, on=&#39;a&#39;)
            a  b  c
        0   foo  1  3

        &gt;&gt;&gt; df1.merge(df2, how=&#39;left&#39;, on=&#39;a&#39;)
            a  b  c
        0   foo  1  3.0
        1   bar  2  NaN

        &gt;&gt;&gt; df1 = DataFrame({&#39;left&#39;: [&#39;foo&#39;, &#39;bar&#39;]})
        &gt;&gt;&gt; df2 = DataFrame({&#39;right&#39;: [7, 8]})

        &gt;&gt;&gt; df1
            left
        0   foo
        1   bar

        &gt;&gt;&gt; df2
            right
        0   7
        1   8

        &gt;&gt;&gt; df1.merge(df2, how=&#39;cross&#39;)
        left  right
        0   foo      7
        1   foo      8
        2   bar      7
        3   bar      8
        &#34;&#34;&#34;
        if not on is None:
            left_on = on
            right_on = on

        if left_index:
            left_on = self._index_columns

        if right_index:
            right_on = right._index_columns

        if left_on is None or right_on is None:
            raise ValueError(&#34;Columns to merge is not specified. Expected on or left_index/right_index.&#34;
                             &#34;Make sure dataframes has specified index columns if using left_index/right_index&#34;)

        if env is None:
            joined_table = self._table.join(table=right._table, join_type=how,
                                            algorithm=algorithm,
                                            left_on=left_on, right_on=right_on,
                                            left_prefix=suffixes[0], right_prefix=suffixes[1])
            return DataFrame(joined_table)
        else:
            self._change_context(env)
            right._change_context(env)
            joined_table = self._table.distributed_join(table=right._table, join_type=how,
                                                        algorithm=algorithm,
                                                        left_on=left_on, right_on=right_on,
                                                        left_prefix=suffixes[0], right_prefix=suffixes[1])
            return DataFrame(joined_table)

    @staticmethod
    def concat(
        objs: Union[Iterable[&#34;DataFrame&#34;]],
        axis=0,
        join=&#34;outer&#34;,
        ignore_index: bool = False,
        keys=None,
        levels=None,
        names=None,
        verify_integrity: bool = False,
        sort: bool = False,
        copy: bool = True,
        env: CylonEnv = None
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Concatenate DataFrames along a particular axis with optional set logic
        along the other axes.
        Can also add a layer of hierarchical indexing on the concatenation axis,
        which may be useful if the labels are the same (or overlapping) on
        the passed axis number.

        Cylon currently support concat along axis=0, for DataFrames having the same schema(Union). 

        Parameters
        ----------
        objs : a sequence or mapping of Series or DataFrame objects
            If a mapping is passed, the sorted keys will be used as the `keys`
            argument, unless it is passed, in which case the values will be
            selected (see below). Any None objects will be dropped silently unless
            they are all None in which case a ValueError will be raised.
        axis : {0/&#39;index&#39;, 1/&#39;columns&#39; (Unsupported)}, default 0
            The axis to concatenate along.
        join(Unsupported) : {&#39;inner&#39;, &#39;outer&#39;}, default &#39;outer&#39;
            How to handle indexes on other axis (or axes).
        ignore_index(Unsupported) : bool, default False
            If True, do not use the index values along the concatenation axis. The
            resulting axis will be labeled 0, ..., n - 1. This is useful if you are
            concatenating objects where the concatenation axis does not have
            meaningful indexing information. Note the index values on the other
            axes are still respected in the join.
        keys(Unsupported) : sequence, default None
            If multiple levels passed, should contain tuples. Construct
            hierarchical index using the passed keys as the outermost level.
        levels(Unsupported) : list of sequences, default None
            Specific levels (unique values) to use for constructing a
            MultiIndex. Otherwise they will be inferred from the keys.
        names(Unsupported) : list, default None
            Names for the levels in the resulting hierarchical index.
        verify_integrity(Unsupported) : bool, default False
            Check whether the new concatenated axis contains duplicates. This can
            be very expensive relative to the actual data concatenation.
        sort(Unsupported) : bool, default False
            Sort non-concatenation axis if it is not already aligned when `join`
            is &#39;outer&#39;.
            This has no effect when ``join=&#39;inner&#39;``, which already preserves
            the order of the non-concatenation axis.
            .. versionchanged:: 1.0.0
            Changed to not sort by default.
        copy(Unsupported) : bool, default True
            If False, do not copy data unnecessarily.
        Returns
        -------
        object, type of objs
            When concatenating along
            the columns (axis=1) or rows (axis=0), a ``DataFrame`` is returned.

        Examples
        --------

        Combine two ``DataFrame`` objects with identical columns.

        &gt;&gt;&gt; df1 = DataFrame([[&#39;a&#39;, 1], [&#39;b&#39;, 2]],
        ...                    columns=[&#39;letter&#39;, &#39;number&#39;])
        &gt;&gt;&gt; df1
        letter  number
        0      a       1
        1      b       2
        &gt;&gt;&gt; df2 = DataFrame([[&#39;c&#39;, 3], [&#39;d&#39;, 4]],
        ...                    columns=[&#39;letter&#39;, &#39;number&#39;])
        &gt;&gt;&gt; df2
        letter  number
        0      c       3
        1      d       4
        &gt;&gt;&gt; DataFrame.concat([df1, df2])
        letter  number
        0      a       1
        1      b       2
        0      c       3
        1      d       4

        (Unsupported) Combine ``DataFrame`` objects with overlapping columns
        and return everything. Columns outside the intersection will
        be filled with ``NaN`` values.

        &gt;&gt;&gt; df3 = DataFrame([[&#39;c&#39;, 3, &#39;cat&#39;], [&#39;d&#39;, 4, &#39;dog&#39;]],
        ...                    columns=[&#39;letter&#39;, &#39;number&#39;, &#39;animal&#39;])
        &gt;&gt;&gt; df3
        letter  number animal
        0      c       3    cat
        1      d       4    dog
        &gt;&gt;&gt; DataFrame.concat([df1, df3], sort=False)
        letter  number animal
        0      a       1    NaN
        1      b       2    NaN
        0      c       3    cat
        1      d       4    dog

        (Unsupported) Combine ``DataFrame`` objects with overlapping columns
        and return only those that are shared by passing ``inner`` to
        the ``join`` keyword argument.

        &gt;&gt;&gt; DataFrame.concat([df1, df3], join=&#34;inner&#34;)
        letter  number
        0      a       1
        1      b       2
        0      c       3
        1      d       4

        (Unsupported) Combine ``DataFrame`` objects horizontally along the x axis by
        passing in ``axis=1``.

        &gt;&gt;&gt; df4 = DataFrame([[&#39;bird&#39;, &#39;polly&#39;], [&#39;monkey&#39;, &#39;george&#39;]],
        ...                    columns=[&#39;animal&#39;, &#39;name&#39;])
        &gt;&gt;&gt; DataFrame.concat([df1, df4], axis=1)

        letter  number  animal    name
        0      a       1    bird   polly
        1      b       2  monkey  george

        (Unsupported) Prevent the result from including duplicate index values with the
        ``verify_integrity`` option.

        &gt;&gt;&gt; df5 = DataFrame([1], index=[&#39;a&#39;])
        &gt;&gt;&gt; df5
        0
        a  1
        &gt;&gt;&gt; df6 = DataFrame([2], index=[&#39;a&#39;])
        &gt;&gt;&gt; df6
        0
        a  2
        &gt;&gt;&gt; DataFrame.concat([df5, df6], verify_integrity=True)
        Traceback (most recent call last):
            ...
        ValueError: Indexes have overlapping values: [&#39;a&#39;]
        &#34;&#34;&#34;

        if len(objs) == 0:
            raise &#34;objs can&#39;t be empty&#34;

        if axis == 0:
            if env is None:
                current_table = objs[0]._table
                for i in range(1, len(objs)):
                    current_table = current_table.union(objs[i]._table)

                return DataFrame(current_table)
            else:
                # todo not optimum for distributed
                current_table = objs[0]._change_context(env)._table
                for i in range(1, len(objs)):
                    current_table = current_table.union(
                        objs[i]._change_context(env)._table)

                return DataFrame(current_table)
        else:
            raise &#34;Unsupported operation&#34;

    def drop_duplicates(
        self,
        subset: Optional[Union[Hashable, Sequence[Hashable]]] = None,
        keep: Union[str, bool] = &#34;first&#34;,
        inplace: bool = False,
        ignore_index: bool = False,
        env: CylonEnv = None
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Return DataFrame with duplicate rows removed.
        Considering certain columns is optional. Indexes, including time indexes
        are ignored.
        Parameters
        ----------
        subset : column label or sequence of labels, optional
            Only consider certain columns for identifying duplicates, by
            default use all of the columns.
        keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
            Determines which duplicates (if any) to keep.
            - ``first`` : Drop duplicates except for the first occurrence.
            - ``last`` : Drop duplicates except for the last occurrence.
            - False (Unsupported): Drop all duplicates.
        inplace : bool, default False
            Whether to drop duplicates in place or to return a copy.
        ignore_index (Unsupported) : bool, default False
            If True, the resulting axis will be labeled 0, 1, …, n - 1.
            .. versionadded:: 1.0.0
        Returns
        -------
        DataFrame or None
            DataFrame with duplicates removed or None if ``inplace=True``(Unsupported).
        See Also
        --------
        DataFrame.value_counts: Count unique combinations of columns.
        Examples
        --------
        Consider dataset containing ramen rating.
        &gt;&gt;&gt; df = DataFrame({
        ...     &#39;brand&#39;: [&#39;Yum Yum&#39;, &#39;Yum Yum&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;],
        ...     &#39;style&#39;: [&#39;cup&#39;, &#39;cup&#39;, &#39;cup&#39;, &#39;pack&#39;, &#39;pack&#39;],
        ...     &#39;rating&#39;: [4, 4, 3.5, 15, 5]
        ... })
        &gt;&gt;&gt; df
            brand style  rating
        0  Yum Yum   cup     4.0
        1  Yum Yum   cup     4.0
        2  Indomie   cup     3.5
        3  Indomie  pack    15.0
        4  Indomie  pack     5.0
        By default, it removes duplicate rows based on all columns.
        &gt;&gt;&gt; df.drop_duplicates()
            brand style  rating
        0  Yum Yum   cup     4.0
        2  Indomie   cup     3.5
        3  Indomie  pack    15.0
        4  Indomie  pack     5.0
        To remove duplicates on specific column(s), use ``subset``.
        &gt;&gt;&gt; df.drop_duplicates(subset=[&#39;brand&#39;])
            brand style  rating
        0  Yum Yum   cup     4.0
        2  Indomie   cup     3.5
        To remove duplicates and keep last occurrences, use ``keep``.
        &gt;&gt;&gt; df.drop_duplicates(subset=[&#39;brand&#39;, &#39;style&#39;], keep=&#39;last&#39;)
            brand style  rating
        1  Yum Yum   cup     4.0
        2  Indomie   cup     3.5
        4  Indomie  pack     5.0
        &#34;&#34;&#34;
        if env is None:
            return DataFrame(self._table.unique(columns=subset, keep=keep, inplace=inplace))
        else:
            return DataFrame(self._change_context(env)._table.distributed_unique(columns=subset, inplace=inplace))

    def sort_values(
        self,
        by,
        axis=0,
        ascending=True,
        inplace=False,
        kind=&#34;quicksort&#34;,
        na_position=&#34;last&#34;,
        ignore_index=False,
        key=None,
        env: CylonEnv = None
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Sort by the values along either axis.
        Parameters
        ----------

        axis : %(axes_single_arg)s, default 0
             Axis to be sorted.
        ascending : bool or list of bool, default True
             Sort ascending vs. descending. Specify list for multiple sort
             orders.  If this is a list of bools, must match the length of
             the by.
        inplace(Unsupported) : bool, default False
             If True, perform operation in-place.
        kind(Unsupported) : {&#39;quicksort&#39;, &#39;mergesort&#39;, &#39;heapsort&#39;, &#39;stable&#39;}, default &#39;quicksort&#39;
             Choice of sorting algorithm. See also :func:`numpy.sort` for more
             information. `mergesort` and `stable` are the only stable algorithms. For
             DataFrames, this option is only applied when sorting on a single
             column or label.
        na_position(Unsupported) : {&#39;first&#39;, &#39;last&#39;}, default &#39;last&#39;
             Puts NaNs at the beginning if `first`; `last` puts NaNs at the
             end.
        ignore_index(Unsupported) : bool, default False
             If True, the resulting axis will be labeled 0, 1, …, n - 1.
             .. versionadded:: 1.0.0
        key(Unsupported) : callable, optional
            Apply the key function to the values
            before sorting. This is similar to the `key` argument in the
            builtin :meth:`sorted` function, with the notable difference that
            this `key` function should be *vectorized*. It should expect a
            ``Series`` and return a Series with the same shape as the input.
            It will be applied to each column in `by` independently.
            .. versionadded:: 1.1.0
        Returns
        -------
        DataFrame or None
            DataFrame with sorted values or None if ``inplace=True``.
        See Also
        --------
        DataFrame.sort_index : Sort a DataFrame by the index.
        Series.sort_values : Similar method for a Series.
        Examples
        --------
        &gt;&gt;&gt; df = DataFrame({
        ...     &#39;col1&#39;: [&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, np.nan, &#39;D&#39;, &#39;C&#39;],
        ...     &#39;col2&#39;: [2, 1, 9, 8, 7, 4],
        ...     &#39;col3&#39;: [0, 1, 9, 4, 2, 3],
        ...     &#39;col4&#39;: [&#39;a&#39;, &#39;B&#39;, &#39;c&#39;, &#39;D&#39;, &#39;e&#39;, &#39;F&#39;]
        ... })
        &gt;&gt;&gt; df
          col1  col2  col3 col4
        0    A     2     0    a
        1    A     1     1    B
        2    B     9     9    c
        3  NaN     8     4    D
        4    D     7     2    e
        5    C     4     3    F
        Sort by col1
        &gt;&gt;&gt; df.sort_values(by=[&#39;col1&#39;])
          col1  col2  col3 col4
        0    A     2     0    a
        1    A     1     1    B
        2    B     9     9    c
        5    C     4     3    F
        4    D     7     2    e
        3  NaN     8     4    D
        Sort by multiple columns
        &gt;&gt;&gt; df.sort_values(by=[&#39;col1&#39;, &#39;col2&#39;])
          col1  col2  col3 col4
        1    A     1     1    B
        0    A     2     0    a
        2    B     9     9    c
        5    C     4     3    F
        4    D     7     2    e
        3  NaN     8     4    D
        Sort Descending
        &gt;&gt;&gt; df.sort_values(by=&#39;col1&#39;, ascending=False)
          col1  col2  col3 col4
        4    D     7     2    e
        5    C     4     3    F
        2    B     9     9    c
        0    A     2     0    a
        1    A     1     1    B
        3  NaN     8     4    D
        &#34;&#34;&#34;
        if env is None:
            return DataFrame(self._table.sort(order_by=by, ascending=ascending))
        else:
            return DataFrame(self._change_context(env)._table.distributed_sort(order_by=by, ascending=ascending))

    def groupby(self, by: Union([int, str, List]), env: CylonEnv = None) -&gt; GroupByDataFrame:
        &#34;&#34;&#34;
        A groupby operation involves some combination of splitting the object, applying a function, and combining the results. 
        This can be used to group large amounts of data and compute operations on these groups.

        Parameters
        ----------

        by : str, int or a list of str, int.  
            List of column(s) used for grouping.
        
        Returns
        -------
        GroupByDataFrame

        Examples
        -------

        &gt;&gt;&gt; df1 = DataFrame([[0, 0, 1, 1], [1, 10, 1, 5], [10, 20, 30, 40]])
        &gt;&gt;&gt; df1


        &gt;&gt;&gt; df3 = df1.groupby(by=0).agg({&#34;1&#34;: &#34;sum&#34;, &#34;2&#34;: &#34;min&#34;})
        &gt;&gt;&gt; df3
        0  sum_1  min_2
        0  0     11     10
        1  1      6     30

        &gt;&gt;&gt; df4 = df1.groupby(by=0).min()
        &gt;&gt;&gt; df4
        0  min_2  min_1
        0  0     10      1
        1  1     30      1

        &gt;&gt;&gt; df5 = df1.groupby(by=[0, 1]).max()
        &gt;&gt;&gt; df5
        0   1  max_2
        0  0   1     10
        1  0  10     20
        2  1   1     30
        3  1   5     40
        &#34;&#34;&#34;
        by_list = []
        if isinstance(by, int):
            by_list.append(self.columns[by])
        elif isinstance(by, str):
            if by not in self.columns:
                raise ValueError(
                    str+&#34; is not a column of this table. Expected one of &#34;+str(by))
            by_list.append(by)
        elif isinstance(by, list):
            if len(by) == 0:
                raise ValueError(&#34;Group by columns should be specified.&#34;)

            for b in by:
                if isinstance(b, str):
                    by_list.append(b)
                elif isinstance(b, int):
                    by_list.append(self.columns[b])
                else:
                    raise ValueError(
                        &#34;Unsupported column specification. Expected column index or name&#34;)
        else:
            raise ValueError(&#34;Unknown value for by&#34;)
        if env is None:
            return GroupByDataFrame(self, by_list)
        else:
            return GroupByDataFrame(self._change_context(env), by_list)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="frame.read_csv"><code class="name flex">
<span>def <span class="ident">read_csv</span></span>(<span>filepath: str, use_threads=True, names=None, sep=',', block_size: int = 1048576, skiprows=0, ignore_emptylines=True, na_values=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Read a comma-separated values (csv) file into DataFrame.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>A valid str path to the file</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>sep</code></strong> :&ensp;<code>str</code>, default <code>,</code></dt>
<dd>Delimiter to use.</dd>
<dt><strong><code>names</code></strong> :&ensp;<code>array-like</code>, optional</dt>
<dd>List of column names to use. If the file contains a header row,
then you should explicitly pass <code>header=0</code> to override the column names.
Duplicates in this list are not allowed.</dd>
<dt><strong><code>block_size</code></strong> :&ensp;<code>int</code>, default <code>1MB</code></dt>
<dd>Arrow block size to be used when chunking the final Cylon table</dd>
<dt><strong><code>skiprows</code></strong> :&ensp;<code>int</code>, optional, default <code>0</code></dt>
<dd>Line numbers to skip (0-indexed) or number of lines to skip (int)
at the start of the file.</dd>
<dt><strong><code>ignore_emptylines</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Whether to keep or ignore empty lines in the csv file</dd>
<dt><strong><code>na_values</code></strong> :&ensp;<code>list-like</code>, optional</dt>
<dd>Additional strings to recognize as NA/NaN.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_csv(filepath: str, use_threads=True,  names=None, sep=&#34;,&#34;, block_size: int = 1 &lt;&lt; 20, skiprows=0, ignore_emptylines=True, na_values=None):
    &#34;&#34;&#34;
    Read a comma-separated values (csv) file into DataFrame.

    Parameters
    ----------
    filepath : A valid str path to the file
    sep : str, default ,
        Delimiter to use. 
    names : array-like, optional
        List of column names to use. If the file contains a header row,
        then you should explicitly pass ``header=0`` to override the column names.
        Duplicates in this list are not allowed.
    block_size : int, default 1MB
        Arrow block size to be used when chunking the final Cylon table
    skiprows : int, optional, default 0
        Line numbers to skip (0-indexed) or number of lines to skip (int)
        at the start of the file.
    ignore_emptylines: bool, default True
        Whether to keep or ignore empty lines in the csv file
    na_values : list-like, optional
        Additional strings to recognize as NA/NaN.
    &#34;&#34;&#34;
    read_config = CSVReadOptions().use_threads(
        use_threads).block_size(block_size).with_delimiter(sep).skip_rows(skiprows)

    if ignore_emptylines:
        read_config.ignore_emptylines()

    if na_values is not None:
        read_config.na_values(na_values)

    if names is not None:
        read_config.use_cols(names)

    table = pcd.csv.read_csv(CylonContext(
        config=None, distributed=False), filepath, read_config)

    return DataFrame(table)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="frame.CylonEnv"><code class="flex name class">
<span>class <span class="ident">CylonEnv</span></span>
<span>(</span><span>config=None, distributed=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CylonEnv(object):

    def __init__(self, config=None, distributed=True) -&gt; None:
        self._context = CylonContext(config, distributed)
        self._distributed = distributed
        self._finalized = False

    @property
    def context(self) -&gt; CylonContext:
        return self._context

    @property
    def rank(self) -&gt; int:
        return self._context.get_rank()

    @property
    def world_size(self) -&gt; int:
        return self._context.get_world_size()

    @property
    def is_distributed(self) -&gt; bool:
        return self._distributed

    def finalize(self):
        if not self._finalized:
            self._finalized = True
            self._context.finalize()

    def barrier(self):
        self._context.barrier()

    def __del__(self):
        &#34;&#34;&#34;
        On destruction of the application, the environment will be automatically finalized
        &#34;&#34;&#34;
        self.finalize()</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="frame.CylonEnv.context"><code class="name">var <span class="ident">context</span> : pycylon.ctx.context.CylonContext</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def context(self) -&gt; CylonContext:
    return self._context</code></pre>
</details>
</dd>
<dt id="frame.CylonEnv.is_distributed"><code class="name">var <span class="ident">is_distributed</span> : bool</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def is_distributed(self) -&gt; bool:
    return self._distributed</code></pre>
</details>
</dd>
<dt id="frame.CylonEnv.rank"><code class="name">var <span class="ident">rank</span> : int</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def rank(self) -&gt; int:
    return self._context.get_rank()</code></pre>
</details>
</dd>
<dt id="frame.CylonEnv.world_size"><code class="name">var <span class="ident">world_size</span> : int</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def world_size(self) -&gt; int:
    return self._context.get_world_size()</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="frame.CylonEnv.barrier"><code class="name flex">
<span>def <span class="ident">barrier</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def barrier(self):
    self._context.barrier()</code></pre>
</details>
</dd>
<dt id="frame.CylonEnv.finalize"><code class="name flex">
<span>def <span class="ident">finalize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def finalize(self):
    if not self._finalized:
        self._finalized = True
        self._context.finalize()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="frame.DataFrame"><code class="flex name class">
<span>class <span class="ident">DataFrame</span></span>
<span>(</span><span>data=None, index=None, columns=None, copy=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Construct a Cylon DataFrame</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>Python list, ndarray, Pandas Dataframe, Arrow Table</code> or <code>a Cylon Table</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>columns</code></strong> :&ensp;<code>Optional set</code> of <code>column names</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>copy</code></strong> :&ensp;<code>By default, Cylon will try not to copy data when constructing a datframe from ndarray, </code></dt>
<dd>Pandas Dataframe, Arrow Table or a Cylon Table. This behavior can be forcefully overridden by setting this flag.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataFrame(object):

    def __init__(self, data=None, index=None, columns=None, copy=False):
        &#34;&#34;&#34;
        Construct a Cylon DataFrame

        Parameters
        ----------
        data : Python list, ndarray, Pandas Dataframe, Arrow Table or a Cylon Table
        columns : Optional set of column names
        copy : By default, Cylon will try not to copy data when constructing a datframe from ndarray, 
            Pandas Dataframe, Arrow Table or a Cylon Table. This behavior can be forcefully overridden by setting this flag.

        Returns
        -------
        DataFrame
        &#34;&#34;&#34;
        self._index = None
        self._columns = []

        self._table = self._initialize_dataframe(
            data=data, index=index, columns=columns, copy=copy)

        # temp workaround for indexing requirement of dataframe api
        self._index_columns = []

        self._device = DEVICE_CPU

    def to_cpu(self):
        &#34;&#34;&#34;
        Move the dataframe from it&#39;s current device to random access memory
        &#34;&#34;&#34;
        pass

    def to_device(self, device=None):
        &#34;&#34;&#34;
        Move the dataframe from it&#39;s current device to the specified device
        &#34;&#34;&#34;
        pass

    def is_cpu(self):
        return self._device == DEVICE_CPU

    def is_device(self, device):
        return self._device == device

    def _change_context(self, env: CylonEnv):
        &#34;&#34;&#34;
        This is a temporary function to make the DataFrame backed by a Cylon Table with a different context.
        This should be removed once C++ support Tables which are independent from Contexts
        &#34;&#34;&#34;
        self._table = self._initialize_dataframe(
            data=self._table.to_arrow(), index=self._index, columns=self._columns, copy=False, context=env.context)
        return self

    def _initialize_dataframe(self, data=None, index=None, columns=None, copy=False, context=CylonContext(config=None, distributed=False)):
        rows = 0
        cols = 0
        self._table = None
        if copy:
            data = self._copy(data)

        if isinstance(data, List):
            # load from List or np.ndarray
            if isinstance(data[0], List):
                rows = len(data[0])
                cols = len(data)
                if not columns:
                    columns = self._initialize_columns(
                        cols=cols, columns=columns)
                return cn.Table.from_list(context, columns, data)
            elif isinstance(data[0], np.ndarray):
                # load from List of np.ndarray
                cols = len(data)
                rows = data[0].shape[0]
                if not columns:
                    columns = self._initialize_columns(
                        cols=cols, columns=columns)
                return cn.Table.from_numpy(context, columns, data)
            else:
                # load from List
                rows = len(data)
                cols = 1
                if not columns:
                    columns = self._initialize_columns(
                        cols=cols, columns=columns)
                return cn.Table.from_list(context, columns, data)
        elif isinstance(data, pd.DataFrame):
            # load from pd.DataFrame
            rows, cols = data.shape
            if columns:
                from pycylon.util.pandas.utils import rename_with_new_column_names
                columns = rename_with_new_column_names(data, columns)
                data = data.rename(columns=columns, inplace=True)
            return cn.Table.from_pandas(context, data)
        elif isinstance(data, dict):
            # load from dictionary
            _, data_items = list(data.items())[0]
            rows = len(data_items)
            return cn.Table.from_pydict(context, data)
        elif isinstance(data, pa.Table):
            # load from pa.Table
            rows, cols = data.shape
            return cn.Table.from_arrow(context, data)
        elif isinstance(data, Series):
            # load from PyCylon Series
            # cols, rows = data.shape
            # columns = self._initialize_columns(cols=cols, columns=columns)
            return NotImplemented
        elif isinstance(data, cn.Table):
            if columns:
                from pycylon.util.pandas.utils import rename_with_new_column_names
                columns = rename_with_new_column_names(data, columns)
                data = data.rename(columns=columns)
            return data
        else:
            raise ValueError(f&#34;Invalid data structure, {type(data)}&#34;)

    def _initialize_dtype(self, dtype):
        raise NotImplemented(
            &#34;Data type forcing is not implemented, only support inferring types&#34;)

    def _initialize_columns(self, cols, columns):
        if columns is None:
            return [str(i) for i in range(cols)]
        else:
            if isinstance(columns, Iterable):
                if len(columns) != cols:
                    raise ValueError(f&#34;data columns count: {cols} and column names count &#34;
                                     f&#34;{len(columns)} not equal&#34;)
                else:
                    return columns

    def _initialize_index(self, index, rows):
        if index is None:
            self._index = RangeIndex(start=0, stop=rows)
        else:
            if isinstance(index, CategoricalIndex):
                # check the validity of provided Index
                pass
            elif isinstance(index, RangeIndex):
                # check the validity of provided Index
                pass

    def _copy(self, obj):
        return copy(obj)

    @property
    def shape(self):
        return self._table.shape

    @property
    def columns(self) -&gt; List[str]:
        return self._table.column_names

    def to_pandas(self) -&gt; pd.DataFrame:
        return self._table.to_pandas()

    def to_numpy(self, order: str = &#39;F&#39;, zero_copy_only: bool = True, writable: bool = False) -&gt; \
            np.ndarray:
        return self._table.to_numpy(order=order, zero_copy_only=zero_copy_only,
                                    writable=writable)

    def to_arrow(self) -&gt; pa.Table:
        return self._table.to_arrow()

    def to_dict(self) -&gt; Dict:
        return self._table.to_pydict()

    def to_table(self) -&gt; cn.Table:
        return self._table

    def to_csv(self, path, csv_write_options: CSVWriteOptions):
        self._table.to_csv(path=path, csv_write_options=csv_write_options)

    def __getitem__(self, item) -&gt; DataFrame:
        &#34;&#34;&#34;
            This method allows to retrieve a subset of a DataFrane by means of a key
            Args:
                key: a key can be the following
                     1. slice i.e dataframe[1:5], rows 1:5
                     2. int i.e a row index
                     3. str i.e extract the data column-wise by column-name
                     4. List of columns are extracted
                     5. PyCylon DataFrame
            Returns: PyCylon DataFrame

            Examples
            --------
            &gt;&gt;&gt; data = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]
            &gt;&gt;&gt; df: DataFrame = DataFrame(data)

            &gt;&gt;&gt; df1 = df[1:3]
                col-1  col-2  col-3
                    0      2      6     10
                    1      3      7     11
                    2      4      8     12

            &gt;&gt;&gt; df2 = df[&#39;col-1&#39;]
                   col-1
                0      1
                1      2
                2      3
                3      4

            &gt;&gt;&gt; df3 = df[[&#39;col-1&#39;, &#39;col-2&#39;]]
                   col-1  col-2
                0      1      5
                1      2      6
                2      3      7
                3      4      8

            &gt;&gt;&gt; df4 = df &gt; 3
                     col-1  col-2  col-3
                0    False   True   True
                1    False   True   True
                2    False   True   True
                3     True   True   True

            &gt;&gt;&gt; df5 = df[tb4]
                    col-1  col-2  col-3
                0    NaN      5      9
                1    NaN      6     10
                2    NaN      7     11
                3    4.0      8     12

            &gt;&gt;&gt; df8 = df[&#39;col-1&#39;] &gt; 2
                   col-1  col-2  col-3
                0      3      7     11
                1      4      8     12

        &#34;&#34;&#34;
        if isinstance(item, slice) or isinstance(item, int) or isinstance(item, str) or \
                isinstance(item, List):
            return DataFrame(self._table.__getitem__(item))
        elif isinstance(item, DataFrame):
            return DataFrame(self._table.__getitem__(item.to_table()))

    def __setitem__(self, key, value):
        &#39;&#39;&#39;
            Sets values for a existing dataframe by means of a column
            Args:
                key: (str) column-name
                value: (DataFrame) data as a single column table

            Returns: PyCylon DataFrame

            Examples
            --------
            &gt;&gt;&gt; df
                   col-1  col-2  col-3
                0      1      5      9
                1      2      6     10
                2      3      7     11
                3      4      8     12


            &gt;&gt;&gt; df[&#39;col-3&#39;] = DataFrame([[90, 100, 110, 120]])
                   col-1  col-2  col-3
                0      1      5     90
                1      2      6    100
                2      3      7    110
                3      4      8    120

            &gt;&gt;&gt; df[&#39;col-4&#39;] = DataFrame([190, 1100, 1110, 1120]])
                    col-1  col-2  col-3  col-4
                0      1      5     90    190
                1      2      6    100   1100
                2      3      7    110   1110
                3      4      8    120   1120
        &#39;&#39;&#39;

        if isinstance(key, str) and isinstance(value, DataFrame):
            self._table.__setitem__(key, value.to_table())
        else:
            raise ValueError(f&#34;Not Implemented __setitem__ option for key Type {type(key)} and &#34;
                             f&#34;value type {type(value)}&#34;)

    def __repr__(self):
        return self._table.__repr__()

    def __eq__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
                Equal operator for DataFrame
                Args:
                    other: can be a numeric scalar or a DataFrame

                Returns: PyCylon DataFrame

                Examples
                --------

                &gt;&gt;&gt; df
                       col-1  col-2  col-3
                    0      1      5      9
                    1      2      6     10
                    2      3      7     11
                    3      4      8     12

                &gt;&gt;&gt; df[&#39;col-1&#39;] == 2
                       col-1
                    0  False
                    1   True
                    2  False
                    3  False

                &gt;&gt;&gt; df == 2
                       col-1  col-2  col-3
                    0  False  False  False
                    1   True  False  False
                    2  False  False  False
                    3  False  False  False

                &#39;&#39;&#39;
        return DataFrame(self._table.__eq__(other))

    def __ne__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Not equal operator for DataFrame
        Args:
            other: can be a numeric scalar or DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df3 = df[&#39;col-1&#39;] != 2
               col-1
            0   True
            1  False
            2   True
            3   True

        &gt;&gt;&gt; df4 = df != 2
               col-1  col-2  col-3
            0   True   True   True
            1  False   True   True
            2   True   True   True
            3   True   True   True
        &#39;&#39;&#39;

        return DataFrame(self._table.__ne__(other))

    def __lt__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Lesser than operator for DataFrame
        Args:
            other: can be a numeric scalar or DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; tb
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; tb3 = tb[&#39;col-1&#39;] &lt; 2
               col-1
            0   True
            1  False
            2  False
            3  False

        &gt;&gt;&gt; tb4 = tb &lt; 2
               col-1  col-2  col-3
            0   True  False  False
            1  False  False  False
            2  False  False  False
            3  False  False  False
        &#39;&#39;&#39;

        return DataFrame(self._table.__lt__(other))

    def __gt__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Greater than operator for DataFrame
        Args:
            other: can be a numeric scalar or DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df3 = df[&#39;col-1&#39;] &gt; 2
                col-1
            0  False
            1  False
            2   True
            3   True

        &gt;&gt;&gt; df4 = df &gt; 2
               col-1  col-2  col-3
            0  False   True   True
            1  False   True   True
            2   True   True   True
            3   True   True   True
        &#39;&#39;&#39;

        return DataFrame(self._table.__gt__(other))

    def __le__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Lesser than or equal operator for DataFrame
        Args:
            other: can be a numeric scalar or DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; tb
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df3 = df[&#39;col-1&#39;] &lt;= 2
                col-1
            0   True
            1   True
            2  False
            3  False

        &gt;&gt;&gt; df4 = df &lt;= 2
               col-1  col-2  col-3
            0   True  False  False
            1   True  False  False
            2  False  False  False
            3  False  False  False
        &#39;&#39;&#39;
        return DataFrame(self._table.__le__(other))

    def __ge__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Greater than or equal operator for DataFrame
        Args:
            other: can be a numeric scalar or DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12


        &gt;&gt;&gt; df3 = df[&#39;col-1&#39;] &gt;= 2
               col-1
            0  False
            1   True
            2   True
            3   True

        &gt;&gt;&gt; df4 = df &gt;= 2
               col-1  col-2  col-3
            0  False   True   True
            1   True   True   True
            2   True   True   True
            3   True   True   True
        &#39;&#39;&#39;

        return DataFrame(self._table.__ge__(other))

    def __or__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        Or operator for DataFrame
        Args:
            other: PyCylon DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df1
               col-1  col-2
            0  False   True
            1   True   True
            2  False  False
            3   True  False

        &gt;&gt;&gt; df2
                col-1  col-2
            0   True  False
            1   True   True
            2  False  False
            3  False   True

        &gt;&gt;&gt; df_or = df1 | df2
               col-1  col-2
            0   True   True
            1   True   True
            2  False  False
            3   True   True
        &#39;&#39;&#39;

        return DataFrame(self._table.__or__(other.to_table()))

    def __and__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
        And operator for DataFrame
        Args:
            other: PyCylon DataFrame

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df1
               col-1  col-2
            0  False   True
            1   True   True
            2  False  False
            3   True  False

        &gt;&gt;&gt; df2
                col-1  col-2
            0   True  False
            1   True   True
            2  False  False
            3  False   True

        &gt;&gt;&gt; df_or = df1 &amp; df2
               col-1  col-2
            0  False  False
            1   True   True
            2  False  False
            3  False  False
        &#39;&#39;&#39;

        return DataFrame(self._table.__and__(other.to_table()))

    def __invert__(self) -&gt; DataFrame:
        &#39;&#39;&#39;
         Invert operator for DataFrame

         Returns: PyCylon DataFrame

         Examples
         --------
         &gt;&gt;&gt; df
                col-1  col-2
            0  False   True
            1   True   True
            2  False  False
            3   True  False

        &gt;&gt;&gt; ~df
               col-1  col-2
            0   True  False
            1  False  False
            2   True   True
            3  False   True
         &#39;&#39;&#39;

        return DataFrame(self._table.__invert__())

    def __neg__(self) -&gt; DataFrame:
        &#39;&#39;&#39;
         Negation operator for DataFrame

         Returns: PyCylon DataFrame

         Examples
         --------
         &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

         &gt;&gt;&gt; -df
               col-1  col-2  col-3
            0     -1     -5     -9
            1     -2     -6    -10
            2     -3     -7    -11
            3     -4     -8    -12
         &#39;&#39;&#39;

        return DataFrame(self._table.__neg__())

    def __add__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
         Add operator for DataFrame
         Args:
             other: scalar numeric

         Returns: PyCylon DataFrame

         Examples
         --------
        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df + 2
               col-1  col-2  col-3
            0      3      7     11
            1      4      8     12
            2      5      9     13
            3      6     10     14
         &#39;&#39;&#39;
        return DataFrame(self._table.__add__(other))

    def __sub__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
         Subtract operator for DataFrame
         Args:
             other: scalar numeric

         Returns: PyCylon DataFrame

         Examples
         --------
        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df - 2
               col-1  col-2  col-3
            0     -1      3      7
            1      0      4      8
            2      1      5      9
            3      2      6     10
         &#39;&#39;&#39;
        return DataFrame(self._table.__sub__(other))

    def __mul__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
         Multiply operator for DataFrame
         Args:
             other: scalar numeric

         Returns: PyCylon DataFrame

         Examples
         --------
        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df * 2
               col-1  col-2  col-3
            0      2     10     18
            1      4     12     20
            2      6     14     22
            3      8     16     24
         &#39;&#39;&#39;

        return DataFrame(self._table.__mul__(other))

    def __truediv__(self, other) -&gt; DataFrame:
        &#39;&#39;&#39;
         Element-wise division operator for DataFrame
         Args:
             other: scalar numeric

         Returns: PyCylon DataFrame

         Examples
         --------
        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df / 2
               col-1  col-2  col-3
            0    0.5    2.5    4.5
            1    1.0    3.0    5.0
            2    1.5    3.5    5.5
            3    2.0    4.0    6.0
         &#39;&#39;&#39;

        return DataFrame(self._table.__truediv__(other))

    def drop(self, column_names: List[str]) -&gt; DataFrame:
        &#39;&#39;&#39;
        drop a column or list of columns from a DataFrame
        Args:
            column_names: List[str]

        Returns: PyCylon DataFrame

        Examples
        --------

        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df.drop([&#39;col-1&#39;])
               col-2  col-3
            0      5      9
            1      6     10
            2      7     11
            3      8     12
        &#39;&#39;&#39;

        return DataFrame(self._table.drop(column_names))

    def fillna(self, fill_value) -&gt; DataFrame:
        &#39;&#39;&#39;
        Fill not applicable values with a given value
        Args:
            fill_value: scalar

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0    1.0    5.0    9.0
            1    NaN    6.0   10.0
            2    3.0    NaN   11.0
            3    4.0    8.0    NaN

        &gt;&gt;&gt; df.fillna(0)
               col-1  col-2  col-3
            0      1      5      9
            1      0      6     10
            2      3      0     11
            3      4      8      0
        &#39;&#39;&#39;
        # Note: Supports numeric types only
        return DataFrame(self._table.fillna(fill_value))

    def where(self, condition: DataFrame = None, other=None) -&gt; DataFrame:
        &#39;&#39;&#39;
        Experimental version of Where operation.
        Replace values where condition is False
        Args:
            condition: bool DataFrame
            other: Scalar

        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df.where(df &gt; 2)
                col-1  col-2  col-3
            0    NaN      5      9
            1    NaN      6     10
            2    3.0      7     11
            3    4.0      8     12

        &gt;&gt;&gt; df.where(df &gt; 2, 10)
               col-1  col-2  col-3
            0     10      5      9
            1     10      6     10
            2      3      7     11
            3      4      8     12
        &#39;&#39;&#39;
        if condition is None:
            raise ValueError(&#34;Condition must be provided&#34;)
        return DataFrame(self._table.where(condition, other))

    def isnull(self) -&gt; DataFrame:
        &#39;&#39;&#39;
        Checks for null elements and returns a bool DataFrame
        Returns: PyCylon DataFrame

        Examples
        --------

        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0    1.0    5.0    9.0
            1    NaN    6.0   10.0
            2    3.0    NaN   11.0
            3    4.0    8.0    NaN

        &gt;&gt;&gt; df.isnull()
                col-1  col-2  col-3
            0  False  False  False
            1   True  False  False
            2  False   True  False
            3  False  False   True

        &#39;&#39;&#39;
        return DataFrame(self._table.isnull())

    def isna(self) -&gt; DataFrame:
        &#39;&#39;&#39;
        Check for not applicable values and returns a bool DataFrame
        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0    1.0    5.0    9.0
            1    NaN    6.0   10.0
            2    3.0    NaN   11.0
            3    4.0    8.0    NaN

        &gt;&gt;&gt; df.isna()
                col-1  col-2  col-3
            0  False  False  False
            1   True  False  False
            2  False   True  False
            3  False  False   True
        &#39;&#39;&#39;
        return DataFrame(self._table.isnull())

    def notnull(self) -&gt; DataFrame:
        &#39;&#39;&#39;
        Check the not null values and returns a bool DataFrame
        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0    1.0    5.0    9.0
            1    NaN    6.0   10.0
            2    3.0    NaN   11.0
            3    4.0    8.0    NaN

        &gt;&gt;&gt; df.notnull()
               col-1  col-2  col-3
            0   True   True   True
            1  False   True   True
            2   True  False   True
            3   True   True  False
        &#39;&#39;&#39;

        return ~self.isnull()

    def notna(self) -&gt; DataFrame:
        &#39;&#39;&#39;
        Checks for not NA values and returns a bool DataFrame
        Returns: PyCylon DataFrame

        Examples
        --------
        &gt;&gt;&gt; df
               col-1  col-2  col-3
            0    1.0    5.0    9.0
            1    NaN    6.0   10.0
            2    3.0    NaN   11.0
            3    4.0    8.0    NaN

        &gt;&gt;&gt; df.notna()
               col-1  col-2  col-3
            0   True   True   True
            1  False   True   True
            2   True  False   True
            3   True   True  False
        &#39;&#39;&#39;

        return ~self.isnull()

    def rename(self, column_names):
        &#39;&#39;&#39;
        Rename a DataFrame with a column name or column names
        Args:
            column_names: dictionary or full list of new column names

        Returns: None

        Examples
        --------
        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df.rename({&#39;col-1&#39;: &#39;col_1&#39;})
               col_1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df.rename([&#39;c1&#39;, &#39;c2&#39;, &#39;c3&#39;])
               c1  c2  c3
            0   1   5   9
            1   2   6  10
            2   3   7  11
            3   4   8  12
        &#39;&#39;&#39;
        self._table.rename(column_names)

    def add_prefix(self, prefix: str) -&gt; DataFrame:
        &#39;&#39;&#39;
        Adding a prefix to column names
        Args:
            prefix: str

        Returns: PyCylon DataFrame with prefix updated

        Examples
        --------

        &gt;&gt;&gt; df
                col-1  col-2  col-3
            0      1      5      9
            1      2      6     10
            2      3      7     11
            3      4      8     12

        &gt;&gt;&gt; df.add_prefix(&#39;old_&#39;)
               old_c1  old_c2  old_c3
            0       1       5       9
            1       2       6      10
            2       3       7      11
            3       4       8      12

        &#39;&#39;&#39;

        return DataFrame(self._table.add_prefix(prefix))

    # Indexing

    def set_index(
        self, keys, drop=True, append=False, inplace=False, verify_integrity=False
    ):
        &#34;&#34;&#34;
        Set the DataFrame index using existing columns.
        Set the DataFrame index (row labels) using one or more existing
        columns or arrays (of the correct length). The index can replace the
        existing index or expand on it.
        Parameters
        ----------
        keys : label or array-like or list of labels/arrays
            This parameter can be either a single column key, a single array of
            the same length as the calling DataFrame, or a list containing an
            arbitrary combination of column keys and arrays. Here, &#34;array&#34;
            encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and
            instances of :class:`~collections.abc.Iterator`.
        drop : bool, default True
            Delete columns to be used as the new index.
        append : bool, default False
            Whether to append columns to existing index.
        inplace : bool, default False
            If True, modifies the DataFrame in place (do not create a new object).
        verify_integrity : bool, default False
            Check the new index for duplicates. Otherwise defer the check until
            necessary. Setting to False will improve the performance of this
            method.
        Returns
        -------
        DataFrame or None
            Changed row labels or None if ``inplace=True``.
        See Also
        --------
        DataFrame.reset_index : Opposite of set_index.
        DataFrame.reindex : Change to new indices or expand indices.
        DataFrame.reindex_like : Change to same indices as other DataFrame.
        Examples
        --------
        &gt;&gt;&gt; df = pd.DataFrame({&#39;month&#39;: [1, 4, 7, 10],
        ...                    &#39;year&#39;: [2012, 2014, 2013, 2014],
        ...                    &#39;sale&#39;: [55, 40, 84, 31]})
        &gt;&gt;&gt; df
           month  year  sale
        0      1  2012    55
        1      4  2014    40
        2      7  2013    84
        3     10  2014    31
        Set the index to become the &#39;month&#39; column:
        &gt;&gt;&gt; df.set_index(&#39;month&#39;)
               year  sale
        month
        1      2012    55
        4      2014    40
        7      2013    84
        10     2014    31
        Create a MultiIndex using columns &#39;year&#39; and &#39;month&#39;:
        &gt;&gt;&gt; df.set_index([&#39;year&#39;, &#39;month&#39;])
                    sale
        year  month
        2012  1     55
        2014  4     40
        2013  7     84
        2014  10    31
        Create a MultiIndex using an Index and a column:
        &gt;&gt;&gt; df.set_index([pd.Index([1, 2, 3, 4]), &#39;year&#39;])
                 month  sale
           year
        1  2012  1      55
        2  2014  4      40
        3  2013  7      84
        4  2014  10     31
        Create a MultiIndex using two Series:
        &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
        &gt;&gt;&gt; df.set_index([s, s**2])
              month  year  sale
        1 1       1  2012    55
        2 4       4  2014    40
        3 9       7  2013    84
        4 16     10  2014    31
        &#34;&#34;&#34;
        # todo this is not a final implementation
        index_keys = []
        index_keys.extend(keys)

        if append:
            for c in self._index_columns:
                if not c in index_keys:
                    index_keys.append(c)

        if inplace:
            self._index_columns = index_keys
            self._table.set_index(index_keys, drop=drop)
            return None
        else:
            new_df = DataFrame(self._table)
            new_df._table.set_index(index_keys, drop=drop)
            new_df._index_columns = index_keys
            return new_df

    def reset_index(  # type: ignore[misc]
        self,
        level: Optional[Union[Hashable, Sequence[Hashable]]] = ...,
        drop: bool = ...,
        inplace: False = ...,
        col_level: Hashable = ...,
        col_fill=...,
    ) -&gt; DataFrame:
        # todo this is not a final implementation
        self._index_columns = []
        self._table.reset_index(drop=drop)
        return self

    # Combining / joining / merging

    def join(self, other: DataFrame, on=None, how=&#39;left&#39;, lsuffix=&#39;l&#39;, rsuffix=&#39;r&#39;,
             sort=False, algorithm=&#34;sort&#34;, env: CylonEnv = None) -&gt; DataFrame:
        &#34;&#34;&#34;
        Join columns with other DataFrame either on index or on a key
        column. Efficiently Join multiple DataFrame objects by index at once by
        passing a list.

        Parameters
        ----------
        other : DataFrame, Series with name field set, or list of DataFrame
            Index should be similar to one of the columns in this one. If a
            Series is passed, its name attribute must be set, and that will be
            used as the column name in the resulting joined DataFrame
        on : column name, tuple/list of column names, or array-like
            Column(s) in the caller to join on the index in other,
            otherwise joins index-on-index. If multiples
            columns given, the passed DataFrame must have a MultiIndex. Can
            pass an array as the join key if not already contained in the
            calling DataFrame. Like an Excel VLOOKUP operation
        how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;}, default: &#39;left&#39;
            How to handle the operation of the two objects.
            * left: use calling frame&#39;s index (or column if on is specified)
            * right: use other frame&#39;s index
            * outer: form union of calling frame&#39;s index (or column if on is
              specified) with other frame&#39;s index, and sort it
              lexicographically
            * inner: form intersection of calling frame&#39;s index (or column if
              on is specified) with other frame&#39;s index, preserving the order
              of the calling&#39;s one
        lsuffix : string
            Suffix to use from left frame&#39;s overlapping columns
        rsuffix : string
            Suffix to use from right frame&#39;s overlapping columns
        sort : boolean, default False
            Order result DataFrame lexicographically by the join key. If False,
            the order of the join key depends on the join type (how keyword)
        algorithm: {&#39;sort&#39;, &#39;hash&#39;}, default: &#39;sort&#39;
            The algorithm that should be used to perform the join between two tables.
        Notes
        -----
        on, lsuffix, and rsuffix options are not supported when passing a list
        of DataFrame objects
        Examples
        --------
        &gt;&gt;&gt; caller
            A key
        0  A0  K0
        1  A1  K1
        2  A2  K2
        3  A3  K3
        4  A4  K4
        5  A5  K5

        &gt;&gt;&gt; other
            B key
        0  B0  K0
        1  B1  K1
        2  B2  K2
        Join DataFrames using their indexes.
        &gt;&gt;&gt; caller.join(other, lsuffix=&#39;_caller&#39;, rsuffix=&#39;_other&#39;)
        &gt;&gt;&gt;     A key_caller    B key_other
            0  A0         K0   B0        K0
            1  A1         K1   B1        K1
            2  A2         K2   B2        K2
            3  A3         K3  NaN       NaN
            4  A4         K4  NaN       NaN
            5  A5         K5  NaN       NaN
        If we want to join using the key columns, we need to set key to be
        the index in both caller and other. The joined DataFrame will have
        key as its index.
        &gt;&gt;&gt; caller.set_index(&#39;key&#39;).join(other.set_index(&#39;key&#39;))
        &gt;&gt;&gt;      A    B
            key
            K0   A0   B0
            K1   A1   B1
            K2   A2   B2
            K3   A3  NaN
            K4   A4  NaN
            K5   A5  NaN
        Another option to join using the key columns is to use the on
        parameter. DataFrame.join always uses other&#39;s index but we can use any
        column in the caller. This method preserves the original caller&#39;s
        index in the result.
        &gt;&gt;&gt; caller.join(other.set_index(&#39;key&#39;), on=&#39;key&#39;)
        &gt;&gt;&gt;     A key    B
            0  A0  K0   B0
            1  A1  K1   B1
            2  A2  K2   B2
            3  A3  K3  NaN
            4  A4  K4  NaN
            5  A5  K5  NaN
        See also
        --------
        DataFrame.merge : For column(s)-on-columns(s) operations
        Returns
        -------
        joined : DataFrame
        &#34;&#34;&#34;
        left_on = on
        if left_on is None:
            left_on = self._index_columns

        right_on = other._index_columns

        if left_on is None or len(left_on) == 0:
            raise ValueError(
                &#34;The column to join from left relation is no specified. Either provide &#39;on&#39; or set indexing&#34;)

        if right_on is None or len(right_on) == 0:
            raise ValueError(
                &#34;The &#39;other&#39; relation doesn&#39;t have index columns specified.&#34;)

        if env is None:
            joined_table = self._table.join(table=other._table, join_type=how,
                                            algorithm=algorithm,
                                            left_on=left_on, right_on=right_on,
                                            left_prefix=lsuffix, right_prefix=rsuffix)
            return DataFrame(joined_table)
        else:
            # attach context
            self._change_context(env=env)
            other._change_context(env=env)

            joined_table = self._table.distributed_join(table=other._table, join_type=how,
                                                        algorithm=algorithm,
                                                        left_on=left_on, right_on=right_on,
                                                        left_prefix=lsuffix, right_prefix=rsuffix)
            return DataFrame(joined_table)

    def merge(self,
              right: DataFrame,
              how=&#34;inner&#34;,
              algorithm=&#34;sort&#34;,
              on=None,
              left_on=None,
              right_on=None,
              left_index=False,
              right_index=False,
              sort=False,
              suffixes=(&#34;_x&#34;, &#34;_y&#34;),
              copy=True,
              indicator=False,
              validate=None,
              env: CylonEnv = None) -&gt; DataFrame:
        &#34;&#34;&#34;
        Merge DataFrame with a database-style join.
        The join is done on columns or indexes. If joining columns on
        columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes
        on indexes or indexes on a column or columns, the index will be passed on.
        When performing a cross merge, no column specifications to merge on are
        allowed.

        Parameters
        ----------
        right : DataFrame or named Series
            Object to merge with.
        how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;, &#39;cross(Unsupported)&#39;}, default &#39;inner&#39;
            Type of merge to be performed.
            * left: use only keys from left frame, similar to a SQL left outer join;
            preserve key order.
            * right: use only keys from right frame, similar to a SQL right outer join;
            preserve key order.
            * outer: use union of keys from both frames, similar to a SQL full outer
            join; sort keys lexicographically.
            * inner: use intersection of keys from both frames, similar to a SQL inner
            join; preserve the order of the left keys.
            * cross: creates the cartesian product from both frames, preserves the order
            of the left keys.
            .. versionadded:: 1.2.0
        on : label or list
            Column or index level names to join on. These must be found in both
            DataFrames. If `on` is None and not merging on indexes then this defaults
            to the intersection of the columns in both DataFrames.
        left_on : label or list, or array-like
            Column or index level names to join on in the left DataFrame. Can also
            be an array or list of arrays of the length of the left DataFrame.
            These arrays are treated as if they are columns.
        right_on : label or list, or array-like
            Column or index level names to join on in the right DataFrame. Can also
            be an array or list of arrays of the length of the right DataFrame.
            These arrays are treated as if they are columns.
        left_index : bool, default False
            Use the index from the left DataFrame as the join key(s). If it is a
            MultiIndex, the number of keys in the other DataFrame (either the index
            or a number of columns) must match the number of levels.
        right_index : bool, default False
            Use the index from the right DataFrame as the join key. Same caveats as
            left_index.
        sort(Unsupported) : bool, default False
            Sort the join keys lexicographically in the result DataFrame. If False,
            the order of the join keys depends on the join type (how keyword).
        suffixes : list-like, default is (&#34;_x&#34;, &#34;_y&#34;)
            A length-2 sequence where each element is optionally a string
            indicating the suffix to add to overlapping column names in
            `left` and `right` respectively. Pass a value of `None` instead
            of a string to indicate that the column name from `left` or
            `right` should be left as-is, with no suffix. At least one of the
            values must not be None.
        copy(Unsupported) : bool, default True
            If False, avoid copy if possible.
        indicator(Unsupported) : bool or str, default False
            If True, adds a column to the output DataFrame called &#34;_merge&#34; with
            information on the source of each row. The column can be given a different
            name by providing a string argument. The column will have a Categorical
            type with the value of &#34;left_only&#34; for observations whose merge key only
            appears in the left DataFrame, &#34;right_only&#34; for observations
            whose merge key only appears in the right DataFrame, and &#34;both&#34;
            if the observation&#39;s merge key is found in both DataFrames.
        validate(Unsupported) : str, optional
            If specified, checks if merge is of specified type.
            * &#34;one_to_one&#34; or &#34;1:1&#34;: check if merge keys are unique in both
            left and right datasets.
            * &#34;one_to_many&#34; or &#34;1:m&#34;: check if merge keys are unique in left
            dataset.
            * &#34;many_to_one&#34; or &#34;m:1&#34;: check if merge keys are unique in right
            dataset.
            * &#34;many_to_many&#34; or &#34;m:m&#34;: allowed, but does not result in checks.
        Returns
        -------
        DataFrame
            A DataFrame of the two merged objects.
        See Also
        --------
        merge_ordered : Merge with optional filling/interpolation.
        merge_asof : Merge on nearest keys.
        DataFrame.join : Similar method using indices.
        Notes
        -----
        Support for specifying index levels as the `on`, `left_on`, and
        `right_on` parameters was added in version 0.23.0
        Support for merging named Series objects was added in version 0.24.0
        Examples
        --------
        &gt;&gt;&gt; df1 = DataFrame({&#39;lkey&#39;: [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;],
        ...                     &#39;value&#39;: [1, 2, 3, 5]})
        &gt;&gt;&gt; df2 = DataFrame({&#39;rkey&#39;: [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;],
        ...                     &#39;value&#39;: [5, 6, 7, 8]})
        &gt;&gt;&gt; df1
            lkey value
        0   foo      1
        1   bar      2
        2   baz      3
        3   foo      5
        &gt;&gt;&gt; df2
            rkey value
        0   foo      5
        1   bar      6
        2   baz      7
        3   foo      8

        Merge df1 and df2 on the lkey and rkey columns. The value columns have
        the default suffixes, _x and _y, appended.

        &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;)
        lkey  value_x rkey  value_y
        0  foo        1  foo        5
        1  foo        1  foo        8
        2  foo        5  foo        5
        3  foo        5  foo        8
        4  bar        2  bar        6
        5  baz        3  baz        7

        Merge DataFrames df1 and df2 with specified left and right suffixes
        appended to any overlapping columns.

        &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;,
        ...           suffixes=(&#39;_left&#39;, &#39;_right&#39;))
        lkey  value_left rkey  value_right
        0  foo           1  foo            5
        1  foo           1  foo            8
        2  foo           5  foo            5
        3  foo           5  foo            8
        4  bar           2  bar            6
        5  baz           3  baz            7

        Merge DataFrames df1 and df2, but raise an exception if the DataFrames have
        any overlapping columns.

        &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;, suffixes=(False, False))
        Traceback (most recent call last):
        ...
        ValueError: columns overlap but no suffix specified:
            Index([&#39;value&#39;], dtype=&#39;object&#39;)

        &gt;&gt;&gt; df1 = DataFrame({&#39;a&#39;: [&#39;foo&#39;, &#39;bar&#39;], &#39;b&#39;: [1, 2]})
        &gt;&gt;&gt; df2 = DataFrame({&#39;a&#39;: [&#39;foo&#39;, &#39;baz&#39;], &#39;c&#39;: [3, 4]})
        &gt;&gt;&gt; df1
            a  b
        0   foo  1
        1   bar  2

        &gt;&gt;&gt; df2
            a  c
        0   foo  3
        1   baz  4

        &gt;&gt;&gt; df1.merge(df2, how=&#39;inner&#39;, on=&#39;a&#39;)
            a  b  c
        0   foo  1  3

        &gt;&gt;&gt; df1.merge(df2, how=&#39;left&#39;, on=&#39;a&#39;)
            a  b  c
        0   foo  1  3.0
        1   bar  2  NaN

        &gt;&gt;&gt; df1 = DataFrame({&#39;left&#39;: [&#39;foo&#39;, &#39;bar&#39;]})
        &gt;&gt;&gt; df2 = DataFrame({&#39;right&#39;: [7, 8]})

        &gt;&gt;&gt; df1
            left
        0   foo
        1   bar

        &gt;&gt;&gt; df2
            right
        0   7
        1   8

        &gt;&gt;&gt; df1.merge(df2, how=&#39;cross&#39;)
        left  right
        0   foo      7
        1   foo      8
        2   bar      7
        3   bar      8
        &#34;&#34;&#34;
        if not on is None:
            left_on = on
            right_on = on

        if left_index:
            left_on = self._index_columns

        if right_index:
            right_on = right._index_columns

        if left_on is None or right_on is None:
            raise ValueError(&#34;Columns to merge is not specified. Expected on or left_index/right_index.&#34;
                             &#34;Make sure dataframes has specified index columns if using left_index/right_index&#34;)

        if env is None:
            joined_table = self._table.join(table=right._table, join_type=how,
                                            algorithm=algorithm,
                                            left_on=left_on, right_on=right_on,
                                            left_prefix=suffixes[0], right_prefix=suffixes[1])
            return DataFrame(joined_table)
        else:
            self._change_context(env)
            right._change_context(env)
            joined_table = self._table.distributed_join(table=right._table, join_type=how,
                                                        algorithm=algorithm,
                                                        left_on=left_on, right_on=right_on,
                                                        left_prefix=suffixes[0], right_prefix=suffixes[1])
            return DataFrame(joined_table)

    @staticmethod
    def concat(
        objs: Union[Iterable[&#34;DataFrame&#34;]],
        axis=0,
        join=&#34;outer&#34;,
        ignore_index: bool = False,
        keys=None,
        levels=None,
        names=None,
        verify_integrity: bool = False,
        sort: bool = False,
        copy: bool = True,
        env: CylonEnv = None
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Concatenate DataFrames along a particular axis with optional set logic
        along the other axes.
        Can also add a layer of hierarchical indexing on the concatenation axis,
        which may be useful if the labels are the same (or overlapping) on
        the passed axis number.

        Cylon currently support concat along axis=0, for DataFrames having the same schema(Union). 

        Parameters
        ----------
        objs : a sequence or mapping of Series or DataFrame objects
            If a mapping is passed, the sorted keys will be used as the `keys`
            argument, unless it is passed, in which case the values will be
            selected (see below). Any None objects will be dropped silently unless
            they are all None in which case a ValueError will be raised.
        axis : {0/&#39;index&#39;, 1/&#39;columns&#39; (Unsupported)}, default 0
            The axis to concatenate along.
        join(Unsupported) : {&#39;inner&#39;, &#39;outer&#39;}, default &#39;outer&#39;
            How to handle indexes on other axis (or axes).
        ignore_index(Unsupported) : bool, default False
            If True, do not use the index values along the concatenation axis. The
            resulting axis will be labeled 0, ..., n - 1. This is useful if you are
            concatenating objects where the concatenation axis does not have
            meaningful indexing information. Note the index values on the other
            axes are still respected in the join.
        keys(Unsupported) : sequence, default None
            If multiple levels passed, should contain tuples. Construct
            hierarchical index using the passed keys as the outermost level.
        levels(Unsupported) : list of sequences, default None
            Specific levels (unique values) to use for constructing a
            MultiIndex. Otherwise they will be inferred from the keys.
        names(Unsupported) : list, default None
            Names for the levels in the resulting hierarchical index.
        verify_integrity(Unsupported) : bool, default False
            Check whether the new concatenated axis contains duplicates. This can
            be very expensive relative to the actual data concatenation.
        sort(Unsupported) : bool, default False
            Sort non-concatenation axis if it is not already aligned when `join`
            is &#39;outer&#39;.
            This has no effect when ``join=&#39;inner&#39;``, which already preserves
            the order of the non-concatenation axis.
            .. versionchanged:: 1.0.0
            Changed to not sort by default.
        copy(Unsupported) : bool, default True
            If False, do not copy data unnecessarily.
        Returns
        -------
        object, type of objs
            When concatenating along
            the columns (axis=1) or rows (axis=0), a ``DataFrame`` is returned.

        Examples
        --------

        Combine two ``DataFrame`` objects with identical columns.

        &gt;&gt;&gt; df1 = DataFrame([[&#39;a&#39;, 1], [&#39;b&#39;, 2]],
        ...                    columns=[&#39;letter&#39;, &#39;number&#39;])
        &gt;&gt;&gt; df1
        letter  number
        0      a       1
        1      b       2
        &gt;&gt;&gt; df2 = DataFrame([[&#39;c&#39;, 3], [&#39;d&#39;, 4]],
        ...                    columns=[&#39;letter&#39;, &#39;number&#39;])
        &gt;&gt;&gt; df2
        letter  number
        0      c       3
        1      d       4
        &gt;&gt;&gt; DataFrame.concat([df1, df2])
        letter  number
        0      a       1
        1      b       2
        0      c       3
        1      d       4

        (Unsupported) Combine ``DataFrame`` objects with overlapping columns
        and return everything. Columns outside the intersection will
        be filled with ``NaN`` values.

        &gt;&gt;&gt; df3 = DataFrame([[&#39;c&#39;, 3, &#39;cat&#39;], [&#39;d&#39;, 4, &#39;dog&#39;]],
        ...                    columns=[&#39;letter&#39;, &#39;number&#39;, &#39;animal&#39;])
        &gt;&gt;&gt; df3
        letter  number animal
        0      c       3    cat
        1      d       4    dog
        &gt;&gt;&gt; DataFrame.concat([df1, df3], sort=False)
        letter  number animal
        0      a       1    NaN
        1      b       2    NaN
        0      c       3    cat
        1      d       4    dog

        (Unsupported) Combine ``DataFrame`` objects with overlapping columns
        and return only those that are shared by passing ``inner`` to
        the ``join`` keyword argument.

        &gt;&gt;&gt; DataFrame.concat([df1, df3], join=&#34;inner&#34;)
        letter  number
        0      a       1
        1      b       2
        0      c       3
        1      d       4

        (Unsupported) Combine ``DataFrame`` objects horizontally along the x axis by
        passing in ``axis=1``.

        &gt;&gt;&gt; df4 = DataFrame([[&#39;bird&#39;, &#39;polly&#39;], [&#39;monkey&#39;, &#39;george&#39;]],
        ...                    columns=[&#39;animal&#39;, &#39;name&#39;])
        &gt;&gt;&gt; DataFrame.concat([df1, df4], axis=1)

        letter  number  animal    name
        0      a       1    bird   polly
        1      b       2  monkey  george

        (Unsupported) Prevent the result from including duplicate index values with the
        ``verify_integrity`` option.

        &gt;&gt;&gt; df5 = DataFrame([1], index=[&#39;a&#39;])
        &gt;&gt;&gt; df5
        0
        a  1
        &gt;&gt;&gt; df6 = DataFrame([2], index=[&#39;a&#39;])
        &gt;&gt;&gt; df6
        0
        a  2
        &gt;&gt;&gt; DataFrame.concat([df5, df6], verify_integrity=True)
        Traceback (most recent call last):
            ...
        ValueError: Indexes have overlapping values: [&#39;a&#39;]
        &#34;&#34;&#34;

        if len(objs) == 0:
            raise &#34;objs can&#39;t be empty&#34;

        if axis == 0:
            if env is None:
                current_table = objs[0]._table
                for i in range(1, len(objs)):
                    current_table = current_table.union(objs[i]._table)

                return DataFrame(current_table)
            else:
                # todo not optimum for distributed
                current_table = objs[0]._change_context(env)._table
                for i in range(1, len(objs)):
                    current_table = current_table.union(
                        objs[i]._change_context(env)._table)

                return DataFrame(current_table)
        else:
            raise &#34;Unsupported operation&#34;

    def drop_duplicates(
        self,
        subset: Optional[Union[Hashable, Sequence[Hashable]]] = None,
        keep: Union[str, bool] = &#34;first&#34;,
        inplace: bool = False,
        ignore_index: bool = False,
        env: CylonEnv = None
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Return DataFrame with duplicate rows removed.
        Considering certain columns is optional. Indexes, including time indexes
        are ignored.
        Parameters
        ----------
        subset : column label or sequence of labels, optional
            Only consider certain columns for identifying duplicates, by
            default use all of the columns.
        keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
            Determines which duplicates (if any) to keep.
            - ``first`` : Drop duplicates except for the first occurrence.
            - ``last`` : Drop duplicates except for the last occurrence.
            - False (Unsupported): Drop all duplicates.
        inplace : bool, default False
            Whether to drop duplicates in place or to return a copy.
        ignore_index (Unsupported) : bool, default False
            If True, the resulting axis will be labeled 0, 1, …, n - 1.
            .. versionadded:: 1.0.0
        Returns
        -------
        DataFrame or None
            DataFrame with duplicates removed or None if ``inplace=True``(Unsupported).
        See Also
        --------
        DataFrame.value_counts: Count unique combinations of columns.
        Examples
        --------
        Consider dataset containing ramen rating.
        &gt;&gt;&gt; df = DataFrame({
        ...     &#39;brand&#39;: [&#39;Yum Yum&#39;, &#39;Yum Yum&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;],
        ...     &#39;style&#39;: [&#39;cup&#39;, &#39;cup&#39;, &#39;cup&#39;, &#39;pack&#39;, &#39;pack&#39;],
        ...     &#39;rating&#39;: [4, 4, 3.5, 15, 5]
        ... })
        &gt;&gt;&gt; df
            brand style  rating
        0  Yum Yum   cup     4.0
        1  Yum Yum   cup     4.0
        2  Indomie   cup     3.5
        3  Indomie  pack    15.0
        4  Indomie  pack     5.0
        By default, it removes duplicate rows based on all columns.
        &gt;&gt;&gt; df.drop_duplicates()
            brand style  rating
        0  Yum Yum   cup     4.0
        2  Indomie   cup     3.5
        3  Indomie  pack    15.0
        4  Indomie  pack     5.0
        To remove duplicates on specific column(s), use ``subset``.
        &gt;&gt;&gt; df.drop_duplicates(subset=[&#39;brand&#39;])
            brand style  rating
        0  Yum Yum   cup     4.0
        2  Indomie   cup     3.5
        To remove duplicates and keep last occurrences, use ``keep``.
        &gt;&gt;&gt; df.drop_duplicates(subset=[&#39;brand&#39;, &#39;style&#39;], keep=&#39;last&#39;)
            brand style  rating
        1  Yum Yum   cup     4.0
        2  Indomie   cup     3.5
        4  Indomie  pack     5.0
        &#34;&#34;&#34;
        if env is None:
            return DataFrame(self._table.unique(columns=subset, keep=keep, inplace=inplace))
        else:
            return DataFrame(self._change_context(env)._table.distributed_unique(columns=subset, inplace=inplace))

    def sort_values(
        self,
        by,
        axis=0,
        ascending=True,
        inplace=False,
        kind=&#34;quicksort&#34;,
        na_position=&#34;last&#34;,
        ignore_index=False,
        key=None,
        env: CylonEnv = None
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Sort by the values along either axis.
        Parameters
        ----------

        axis : %(axes_single_arg)s, default 0
             Axis to be sorted.
        ascending : bool or list of bool, default True
             Sort ascending vs. descending. Specify list for multiple sort
             orders.  If this is a list of bools, must match the length of
             the by.
        inplace(Unsupported) : bool, default False
             If True, perform operation in-place.
        kind(Unsupported) : {&#39;quicksort&#39;, &#39;mergesort&#39;, &#39;heapsort&#39;, &#39;stable&#39;}, default &#39;quicksort&#39;
             Choice of sorting algorithm. See also :func:`numpy.sort` for more
             information. `mergesort` and `stable` are the only stable algorithms. For
             DataFrames, this option is only applied when sorting on a single
             column or label.
        na_position(Unsupported) : {&#39;first&#39;, &#39;last&#39;}, default &#39;last&#39;
             Puts NaNs at the beginning if `first`; `last` puts NaNs at the
             end.
        ignore_index(Unsupported) : bool, default False
             If True, the resulting axis will be labeled 0, 1, …, n - 1.
             .. versionadded:: 1.0.0
        key(Unsupported) : callable, optional
            Apply the key function to the values
            before sorting. This is similar to the `key` argument in the
            builtin :meth:`sorted` function, with the notable difference that
            this `key` function should be *vectorized*. It should expect a
            ``Series`` and return a Series with the same shape as the input.
            It will be applied to each column in `by` independently.
            .. versionadded:: 1.1.0
        Returns
        -------
        DataFrame or None
            DataFrame with sorted values or None if ``inplace=True``.
        See Also
        --------
        DataFrame.sort_index : Sort a DataFrame by the index.
        Series.sort_values : Similar method for a Series.
        Examples
        --------
        &gt;&gt;&gt; df = DataFrame({
        ...     &#39;col1&#39;: [&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, np.nan, &#39;D&#39;, &#39;C&#39;],
        ...     &#39;col2&#39;: [2, 1, 9, 8, 7, 4],
        ...     &#39;col3&#39;: [0, 1, 9, 4, 2, 3],
        ...     &#39;col4&#39;: [&#39;a&#39;, &#39;B&#39;, &#39;c&#39;, &#39;D&#39;, &#39;e&#39;, &#39;F&#39;]
        ... })
        &gt;&gt;&gt; df
          col1  col2  col3 col4
        0    A     2     0    a
        1    A     1     1    B
        2    B     9     9    c
        3  NaN     8     4    D
        4    D     7     2    e
        5    C     4     3    F
        Sort by col1
        &gt;&gt;&gt; df.sort_values(by=[&#39;col1&#39;])
          col1  col2  col3 col4
        0    A     2     0    a
        1    A     1     1    B
        2    B     9     9    c
        5    C     4     3    F
        4    D     7     2    e
        3  NaN     8     4    D
        Sort by multiple columns
        &gt;&gt;&gt; df.sort_values(by=[&#39;col1&#39;, &#39;col2&#39;])
          col1  col2  col3 col4
        1    A     1     1    B
        0    A     2     0    a
        2    B     9     9    c
        5    C     4     3    F
        4    D     7     2    e
        3  NaN     8     4    D
        Sort Descending
        &gt;&gt;&gt; df.sort_values(by=&#39;col1&#39;, ascending=False)
          col1  col2  col3 col4
        4    D     7     2    e
        5    C     4     3    F
        2    B     9     9    c
        0    A     2     0    a
        1    A     1     1    B
        3  NaN     8     4    D
        &#34;&#34;&#34;
        if env is None:
            return DataFrame(self._table.sort(order_by=by, ascending=ascending))
        else:
            return DataFrame(self._change_context(env)._table.distributed_sort(order_by=by, ascending=ascending))

    def groupby(self, by: Union([int, str, List]), env: CylonEnv = None) -&gt; GroupByDataFrame:
        &#34;&#34;&#34;
        A groupby operation involves some combination of splitting the object, applying a function, and combining the results. 
        This can be used to group large amounts of data and compute operations on these groups.

        Parameters
        ----------

        by : str, int or a list of str, int.  
            List of column(s) used for grouping.
        
        Returns
        -------
        GroupByDataFrame

        Examples
        -------

        &gt;&gt;&gt; df1 = DataFrame([[0, 0, 1, 1], [1, 10, 1, 5], [10, 20, 30, 40]])
        &gt;&gt;&gt; df1


        &gt;&gt;&gt; df3 = df1.groupby(by=0).agg({&#34;1&#34;: &#34;sum&#34;, &#34;2&#34;: &#34;min&#34;})
        &gt;&gt;&gt; df3
        0  sum_1  min_2
        0  0     11     10
        1  1      6     30

        &gt;&gt;&gt; df4 = df1.groupby(by=0).min()
        &gt;&gt;&gt; df4
        0  min_2  min_1
        0  0     10      1
        1  1     30      1

        &gt;&gt;&gt; df5 = df1.groupby(by=[0, 1]).max()
        &gt;&gt;&gt; df5
        0   1  max_2
        0  0   1     10
        1  0  10     20
        2  1   1     30
        3  1   5     40
        &#34;&#34;&#34;
        by_list = []
        if isinstance(by, int):
            by_list.append(self.columns[by])
        elif isinstance(by, str):
            if by not in self.columns:
                raise ValueError(
                    str+&#34; is not a column of this table. Expected one of &#34;+str(by))
            by_list.append(by)
        elif isinstance(by, list):
            if len(by) == 0:
                raise ValueError(&#34;Group by columns should be specified.&#34;)

            for b in by:
                if isinstance(b, str):
                    by_list.append(b)
                elif isinstance(b, int):
                    by_list.append(self.columns[b])
                else:
                    raise ValueError(
                        &#34;Unsupported column specification. Expected column index or name&#34;)
        else:
            raise ValueError(&#34;Unknown value for by&#34;)
        if env is None:
            return GroupByDataFrame(self, by_list)
        else:
            return GroupByDataFrame(self._change_context(env), by_list)</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="frame.DataFrame.concat"><code class="name flex">
<span>def <span class="ident">concat</span></span>(<span>objs: "Union[Iterable['<a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a>']]", axis=0, join='outer', ignore_index: bool = False, keys=None, levels=None, names=None, verify_integrity: bool = False, sort: bool = False, copy: bool = True, env: <a title="frame.CylonEnv" href="#frame.CylonEnv">CylonEnv</a> = None) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Concatenate DataFrames along a particular axis with optional set logic
along the other axes.
Can also add a layer of hierarchical indexing on the concatenation axis,
which may be useful if the labels are the same (or overlapping) on
the passed axis number.</p>
<p>Cylon currently support concat along axis=0, for DataFrames having the same schema(Union). </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>objs</code></strong> :&ensp;<code>a sequence</code> or <code>mapping</code> of <code>Series</code> or <code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a> objects</code></dt>
<dd>If a mapping is passed, the sorted keys will be used as the <code>keys</code>
argument, unless it is passed, in which case the values will be
selected (see below). Any None objects will be dropped silently unless
they are all None in which case a ValueError will be raised.</dd>
<dt><strong><code>axis</code></strong> :&ensp;<code>{0/'index', 1/'columns' (Unsupported)}</code>, default <code>0</code></dt>
<dd>The axis to concatenate along.</dd>
</dl>
<p>join(Unsupported) : {'inner', 'outer'}, default 'outer'
How to handle indexes on other axis (or axes).
ignore_index(Unsupported) : bool, default False
If True, do not use the index values along the concatenation axis. The
resulting axis will be labeled 0, &hellip;, n - 1. This is useful if you are
concatenating objects where the concatenation axis does not have
meaningful indexing information. Note the index values on the other
axes are still respected in the join.
keys(Unsupported) : sequence, default None
If multiple levels passed, should contain tuples. Construct
hierarchical index using the passed keys as the outermost level.
levels(Unsupported) : list of sequences, default None
Specific levels (unique values) to use for constructing a
MultiIndex. Otherwise they will be inferred from the keys.
names(Unsupported) : list, default None
Names for the levels in the resulting hierarchical index.
verify_integrity(Unsupported) : bool, default False
Check whether the new concatenated axis contains duplicates. This can
be very expensive relative to the actual data concatenation.
sort(Unsupported) : bool, default False
Sort non-concatenation axis if it is not already aligned when <code>join</code>
is 'outer'.
This has no effect when <code>join='inner'</code>, which already preserves
the order of the non-concatenation axis.
!!! versionchanged "Changed in version:&ensp;1.0.0"</p>
<pre><code>Changed to not sort by default.
</code></pre>
<p>copy(Unsupported) : bool, default True
If False, do not copy data unnecessarily.
Returns</p>
<hr>
<dl>
<dt><code>object, type</code> of <code>objs</code></dt>
<dd>When concatenating along
the columns (axis=1) or rows (axis=0), a <code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code> is returned.</dd>
</dl>
<h2 id="examples">Examples</h2>
<p>Combine two <code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code> objects with identical columns.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1 = DataFrame([['a', 1], ['b', 2]],
...                    columns=['letter', 'number'])
&gt;&gt;&gt; df1
letter  number
0      a       1
1      b       2
&gt;&gt;&gt; df2 = DataFrame([['c', 3], ['d', 4]],
...                    columns=['letter', 'number'])
&gt;&gt;&gt; df2
letter  number
0      c       3
1      d       4
&gt;&gt;&gt; DataFrame.concat([df1, df2])
letter  number
0      a       1
1      b       2
0      c       3
1      d       4
</code></pre>
<p>(Unsupported) Combine <code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code> objects with overlapping columns
and return everything. Columns outside the intersection will
be filled with <code>NaN</code> values.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df3 = DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],
...                    columns=['letter', 'number', 'animal'])
&gt;&gt;&gt; df3
letter  number animal
0      c       3    cat
1      d       4    dog
&gt;&gt;&gt; DataFrame.concat([df1, df3], sort=False)
letter  number animal
0      a       1    NaN
1      b       2    NaN
0      c       3    cat
1      d       4    dog
</code></pre>
<p>(Unsupported) Combine <code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code> objects with overlapping columns
and return only those that are shared by passing <code>inner</code> to
the <code>join</code> keyword argument.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; DataFrame.concat([df1, df3], join=&quot;inner&quot;)
letter  number
0      a       1
1      b       2
0      c       3
1      d       4
</code></pre>
<p>(Unsupported) Combine <code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code> objects horizontally along the x axis by
passing in <code>axis=1</code>.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df4 = DataFrame([['bird', 'polly'], ['monkey', 'george']],
...                    columns=['animal', 'name'])
&gt;&gt;&gt; DataFrame.concat([df1, df4], axis=1)
</code></pre>
<p>letter
number
animal
name
0
a
1
bird
polly
1
b
2
monkey
george</p>
<p>(Unsupported) Prevent the result from including duplicate index values with the
<code>verify_integrity</code> option.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df5 = DataFrame([1], index=['a'])
&gt;&gt;&gt; df5
0
a  1
&gt;&gt;&gt; df6 = DataFrame([2], index=['a'])
&gt;&gt;&gt; df6
0
a  2
&gt;&gt;&gt; DataFrame.concat([df5, df6], verify_integrity=True)
Traceback (most recent call last):
    ...
ValueError: Indexes have overlapping values: ['a']
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def concat(
    objs: Union[Iterable[&#34;DataFrame&#34;]],
    axis=0,
    join=&#34;outer&#34;,
    ignore_index: bool = False,
    keys=None,
    levels=None,
    names=None,
    verify_integrity: bool = False,
    sort: bool = False,
    copy: bool = True,
    env: CylonEnv = None
) -&gt; DataFrame:
    &#34;&#34;&#34;
    Concatenate DataFrames along a particular axis with optional set logic
    along the other axes.
    Can also add a layer of hierarchical indexing on the concatenation axis,
    which may be useful if the labels are the same (or overlapping) on
    the passed axis number.

    Cylon currently support concat along axis=0, for DataFrames having the same schema(Union). 

    Parameters
    ----------
    objs : a sequence or mapping of Series or DataFrame objects
        If a mapping is passed, the sorted keys will be used as the `keys`
        argument, unless it is passed, in which case the values will be
        selected (see below). Any None objects will be dropped silently unless
        they are all None in which case a ValueError will be raised.
    axis : {0/&#39;index&#39;, 1/&#39;columns&#39; (Unsupported)}, default 0
        The axis to concatenate along.
    join(Unsupported) : {&#39;inner&#39;, &#39;outer&#39;}, default &#39;outer&#39;
        How to handle indexes on other axis (or axes).
    ignore_index(Unsupported) : bool, default False
        If True, do not use the index values along the concatenation axis. The
        resulting axis will be labeled 0, ..., n - 1. This is useful if you are
        concatenating objects where the concatenation axis does not have
        meaningful indexing information. Note the index values on the other
        axes are still respected in the join.
    keys(Unsupported) : sequence, default None
        If multiple levels passed, should contain tuples. Construct
        hierarchical index using the passed keys as the outermost level.
    levels(Unsupported) : list of sequences, default None
        Specific levels (unique values) to use for constructing a
        MultiIndex. Otherwise they will be inferred from the keys.
    names(Unsupported) : list, default None
        Names for the levels in the resulting hierarchical index.
    verify_integrity(Unsupported) : bool, default False
        Check whether the new concatenated axis contains duplicates. This can
        be very expensive relative to the actual data concatenation.
    sort(Unsupported) : bool, default False
        Sort non-concatenation axis if it is not already aligned when `join`
        is &#39;outer&#39;.
        This has no effect when ``join=&#39;inner&#39;``, which already preserves
        the order of the non-concatenation axis.
        .. versionchanged:: 1.0.0
        Changed to not sort by default.
    copy(Unsupported) : bool, default True
        If False, do not copy data unnecessarily.
    Returns
    -------
    object, type of objs
        When concatenating along
        the columns (axis=1) or rows (axis=0), a ``DataFrame`` is returned.

    Examples
    --------

    Combine two ``DataFrame`` objects with identical columns.

    &gt;&gt;&gt; df1 = DataFrame([[&#39;a&#39;, 1], [&#39;b&#39;, 2]],
    ...                    columns=[&#39;letter&#39;, &#39;number&#39;])
    &gt;&gt;&gt; df1
    letter  number
    0      a       1
    1      b       2
    &gt;&gt;&gt; df2 = DataFrame([[&#39;c&#39;, 3], [&#39;d&#39;, 4]],
    ...                    columns=[&#39;letter&#39;, &#39;number&#39;])
    &gt;&gt;&gt; df2
    letter  number
    0      c       3
    1      d       4
    &gt;&gt;&gt; DataFrame.concat([df1, df2])
    letter  number
    0      a       1
    1      b       2
    0      c       3
    1      d       4

    (Unsupported) Combine ``DataFrame`` objects with overlapping columns
    and return everything. Columns outside the intersection will
    be filled with ``NaN`` values.

    &gt;&gt;&gt; df3 = DataFrame([[&#39;c&#39;, 3, &#39;cat&#39;], [&#39;d&#39;, 4, &#39;dog&#39;]],
    ...                    columns=[&#39;letter&#39;, &#39;number&#39;, &#39;animal&#39;])
    &gt;&gt;&gt; df3
    letter  number animal
    0      c       3    cat
    1      d       4    dog
    &gt;&gt;&gt; DataFrame.concat([df1, df3], sort=False)
    letter  number animal
    0      a       1    NaN
    1      b       2    NaN
    0      c       3    cat
    1      d       4    dog

    (Unsupported) Combine ``DataFrame`` objects with overlapping columns
    and return only those that are shared by passing ``inner`` to
    the ``join`` keyword argument.

    &gt;&gt;&gt; DataFrame.concat([df1, df3], join=&#34;inner&#34;)
    letter  number
    0      a       1
    1      b       2
    0      c       3
    1      d       4

    (Unsupported) Combine ``DataFrame`` objects horizontally along the x axis by
    passing in ``axis=1``.

    &gt;&gt;&gt; df4 = DataFrame([[&#39;bird&#39;, &#39;polly&#39;], [&#39;monkey&#39;, &#39;george&#39;]],
    ...                    columns=[&#39;animal&#39;, &#39;name&#39;])
    &gt;&gt;&gt; DataFrame.concat([df1, df4], axis=1)

    letter  number  animal    name
    0      a       1    bird   polly
    1      b       2  monkey  george

    (Unsupported) Prevent the result from including duplicate index values with the
    ``verify_integrity`` option.

    &gt;&gt;&gt; df5 = DataFrame([1], index=[&#39;a&#39;])
    &gt;&gt;&gt; df5
    0
    a  1
    &gt;&gt;&gt; df6 = DataFrame([2], index=[&#39;a&#39;])
    &gt;&gt;&gt; df6
    0
    a  2
    &gt;&gt;&gt; DataFrame.concat([df5, df6], verify_integrity=True)
    Traceback (most recent call last):
        ...
    ValueError: Indexes have overlapping values: [&#39;a&#39;]
    &#34;&#34;&#34;

    if len(objs) == 0:
        raise &#34;objs can&#39;t be empty&#34;

    if axis == 0:
        if env is None:
            current_table = objs[0]._table
            for i in range(1, len(objs)):
                current_table = current_table.union(objs[i]._table)

            return DataFrame(current_table)
        else:
            # todo not optimum for distributed
            current_table = objs[0]._change_context(env)._table
            for i in range(1, len(objs)):
                current_table = current_table.union(
                    objs[i]._change_context(env)._table)

            return DataFrame(current_table)
    else:
        raise &#34;Unsupported operation&#34;</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="frame.DataFrame.columns"><code class="name">var <span class="ident">columns</span> : List[str]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def columns(self) -&gt; List[str]:
    return self._table.column_names</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.shape"><code class="name">var <span class="ident">shape</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def shape(self):
    return self._table.shape</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="frame.DataFrame.add_prefix"><code class="name flex">
<span>def <span class="ident">add_prefix</span></span>(<span>self, prefix: str) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Adding a prefix to column names</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>prefix</code></strong></dt>
<dd>str</dd>
</dl>
<p>Returns: PyCylon DataFrame with prefix updated</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df
        col-1  col-2  col-3
    0      1      5      9
    1      2      6     10
    2      3      7     11
    3      4      8     12
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.add_prefix('old_')
       old_c1  old_c2  old_c3
    0       1       5       9
    1       2       6      10
    2       3       7      11
    3       4       8      12
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_prefix(self, prefix: str) -&gt; DataFrame:
    &#39;&#39;&#39;
    Adding a prefix to column names
    Args:
        prefix: str

    Returns: PyCylon DataFrame with prefix updated

    Examples
    --------

    &gt;&gt;&gt; df
            col-1  col-2  col-3
        0      1      5      9
        1      2      6     10
        2      3      7     11
        3      4      8     12

    &gt;&gt;&gt; df.add_prefix(&#39;old_&#39;)
           old_c1  old_c2  old_c3
        0       1       5       9
        1       2       6      10
        2       3       7      11
        3       4       8      12

    &#39;&#39;&#39;

    return DataFrame(self._table.add_prefix(prefix))</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.drop"><code class="name flex">
<span>def <span class="ident">drop</span></span>(<span>self, column_names: List[str]) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>drop a column or list of columns from a DataFrame</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>column_names</code></strong></dt>
<dd>List[str]</dd>
</dl>
<p>Returns: PyCylon DataFrame</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df
        col-1  col-2  col-3
    0      1      5      9
    1      2      6     10
    2      3      7     11
    3      4      8     12
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.drop(['col-1'])
       col-2  col-3
    0      5      9
    1      6     10
    2      7     11
    3      8     12
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drop(self, column_names: List[str]) -&gt; DataFrame:
    &#39;&#39;&#39;
    drop a column or list of columns from a DataFrame
    Args:
        column_names: List[str]

    Returns: PyCylon DataFrame

    Examples
    --------

    &gt;&gt;&gt; df
            col-1  col-2  col-3
        0      1      5      9
        1      2      6     10
        2      3      7     11
        3      4      8     12

    &gt;&gt;&gt; df.drop([&#39;col-1&#39;])
           col-2  col-3
        0      5      9
        1      6     10
        2      7     11
        3      8     12
    &#39;&#39;&#39;

    return DataFrame(self._table.drop(column_names))</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.drop_duplicates"><code class="name flex">
<span>def <span class="ident">drop_duplicates</span></span>(<span>self, subset: Optional[Union[Hashable, Sequence[Hashable]]] = None, keep: Union[str, bool] = 'first', inplace: bool = False, ignore_index: bool = False, env: <a title="frame.CylonEnv" href="#frame.CylonEnv">CylonEnv</a> = None) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Return DataFrame with duplicate rows removed.
Considering certain columns is optional. Indexes, including time indexes
are ignored.
Parameters</p>
<hr>
<dl>
<dt><strong><code>subset</code></strong> :&ensp;<code>column label</code> or <code>sequence</code> of <code>labels</code>, optional</dt>
<dd>Only consider certain columns for identifying duplicates, by
default use all of the columns.</dd>
<dt><strong><code>keep</code></strong> :&ensp;<code>{'first', 'last', False}</code>, default <code>'first'</code></dt>
<dd>Determines which duplicates (if any) to keep.
- <code>first</code> : Drop duplicates except for the first occurrence.
- <code>last</code> : Drop duplicates except for the last occurrence.
- False (Unsupported): Drop all duplicates.</dd>
<dt><strong><code>inplace</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Whether to drop duplicates in place or to return a copy.</dd>
</dl>
<p>ignore_index (Unsupported) : bool, default False
If True, the resulting axis will be labeled 0, 1, …, n - 1.
!!! versionadded "Added in version:&ensp;1.0.0"</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code> or <code>None</code></dt>
<dd>DataFrame with duplicates removed or None if <code>inplace=True</code>(Unsupported).</dd>
</dl>
<h2 id="see-also">See Also</h2>
<dl>
<dt><code>DataFrame.value_counts</code></dt>
<dd>Count unique combinations of columns.
Examples</dd>
</dl>
<hr>
<p>Consider dataset containing ramen rating.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df = DataFrame({
...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],
...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],
...     'rating': [4, 4, 3.5, 15, 5]
... })
&gt;&gt;&gt; df
    brand style  rating
0  Yum Yum   cup     4.0
1  Yum Yum   cup     4.0
2  Indomie   cup     3.5
3  Indomie  pack    15.0
4  Indomie  pack     5.0
By default, it removes duplicate rows based on all columns.
&gt;&gt;&gt; df.drop_duplicates()
    brand style  rating
0  Yum Yum   cup     4.0
2  Indomie   cup     3.5
3  Indomie  pack    15.0
4  Indomie  pack     5.0
To remove duplicates on specific column(s), use &lt;code&gt;subset&lt;/code&gt;.
&gt;&gt;&gt; df.drop_duplicates(subset=['brand'])
    brand style  rating
0  Yum Yum   cup     4.0
2  Indomie   cup     3.5
To remove duplicates and keep last occurrences, use &lt;code&gt;keep&lt;/code&gt;.
&gt;&gt;&gt; df.drop_duplicates(subset=['brand', 'style'], keep='last')
    brand style  rating
1  Yum Yum   cup     4.0
2  Indomie   cup     3.5
4  Indomie  pack     5.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drop_duplicates(
    self,
    subset: Optional[Union[Hashable, Sequence[Hashable]]] = None,
    keep: Union[str, bool] = &#34;first&#34;,
    inplace: bool = False,
    ignore_index: bool = False,
    env: CylonEnv = None
) -&gt; DataFrame:
    &#34;&#34;&#34;
    Return DataFrame with duplicate rows removed.
    Considering certain columns is optional. Indexes, including time indexes
    are ignored.
    Parameters
    ----------
    subset : column label or sequence of labels, optional
        Only consider certain columns for identifying duplicates, by
        default use all of the columns.
    keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
        Determines which duplicates (if any) to keep.
        - ``first`` : Drop duplicates except for the first occurrence.
        - ``last`` : Drop duplicates except for the last occurrence.
        - False (Unsupported): Drop all duplicates.
    inplace : bool, default False
        Whether to drop duplicates in place or to return a copy.
    ignore_index (Unsupported) : bool, default False
        If True, the resulting axis will be labeled 0, 1, …, n - 1.
        .. versionadded:: 1.0.0
    Returns
    -------
    DataFrame or None
        DataFrame with duplicates removed or None if ``inplace=True``(Unsupported).
    See Also
    --------
    DataFrame.value_counts: Count unique combinations of columns.
    Examples
    --------
    Consider dataset containing ramen rating.
    &gt;&gt;&gt; df = DataFrame({
    ...     &#39;brand&#39;: [&#39;Yum Yum&#39;, &#39;Yum Yum&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;],
    ...     &#39;style&#39;: [&#39;cup&#39;, &#39;cup&#39;, &#39;cup&#39;, &#39;pack&#39;, &#39;pack&#39;],
    ...     &#39;rating&#39;: [4, 4, 3.5, 15, 5]
    ... })
    &gt;&gt;&gt; df
        brand style  rating
    0  Yum Yum   cup     4.0
    1  Yum Yum   cup     4.0
    2  Indomie   cup     3.5
    3  Indomie  pack    15.0
    4  Indomie  pack     5.0
    By default, it removes duplicate rows based on all columns.
    &gt;&gt;&gt; df.drop_duplicates()
        brand style  rating
    0  Yum Yum   cup     4.0
    2  Indomie   cup     3.5
    3  Indomie  pack    15.0
    4  Indomie  pack     5.0
    To remove duplicates on specific column(s), use ``subset``.
    &gt;&gt;&gt; df.drop_duplicates(subset=[&#39;brand&#39;])
        brand style  rating
    0  Yum Yum   cup     4.0
    2  Indomie   cup     3.5
    To remove duplicates and keep last occurrences, use ``keep``.
    &gt;&gt;&gt; df.drop_duplicates(subset=[&#39;brand&#39;, &#39;style&#39;], keep=&#39;last&#39;)
        brand style  rating
    1  Yum Yum   cup     4.0
    2  Indomie   cup     3.5
    4  Indomie  pack     5.0
    &#34;&#34;&#34;
    if env is None:
        return DataFrame(self._table.unique(columns=subset, keep=keep, inplace=inplace))
    else:
        return DataFrame(self._change_context(env)._table.distributed_unique(columns=subset, inplace=inplace))</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.fillna"><code class="name flex">
<span>def <span class="ident">fillna</span></span>(<span>self, fill_value) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Fill not applicable values with a given value</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fill_value</code></strong></dt>
<dd>scalar</dd>
</dl>
<p>Returns: PyCylon DataFrame</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df
       col-1  col-2  col-3
    0    1.0    5.0    9.0
    1    NaN    6.0   10.0
    2    3.0    NaN   11.0
    3    4.0    8.0    NaN
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.fillna(0)
       col-1  col-2  col-3
    0      1      5      9
    1      0      6     10
    2      3      0     11
    3      4      8      0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fillna(self, fill_value) -&gt; DataFrame:
    &#39;&#39;&#39;
    Fill not applicable values with a given value
    Args:
        fill_value: scalar

    Returns: PyCylon DataFrame

    Examples
    --------
    &gt;&gt;&gt; df
           col-1  col-2  col-3
        0    1.0    5.0    9.0
        1    NaN    6.0   10.0
        2    3.0    NaN   11.0
        3    4.0    8.0    NaN

    &gt;&gt;&gt; df.fillna(0)
           col-1  col-2  col-3
        0      1      5      9
        1      0      6     10
        2      3      0     11
        3      4      8      0
    &#39;&#39;&#39;
    # Note: Supports numeric types only
    return DataFrame(self._table.fillna(fill_value))</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.groupby"><code class="name flex">
<span>def <span class="ident">groupby</span></span>(<span>self, by: Union([int, str, List]), env: <a title="frame.CylonEnv" href="#frame.CylonEnv">CylonEnv</a> = None) ‑> <a title="frame.GroupByDataFrame" href="#frame.GroupByDataFrame">GroupByDataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>A groupby operation involves some combination of splitting the object, applying a function, and combining the results.
This can be used to group large amounts of data and compute operations on these groups.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>by</code></strong> :&ensp;<code>str, int</code> or <code>a list</code> of <code>str, int.
</code></dt>
<dd>List of column(s) used for grouping.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="frame.GroupByDataFrame" href="#frame.GroupByDataFrame">GroupByDataFrame</a></code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1 = DataFrame([[0, 0, 1, 1], [1, 10, 1, 5], [10, 20, 30, 40]])
&gt;&gt;&gt; df1
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df3 = df1.groupby(by=0).agg({&quot;1&quot;: &quot;sum&quot;, &quot;2&quot;: &quot;min&quot;})
&gt;&gt;&gt; df3
0  sum_1  min_2
0  0     11     10
1  1      6     30
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df4 = df1.groupby(by=0).min()
&gt;&gt;&gt; df4
0  min_2  min_1
0  0     10      1
1  1     30      1
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df5 = df1.groupby(by=[0, 1]).max()
&gt;&gt;&gt; df5
0   1  max_2
0  0   1     10
1  0  10     20
2  1   1     30
3  1   5     40
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def groupby(self, by: Union([int, str, List]), env: CylonEnv = None) -&gt; GroupByDataFrame:
    &#34;&#34;&#34;
    A groupby operation involves some combination of splitting the object, applying a function, and combining the results. 
    This can be used to group large amounts of data and compute operations on these groups.

    Parameters
    ----------

    by : str, int or a list of str, int.  
        List of column(s) used for grouping.
    
    Returns
    -------
    GroupByDataFrame

    Examples
    -------

    &gt;&gt;&gt; df1 = DataFrame([[0, 0, 1, 1], [1, 10, 1, 5], [10, 20, 30, 40]])
    &gt;&gt;&gt; df1


    &gt;&gt;&gt; df3 = df1.groupby(by=0).agg({&#34;1&#34;: &#34;sum&#34;, &#34;2&#34;: &#34;min&#34;})
    &gt;&gt;&gt; df3
    0  sum_1  min_2
    0  0     11     10
    1  1      6     30

    &gt;&gt;&gt; df4 = df1.groupby(by=0).min()
    &gt;&gt;&gt; df4
    0  min_2  min_1
    0  0     10      1
    1  1     30      1

    &gt;&gt;&gt; df5 = df1.groupby(by=[0, 1]).max()
    &gt;&gt;&gt; df5
    0   1  max_2
    0  0   1     10
    1  0  10     20
    2  1   1     30
    3  1   5     40
    &#34;&#34;&#34;
    by_list = []
    if isinstance(by, int):
        by_list.append(self.columns[by])
    elif isinstance(by, str):
        if by not in self.columns:
            raise ValueError(
                str+&#34; is not a column of this table. Expected one of &#34;+str(by))
        by_list.append(by)
    elif isinstance(by, list):
        if len(by) == 0:
            raise ValueError(&#34;Group by columns should be specified.&#34;)

        for b in by:
            if isinstance(b, str):
                by_list.append(b)
            elif isinstance(b, int):
                by_list.append(self.columns[b])
            else:
                raise ValueError(
                    &#34;Unsupported column specification. Expected column index or name&#34;)
    else:
        raise ValueError(&#34;Unknown value for by&#34;)
    if env is None:
        return GroupByDataFrame(self, by_list)
    else:
        return GroupByDataFrame(self._change_context(env), by_list)</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.is_cpu"><code class="name flex">
<span>def <span class="ident">is_cpu</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_cpu(self):
    return self._device == DEVICE_CPU</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.is_device"><code class="name flex">
<span>def <span class="ident">is_device</span></span>(<span>self, device)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_device(self, device):
    return self._device == device</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.isna"><code class="name flex">
<span>def <span class="ident">isna</span></span>(<span>self) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Check for not applicable values and returns a bool DataFrame
Returns: PyCylon DataFrame</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df
       col-1  col-2  col-3
    0    1.0    5.0    9.0
    1    NaN    6.0   10.0
    2    3.0    NaN   11.0
    3    4.0    8.0    NaN
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.isna()
        col-1  col-2  col-3
    0  False  False  False
    1   True  False  False
    2  False   True  False
    3  False  False   True
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def isna(self) -&gt; DataFrame:
    &#39;&#39;&#39;
    Check for not applicable values and returns a bool DataFrame
    Returns: PyCylon DataFrame

    Examples
    --------
    &gt;&gt;&gt; df
           col-1  col-2  col-3
        0    1.0    5.0    9.0
        1    NaN    6.0   10.0
        2    3.0    NaN   11.0
        3    4.0    8.0    NaN

    &gt;&gt;&gt; df.isna()
            col-1  col-2  col-3
        0  False  False  False
        1   True  False  False
        2  False   True  False
        3  False  False   True
    &#39;&#39;&#39;
    return DataFrame(self._table.isnull())</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.isnull"><code class="name flex">
<span>def <span class="ident">isnull</span></span>(<span>self) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Checks for null elements and returns a bool DataFrame
Returns: PyCylon DataFrame</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df
       col-1  col-2  col-3
    0    1.0    5.0    9.0
    1    NaN    6.0   10.0
    2    3.0    NaN   11.0
    3    4.0    8.0    NaN
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.isnull()
        col-1  col-2  col-3
    0  False  False  False
    1   True  False  False
    2  False   True  False
    3  False  False   True
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def isnull(self) -&gt; DataFrame:
    &#39;&#39;&#39;
    Checks for null elements and returns a bool DataFrame
    Returns: PyCylon DataFrame

    Examples
    --------

    &gt;&gt;&gt; df
           col-1  col-2  col-3
        0    1.0    5.0    9.0
        1    NaN    6.0   10.0
        2    3.0    NaN   11.0
        3    4.0    8.0    NaN

    &gt;&gt;&gt; df.isnull()
            col-1  col-2  col-3
        0  False  False  False
        1   True  False  False
        2  False   True  False
        3  False  False   True

    &#39;&#39;&#39;
    return DataFrame(self._table.isnull())</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.join"><code class="name flex">
<span>def <span class="ident">join</span></span>(<span>self, other: <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a>, on=None, how='left', lsuffix='l', rsuffix='r', sort=False, algorithm='sort', env: <a title="frame.CylonEnv" href="#frame.CylonEnv">CylonEnv</a> = None) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Join columns with other DataFrame either on index or on a key
column. Efficiently Join multiple DataFrame objects by index at once by
passing a list.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>other</code></strong> :&ensp;<code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a>, Series with name field set,</code> or <code>list</code> of <code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code></dt>
<dd>Index should be similar to one of the columns in this one. If a
Series is passed, its name attribute must be set, and that will be
used as the column name in the resulting joined DataFrame</dd>
<dt><strong><code>on</code></strong> :&ensp;<code>column name, tuple/list</code> of <code>column names,</code> or <code>array-like</code></dt>
<dd>Column(s) in the caller to join on the index in other,
otherwise joins index-on-index. If multiples
columns given, the passed DataFrame must have a MultiIndex. Can
pass an array as the join key if not already contained in the
calling DataFrame. Like an Excel VLOOKUP operation</dd>
<dt><strong><code>how</code></strong> :&ensp;<code>{'left', 'right', 'outer', 'inner'}</code>, default<code>: 'left'</code></dt>
<dd>How to handle the operation of the two objects.
* left: use calling frame's index (or column if on is specified)
* right: use other frame's index
* outer: form union of calling frame's index (or column if on is
specified) with other frame's index, and sort it
lexicographically
* inner: form intersection of calling frame's index (or column if
on is specified) with other frame's index, preserving the order
of the calling's one</dd>
<dt><strong><code>lsuffix</code></strong> :&ensp;<code>string</code></dt>
<dd>Suffix to use from left frame's overlapping columns</dd>
<dt><strong><code>rsuffix</code></strong> :&ensp;<code>string</code></dt>
<dd>Suffix to use from right frame's overlapping columns</dd>
<dt><strong><code>sort</code></strong> :&ensp;<code>boolean</code>, default <code>False</code></dt>
<dd>Order result DataFrame lexicographically by the join key. If False,
the order of the join key depends on the join type (how keyword)</dd>
<dt><strong><code>algorithm</code></strong> :&ensp;<code>{'sort', 'hash'}</code>, default<code>: 'sort'</code></dt>
<dd>The algorithm that should be used to perform the join between two tables.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>on, lsuffix, and rsuffix options are not supported when passing a list
of DataFrame objects
Examples</p>
<hr>
<pre><code class="language-python-repl">&gt;&gt;&gt; caller
    A key
0  A0  K0
1  A1  K1
2  A2  K2
3  A3  K3
4  A4  K4
5  A5  K5
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; other
    B key
0  B0  K0
1  B1  K1
2  B2  K2
Join DataFrames using their indexes.
&gt;&gt;&gt; caller.join(other, lsuffix='_caller', rsuffix='_other')
&gt;&gt;&gt;     A key_caller    B key_other
    0  A0         K0   B0        K0
    1  A1         K1   B1        K1
    2  A2         K2   B2        K2
    3  A3         K3  NaN       NaN
    4  A4         K4  NaN       NaN
    5  A5         K5  NaN       NaN
If we want to join using the key columns, we need to set key to be
the index in both caller and other. The joined DataFrame will have
key as its index.
&gt;&gt;&gt; caller.set_index('key').join(other.set_index('key'))
&gt;&gt;&gt;      A    B
    key
    K0   A0   B0
    K1   A1   B1
    K2   A2   B2
    K3   A3  NaN
    K4   A4  NaN
    K5   A5  NaN
Another option to join using the key columns is to use the on
parameter. DataFrame.join always uses other's index but we can use any
column in the caller. This method preserves the original caller's
index in the result.
&gt;&gt;&gt; caller.join(other.set_index('key'), on='key')
&gt;&gt;&gt;     A key    B
    0  A0  K0   B0
    1  A1  K1   B1
    2  A2  K2   B2
    3  A3  K3  NaN
    4  A4  K4  NaN
    5  A5  K5  NaN
See Also
-----
&lt;code&gt;&lt;a title=&quot;frame.DataFrame.merge&quot; href=&quot;#frame.DataFrame.merge&quot;&gt;DataFrame.merge()&lt;/a&gt;&lt;/code&gt;
:   For column(s)-on-columns(s) operations
Returns
-----
**```joined```** :&amp;ensp;&lt;code&gt;&lt;a title=&quot;frame.DataFrame&quot; href=&quot;#frame.DataFrame&quot;&gt;DataFrame&lt;/a&gt;&lt;/code&gt;
:   &amp;nbsp;


</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def join(self, other: DataFrame, on=None, how=&#39;left&#39;, lsuffix=&#39;l&#39;, rsuffix=&#39;r&#39;,
         sort=False, algorithm=&#34;sort&#34;, env: CylonEnv = None) -&gt; DataFrame:
    &#34;&#34;&#34;
    Join columns with other DataFrame either on index or on a key
    column. Efficiently Join multiple DataFrame objects by index at once by
    passing a list.

    Parameters
    ----------
    other : DataFrame, Series with name field set, or list of DataFrame
        Index should be similar to one of the columns in this one. If a
        Series is passed, its name attribute must be set, and that will be
        used as the column name in the resulting joined DataFrame
    on : column name, tuple/list of column names, or array-like
        Column(s) in the caller to join on the index in other,
        otherwise joins index-on-index. If multiples
        columns given, the passed DataFrame must have a MultiIndex. Can
        pass an array as the join key if not already contained in the
        calling DataFrame. Like an Excel VLOOKUP operation
    how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;}, default: &#39;left&#39;
        How to handle the operation of the two objects.
        * left: use calling frame&#39;s index (or column if on is specified)
        * right: use other frame&#39;s index
        * outer: form union of calling frame&#39;s index (or column if on is
          specified) with other frame&#39;s index, and sort it
          lexicographically
        * inner: form intersection of calling frame&#39;s index (or column if
          on is specified) with other frame&#39;s index, preserving the order
          of the calling&#39;s one
    lsuffix : string
        Suffix to use from left frame&#39;s overlapping columns
    rsuffix : string
        Suffix to use from right frame&#39;s overlapping columns
    sort : boolean, default False
        Order result DataFrame lexicographically by the join key. If False,
        the order of the join key depends on the join type (how keyword)
    algorithm: {&#39;sort&#39;, &#39;hash&#39;}, default: &#39;sort&#39;
        The algorithm that should be used to perform the join between two tables.
    Notes
    -----
    on, lsuffix, and rsuffix options are not supported when passing a list
    of DataFrame objects
    Examples
    --------
    &gt;&gt;&gt; caller
        A key
    0  A0  K0
    1  A1  K1
    2  A2  K2
    3  A3  K3
    4  A4  K4
    5  A5  K5

    &gt;&gt;&gt; other
        B key
    0  B0  K0
    1  B1  K1
    2  B2  K2
    Join DataFrames using their indexes.
    &gt;&gt;&gt; caller.join(other, lsuffix=&#39;_caller&#39;, rsuffix=&#39;_other&#39;)
    &gt;&gt;&gt;     A key_caller    B key_other
        0  A0         K0   B0        K0
        1  A1         K1   B1        K1
        2  A2         K2   B2        K2
        3  A3         K3  NaN       NaN
        4  A4         K4  NaN       NaN
        5  A5         K5  NaN       NaN
    If we want to join using the key columns, we need to set key to be
    the index in both caller and other. The joined DataFrame will have
    key as its index.
    &gt;&gt;&gt; caller.set_index(&#39;key&#39;).join(other.set_index(&#39;key&#39;))
    &gt;&gt;&gt;      A    B
        key
        K0   A0   B0
        K1   A1   B1
        K2   A2   B2
        K3   A3  NaN
        K4   A4  NaN
        K5   A5  NaN
    Another option to join using the key columns is to use the on
    parameter. DataFrame.join always uses other&#39;s index but we can use any
    column in the caller. This method preserves the original caller&#39;s
    index in the result.
    &gt;&gt;&gt; caller.join(other.set_index(&#39;key&#39;), on=&#39;key&#39;)
    &gt;&gt;&gt;     A key    B
        0  A0  K0   B0
        1  A1  K1   B1
        2  A2  K2   B2
        3  A3  K3  NaN
        4  A4  K4  NaN
        5  A5  K5  NaN
    See also
    --------
    DataFrame.merge : For column(s)-on-columns(s) operations
    Returns
    -------
    joined : DataFrame
    &#34;&#34;&#34;
    left_on = on
    if left_on is None:
        left_on = self._index_columns

    right_on = other._index_columns

    if left_on is None or len(left_on) == 0:
        raise ValueError(
            &#34;The column to join from left relation is no specified. Either provide &#39;on&#39; or set indexing&#34;)

    if right_on is None or len(right_on) == 0:
        raise ValueError(
            &#34;The &#39;other&#39; relation doesn&#39;t have index columns specified.&#34;)

    if env is None:
        joined_table = self._table.join(table=other._table, join_type=how,
                                        algorithm=algorithm,
                                        left_on=left_on, right_on=right_on,
                                        left_prefix=lsuffix, right_prefix=rsuffix)
        return DataFrame(joined_table)
    else:
        # attach context
        self._change_context(env=env)
        other._change_context(env=env)

        joined_table = self._table.distributed_join(table=other._table, join_type=how,
                                                    algorithm=algorithm,
                                                    left_on=left_on, right_on=right_on,
                                                    left_prefix=lsuffix, right_prefix=rsuffix)
        return DataFrame(joined_table)</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.merge"><code class="name flex">
<span>def <span class="ident">merge</span></span>(<span>self, right: <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a>, how='inner', algorithm='sort', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None, env: <a title="frame.CylonEnv" href="#frame.CylonEnv">CylonEnv</a> = None) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Merge DataFrame with a database-style join.
The join is done on columns or indexes. If joining columns on
columns, the DataFrame indexes <em>will be ignored</em>. Otherwise if joining indexes
on indexes or indexes on a column or columns, the index will be passed on.
When performing a cross merge, no column specifications to merge on are
allowed.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>right</code></strong> :&ensp;<code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code> or <code>named Series</code></dt>
<dd>Object to merge with.</dd>
<dt><strong><code>how</code></strong> :&ensp;<code>{'left', 'right', 'outer', 'inner', 'cross(Unsupported)'}</code>, default <code>'inner'</code></dt>
<dd>Type of merge to be performed.
* left: use only keys from left frame, similar to a SQL left outer join;
preserve key order.
* right: use only keys from right frame, similar to a SQL right outer join;
preserve key order.
* outer: use union of keys from both frames, similar to a SQL full outer
join; sort keys lexicographically.
* inner: use intersection of keys from both frames, similar to a SQL inner
join; preserve the order of the left keys.
* cross: creates the cartesian product from both frames, preserves the order
of the left keys.<div class="admonition versionadded">
<p class="admonition-title">Added in version:&ensp;1.2.0</p>
</div>
</dd>
<dt><strong><code>on</code></strong> :&ensp;<code>label</code> or <code>list</code></dt>
<dd>Column or index level names to join on. These must be found in both
DataFrames. If <code>on</code> is None and not merging on indexes then this defaults
to the intersection of the columns in both DataFrames.</dd>
<dt><strong><code>left_on</code></strong> :&ensp;<code>label</code> or <code>list,</code> or <code>array-like</code></dt>
<dd>Column or index level names to join on in the left DataFrame. Can also
be an array or list of arrays of the length of the left DataFrame.
These arrays are treated as if they are columns.</dd>
<dt><strong><code>right_on</code></strong> :&ensp;<code>label</code> or <code>list,</code> or <code>array-like</code></dt>
<dd>Column or index level names to join on in the right DataFrame. Can also
be an array or list of arrays of the length of the right DataFrame.
These arrays are treated as if they are columns.</dd>
<dt><strong><code>left_index</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Use the index from the left DataFrame as the join key(s). If it is a
MultiIndex, the number of keys in the other DataFrame (either the index
or a number of columns) must match the number of levels.</dd>
<dt><strong><code>right_index</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Use the index from the right DataFrame as the join key. Same caveats as
left_index.</dd>
<dt>sort(Unsupported) : bool, default False</dt>
<dt>Sort the join keys lexicographically in the result DataFrame. If False,</dt>
<dt>the order of the join keys depends on the join type (how keyword).</dt>
<dt><strong><code>suffixes</code></strong> :&ensp;<code>list-like</code>, default <code>is ("_x", "_y")</code></dt>
<dd>A length-2 sequence where each element is optionally a string
indicating the suffix to add to overlapping column names in
<code>left</code> and <code>right</code> respectively. Pass a value of <code>None</code> instead
of a string to indicate that the column name from <code>left</code> or
<code>right</code> should be left as-is, with no suffix. At least one of the
values must not be None.</dd>
</dl>
<p>copy(Unsupported) : bool, default True
If False, avoid copy if possible.
indicator(Unsupported) : bool or str, default False
If True, adds a column to the output DataFrame called "_merge" with
information on the source of each row. The column can be given a different
name by providing a string argument. The column will have a Categorical
type with the value of "left_only" for observations whose merge key only
appears in the left DataFrame, "right_only" for observations
whose merge key only appears in the right DataFrame, and "both"
if the observation's merge key is found in both DataFrames.
validate(Unsupported) : str, optional
If specified, checks if merge is of specified type.
* "one_to_one" or "1:1": check if merge keys are unique in both
left and right datasets.
* "one_to_many" or "1:m": check if merge keys are unique in left
dataset.
* "many_to_one" or "m:1": check if merge keys are unique in right
dataset.
* "many_to_many" or "m:m": allowed, but does not result in checks.
Returns</p>
<hr>
<dl>
<dt><code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code></dt>
<dd>A DataFrame of the two merged objects.</dd>
</dl>
<h2 id="see-also">See Also</h2>
<dl>
<dt><code>merge_ordered</code></dt>
<dd>Merge with optional filling/interpolation.</dd>
<dt><code>merge_asof</code></dt>
<dd>Merge on nearest keys.</dd>
<dt><code><a title="frame.DataFrame.join" href="#frame.DataFrame.join">DataFrame.join()</a></code></dt>
<dd>Similar method using indices.
Notes</dd>
</dl>
<hr>
<p>Support for specifying index levels as the <code>on</code>, <code>left_on</code>, and
<code>right_on</code> parameters was added in version 0.23.0
Support for merging named Series objects was added in version 0.24.0
Examples</p>
<hr>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1 = DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],
...                     'value': [1, 2, 3, 5]})
&gt;&gt;&gt; df2 = DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],
...                     'value': [5, 6, 7, 8]})
&gt;&gt;&gt; df1
    lkey value
0   foo      1
1   bar      2
2   baz      3
3   foo      5
&gt;&gt;&gt; df2
    rkey value
0   foo      5
1   bar      6
2   baz      7
3   foo      8
</code></pre>
<p>Merge df1 and df2 on the lkey and rkey columns. The value columns have
the default suffixes, _x and _y, appended.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1.merge(df2, left_on='lkey', right_on='rkey')
lkey  value_x rkey  value_y
0  foo        1  foo        5
1  foo        1  foo        8
2  foo        5  foo        5
3  foo        5  foo        8
4  bar        2  bar        6
5  baz        3  baz        7
</code></pre>
<p>Merge DataFrames df1 and df2 with specified left and right suffixes
appended to any overlapping columns.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1.merge(df2, left_on='lkey', right_on='rkey',
...           suffixes=('_left', '_right'))
lkey  value_left rkey  value_right
0  foo           1  foo            5
1  foo           1  foo            8
2  foo           5  foo            5
3  foo           5  foo            8
4  bar           2  bar            6
5  baz           3  baz            7
</code></pre>
<p>Merge DataFrames df1 and df2, but raise an exception if the DataFrames have
any overlapping columns.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))
Traceback (most recent call last):
...
ValueError: columns overlap but no suffix specified:
    Index(['value'], dtype='object')
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1 = DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})
&gt;&gt;&gt; df2 = DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})
&gt;&gt;&gt; df1
    a  b
0   foo  1
1   bar  2
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df2
    a  c
0   foo  3
1   baz  4
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1.merge(df2, how='inner', on='a')
    a  b  c
0   foo  1  3
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1.merge(df2, how='left', on='a')
    a  b  c
0   foo  1  3.0
1   bar  2  NaN
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1 = DataFrame({'left': ['foo', 'bar']})
&gt;&gt;&gt; df2 = DataFrame({'right': [7, 8]})
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1
    left
0   foo
1   bar
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df2
    right
0   7
1   8
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df1.merge(df2, how='cross')
left  right
0   foo      7
1   foo      8
2   bar      7
3   bar      8
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge(self,
          right: DataFrame,
          how=&#34;inner&#34;,
          algorithm=&#34;sort&#34;,
          on=None,
          left_on=None,
          right_on=None,
          left_index=False,
          right_index=False,
          sort=False,
          suffixes=(&#34;_x&#34;, &#34;_y&#34;),
          copy=True,
          indicator=False,
          validate=None,
          env: CylonEnv = None) -&gt; DataFrame:
    &#34;&#34;&#34;
    Merge DataFrame with a database-style join.
    The join is done on columns or indexes. If joining columns on
    columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes
    on indexes or indexes on a column or columns, the index will be passed on.
    When performing a cross merge, no column specifications to merge on are
    allowed.

    Parameters
    ----------
    right : DataFrame or named Series
        Object to merge with.
    how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;, &#39;cross(Unsupported)&#39;}, default &#39;inner&#39;
        Type of merge to be performed.
        * left: use only keys from left frame, similar to a SQL left outer join;
        preserve key order.
        * right: use only keys from right frame, similar to a SQL right outer join;
        preserve key order.
        * outer: use union of keys from both frames, similar to a SQL full outer
        join; sort keys lexicographically.
        * inner: use intersection of keys from both frames, similar to a SQL inner
        join; preserve the order of the left keys.
        * cross: creates the cartesian product from both frames, preserves the order
        of the left keys.
        .. versionadded:: 1.2.0
    on : label or list
        Column or index level names to join on. These must be found in both
        DataFrames. If `on` is None and not merging on indexes then this defaults
        to the intersection of the columns in both DataFrames.
    left_on : label or list, or array-like
        Column or index level names to join on in the left DataFrame. Can also
        be an array or list of arrays of the length of the left DataFrame.
        These arrays are treated as if they are columns.
    right_on : label or list, or array-like
        Column or index level names to join on in the right DataFrame. Can also
        be an array or list of arrays of the length of the right DataFrame.
        These arrays are treated as if they are columns.
    left_index : bool, default False
        Use the index from the left DataFrame as the join key(s). If it is a
        MultiIndex, the number of keys in the other DataFrame (either the index
        or a number of columns) must match the number of levels.
    right_index : bool, default False
        Use the index from the right DataFrame as the join key. Same caveats as
        left_index.
    sort(Unsupported) : bool, default False
        Sort the join keys lexicographically in the result DataFrame. If False,
        the order of the join keys depends on the join type (how keyword).
    suffixes : list-like, default is (&#34;_x&#34;, &#34;_y&#34;)
        A length-2 sequence where each element is optionally a string
        indicating the suffix to add to overlapping column names in
        `left` and `right` respectively. Pass a value of `None` instead
        of a string to indicate that the column name from `left` or
        `right` should be left as-is, with no suffix. At least one of the
        values must not be None.
    copy(Unsupported) : bool, default True
        If False, avoid copy if possible.
    indicator(Unsupported) : bool or str, default False
        If True, adds a column to the output DataFrame called &#34;_merge&#34; with
        information on the source of each row. The column can be given a different
        name by providing a string argument. The column will have a Categorical
        type with the value of &#34;left_only&#34; for observations whose merge key only
        appears in the left DataFrame, &#34;right_only&#34; for observations
        whose merge key only appears in the right DataFrame, and &#34;both&#34;
        if the observation&#39;s merge key is found in both DataFrames.
    validate(Unsupported) : str, optional
        If specified, checks if merge is of specified type.
        * &#34;one_to_one&#34; or &#34;1:1&#34;: check if merge keys are unique in both
        left and right datasets.
        * &#34;one_to_many&#34; or &#34;1:m&#34;: check if merge keys are unique in left
        dataset.
        * &#34;many_to_one&#34; or &#34;m:1&#34;: check if merge keys are unique in right
        dataset.
        * &#34;many_to_many&#34; or &#34;m:m&#34;: allowed, but does not result in checks.
    Returns
    -------
    DataFrame
        A DataFrame of the two merged objects.
    See Also
    --------
    merge_ordered : Merge with optional filling/interpolation.
    merge_asof : Merge on nearest keys.
    DataFrame.join : Similar method using indices.
    Notes
    -----
    Support for specifying index levels as the `on`, `left_on`, and
    `right_on` parameters was added in version 0.23.0
    Support for merging named Series objects was added in version 0.24.0
    Examples
    --------
    &gt;&gt;&gt; df1 = DataFrame({&#39;lkey&#39;: [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;],
    ...                     &#39;value&#39;: [1, 2, 3, 5]})
    &gt;&gt;&gt; df2 = DataFrame({&#39;rkey&#39;: [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;],
    ...                     &#39;value&#39;: [5, 6, 7, 8]})
    &gt;&gt;&gt; df1
        lkey value
    0   foo      1
    1   bar      2
    2   baz      3
    3   foo      5
    &gt;&gt;&gt; df2
        rkey value
    0   foo      5
    1   bar      6
    2   baz      7
    3   foo      8

    Merge df1 and df2 on the lkey and rkey columns. The value columns have
    the default suffixes, _x and _y, appended.

    &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;)
    lkey  value_x rkey  value_y
    0  foo        1  foo        5
    1  foo        1  foo        8
    2  foo        5  foo        5
    3  foo        5  foo        8
    4  bar        2  bar        6
    5  baz        3  baz        7

    Merge DataFrames df1 and df2 with specified left and right suffixes
    appended to any overlapping columns.

    &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;,
    ...           suffixes=(&#39;_left&#39;, &#39;_right&#39;))
    lkey  value_left rkey  value_right
    0  foo           1  foo            5
    1  foo           1  foo            8
    2  foo           5  foo            5
    3  foo           5  foo            8
    4  bar           2  bar            6
    5  baz           3  baz            7

    Merge DataFrames df1 and df2, but raise an exception if the DataFrames have
    any overlapping columns.

    &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;, suffixes=(False, False))
    Traceback (most recent call last):
    ...
    ValueError: columns overlap but no suffix specified:
        Index([&#39;value&#39;], dtype=&#39;object&#39;)

    &gt;&gt;&gt; df1 = DataFrame({&#39;a&#39;: [&#39;foo&#39;, &#39;bar&#39;], &#39;b&#39;: [1, 2]})
    &gt;&gt;&gt; df2 = DataFrame({&#39;a&#39;: [&#39;foo&#39;, &#39;baz&#39;], &#39;c&#39;: [3, 4]})
    &gt;&gt;&gt; df1
        a  b
    0   foo  1
    1   bar  2

    &gt;&gt;&gt; df2
        a  c
    0   foo  3
    1   baz  4

    &gt;&gt;&gt; df1.merge(df2, how=&#39;inner&#39;, on=&#39;a&#39;)
        a  b  c
    0   foo  1  3

    &gt;&gt;&gt; df1.merge(df2, how=&#39;left&#39;, on=&#39;a&#39;)
        a  b  c
    0   foo  1  3.0
    1   bar  2  NaN

    &gt;&gt;&gt; df1 = DataFrame({&#39;left&#39;: [&#39;foo&#39;, &#39;bar&#39;]})
    &gt;&gt;&gt; df2 = DataFrame({&#39;right&#39;: [7, 8]})

    &gt;&gt;&gt; df1
        left
    0   foo
    1   bar

    &gt;&gt;&gt; df2
        right
    0   7
    1   8

    &gt;&gt;&gt; df1.merge(df2, how=&#39;cross&#39;)
    left  right
    0   foo      7
    1   foo      8
    2   bar      7
    3   bar      8
    &#34;&#34;&#34;
    if not on is None:
        left_on = on
        right_on = on

    if left_index:
        left_on = self._index_columns

    if right_index:
        right_on = right._index_columns

    if left_on is None or right_on is None:
        raise ValueError(&#34;Columns to merge is not specified. Expected on or left_index/right_index.&#34;
                         &#34;Make sure dataframes has specified index columns if using left_index/right_index&#34;)

    if env is None:
        joined_table = self._table.join(table=right._table, join_type=how,
                                        algorithm=algorithm,
                                        left_on=left_on, right_on=right_on,
                                        left_prefix=suffixes[0], right_prefix=suffixes[1])
        return DataFrame(joined_table)
    else:
        self._change_context(env)
        right._change_context(env)
        joined_table = self._table.distributed_join(table=right._table, join_type=how,
                                                    algorithm=algorithm,
                                                    left_on=left_on, right_on=right_on,
                                                    left_prefix=suffixes[0], right_prefix=suffixes[1])
        return DataFrame(joined_table)</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.notna"><code class="name flex">
<span>def <span class="ident">notna</span></span>(<span>self) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Checks for not NA values and returns a bool DataFrame
Returns: PyCylon DataFrame</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df
       col-1  col-2  col-3
    0    1.0    5.0    9.0
    1    NaN    6.0   10.0
    2    3.0    NaN   11.0
    3    4.0    8.0    NaN
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.notna()
       col-1  col-2  col-3
    0   True   True   True
    1  False   True   True
    2   True  False   True
    3   True   True  False
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def notna(self) -&gt; DataFrame:
    &#39;&#39;&#39;
    Checks for not NA values and returns a bool DataFrame
    Returns: PyCylon DataFrame

    Examples
    --------
    &gt;&gt;&gt; df
           col-1  col-2  col-3
        0    1.0    5.0    9.0
        1    NaN    6.0   10.0
        2    3.0    NaN   11.0
        3    4.0    8.0    NaN

    &gt;&gt;&gt; df.notna()
           col-1  col-2  col-3
        0   True   True   True
        1  False   True   True
        2   True  False   True
        3   True   True  False
    &#39;&#39;&#39;

    return ~self.isnull()</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.notnull"><code class="name flex">
<span>def <span class="ident">notnull</span></span>(<span>self) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Check the not null values and returns a bool DataFrame
Returns: PyCylon DataFrame</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df
       col-1  col-2  col-3
    0    1.0    5.0    9.0
    1    NaN    6.0   10.0
    2    3.0    NaN   11.0
    3    4.0    8.0    NaN
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.notnull()
       col-1  col-2  col-3
    0   True   True   True
    1  False   True   True
    2   True  False   True
    3   True   True  False
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def notnull(self) -&gt; DataFrame:
    &#39;&#39;&#39;
    Check the not null values and returns a bool DataFrame
    Returns: PyCylon DataFrame

    Examples
    --------
    &gt;&gt;&gt; df
           col-1  col-2  col-3
        0    1.0    5.0    9.0
        1    NaN    6.0   10.0
        2    3.0    NaN   11.0
        3    4.0    8.0    NaN

    &gt;&gt;&gt; df.notnull()
           col-1  col-2  col-3
        0   True   True   True
        1  False   True   True
        2   True  False   True
        3   True   True  False
    &#39;&#39;&#39;

    return ~self.isnull()</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.rename"><code class="name flex">
<span>def <span class="ident">rename</span></span>(<span>self, column_names)</span>
</code></dt>
<dd>
<div class="desc"><p>Rename a DataFrame with a column name or column names</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>column_names</code></strong></dt>
<dd>dictionary or full list of new column names</dd>
</dl>
<p>Returns: None</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df
        col-1  col-2  col-3
    0      1      5      9
    1      2      6     10
    2      3      7     11
    3      4      8     12
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.rename({'col-1': 'col_1'})
       col_1  col-2  col-3
    0      1      5      9
    1      2      6     10
    2      3      7     11
    3      4      8     12
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.rename(['c1', 'c2', 'c3'])
       c1  c2  c3
    0   1   5   9
    1   2   6  10
    2   3   7  11
    3   4   8  12
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rename(self, column_names):
    &#39;&#39;&#39;
    Rename a DataFrame with a column name or column names
    Args:
        column_names: dictionary or full list of new column names

    Returns: None

    Examples
    --------
    &gt;&gt;&gt; df
            col-1  col-2  col-3
        0      1      5      9
        1      2      6     10
        2      3      7     11
        3      4      8     12

    &gt;&gt;&gt; df.rename({&#39;col-1&#39;: &#39;col_1&#39;})
           col_1  col-2  col-3
        0      1      5      9
        1      2      6     10
        2      3      7     11
        3      4      8     12

    &gt;&gt;&gt; df.rename([&#39;c1&#39;, &#39;c2&#39;, &#39;c3&#39;])
           c1  c2  c3
        0   1   5   9
        1   2   6  10
        2   3   7  11
        3   4   8  12
    &#39;&#39;&#39;
    self._table.rename(column_names)</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.reset_index"><code class="name flex">
<span>def <span class="ident">reset_index</span></span>(<span>self, level: Optional[Union[Hashable, Sequence[Hashable]]] = Ellipsis, drop: bool = Ellipsis, inplace: False = Ellipsis, col_level: Hashable = Ellipsis, col_fill=Ellipsis) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_index(  # type: ignore[misc]
    self,
    level: Optional[Union[Hashable, Sequence[Hashable]]] = ...,
    drop: bool = ...,
    inplace: False = ...,
    col_level: Hashable = ...,
    col_fill=...,
) -&gt; DataFrame:
    # todo this is not a final implementation
    self._index_columns = []
    self._table.reset_index(drop=drop)
    return self</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.set_index"><code class="name flex">
<span>def <span class="ident">set_index</span></span>(<span>self, keys, drop=True, append=False, inplace=False, verify_integrity=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the DataFrame index using existing columns.
Set the DataFrame index (row labels) using one or more existing
columns or arrays (of the correct length). The index can replace the
existing index or expand on it.
Parameters</p>
<hr>
<dl>
<dt><strong><code>keys</code></strong> :&ensp;<code>label</code> or <code>array-like</code> or <code>list</code> of <code>labels/arrays</code></dt>
<dd>This parameter can be either a single column key, a single array of
the same length as the calling DataFrame, or a list containing an
arbitrary combination of column keys and arrays. Here, "array"
encompasses :class:<code>Series</code>, :class:<code>Index</code>, <code>np.ndarray</code>, and
instances of :class:<code>~collections.abc.Iterator</code>.</dd>
<dt><strong><code>drop</code></strong> :&ensp;<code>bool</code>, default <code>True</code></dt>
<dd>Delete columns to be used as the new index.</dd>
<dt><strong><code>append</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Whether to append columns to existing index.</dd>
<dt><strong><code>inplace</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>If True, modifies the DataFrame in place (do not create a new object).</dd>
<dt><strong><code>verify_integrity</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>Check the new index for duplicates. Otherwise defer the check until
necessary. Setting to False will improve the performance of this
method.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code> or <code>None</code></dt>
<dd>Changed row labels or None if <code>inplace=True</code>.</dd>
</dl>
<h2 id="see-also">See Also</h2>
<dl>
<dt><code><a title="frame.DataFrame.reset_index" href="#frame.DataFrame.reset_index">DataFrame.reset_index()</a></code></dt>
<dd>Opposite of set_index.</dd>
<dt><code>DataFrame.reindex</code></dt>
<dd>Change to new indices or expand indices.</dd>
<dt><code>DataFrame.reindex_like</code></dt>
<dd>Change to same indices as other DataFrame.
Examples</dd>
</dl>
<hr>
<pre><code class="language-python-repl">&gt;&gt;&gt; df = pd.DataFrame({'month': [1, 4, 7, 10],
...                    'year': [2012, 2014, 2013, 2014],
...                    'sale': [55, 40, 84, 31]})
&gt;&gt;&gt; df
   month  year  sale
0      1  2012    55
1      4  2014    40
2      7  2013    84
3     10  2014    31
Set the index to become the 'month' column:
&gt;&gt;&gt; df.set_index('month')
       year  sale
month
1      2012    55
4      2014    40
7      2013    84
10     2014    31
Create a MultiIndex using columns 'year' and 'month':
&gt;&gt;&gt; df.set_index(['year', 'month'])
            sale
year  month
2012  1     55
2014  4     40
2013  7     84
2014  10    31
Create a MultiIndex using an Index and a column:
&gt;&gt;&gt; df.set_index([pd.Index([1, 2, 3, 4]), 'year'])
         month  sale
   year
1  2012  1      55
2  2014  4      40
3  2013  7      84
4  2014  10     31
Create a MultiIndex using two Series:
&gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
&gt;&gt;&gt; df.set_index([s, s**2])
      month  year  sale
1 1       1  2012    55
2 4       4  2014    40
3 9       7  2013    84
4 16     10  2014    31
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_index(
    self, keys, drop=True, append=False, inplace=False, verify_integrity=False
):
    &#34;&#34;&#34;
    Set the DataFrame index using existing columns.
    Set the DataFrame index (row labels) using one or more existing
    columns or arrays (of the correct length). The index can replace the
    existing index or expand on it.
    Parameters
    ----------
    keys : label or array-like or list of labels/arrays
        This parameter can be either a single column key, a single array of
        the same length as the calling DataFrame, or a list containing an
        arbitrary combination of column keys and arrays. Here, &#34;array&#34;
        encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and
        instances of :class:`~collections.abc.Iterator`.
    drop : bool, default True
        Delete columns to be used as the new index.
    append : bool, default False
        Whether to append columns to existing index.
    inplace : bool, default False
        If True, modifies the DataFrame in place (do not create a new object).
    verify_integrity : bool, default False
        Check the new index for duplicates. Otherwise defer the check until
        necessary. Setting to False will improve the performance of this
        method.
    Returns
    -------
    DataFrame or None
        Changed row labels or None if ``inplace=True``.
    See Also
    --------
    DataFrame.reset_index : Opposite of set_index.
    DataFrame.reindex : Change to new indices or expand indices.
    DataFrame.reindex_like : Change to same indices as other DataFrame.
    Examples
    --------
    &gt;&gt;&gt; df = pd.DataFrame({&#39;month&#39;: [1, 4, 7, 10],
    ...                    &#39;year&#39;: [2012, 2014, 2013, 2014],
    ...                    &#39;sale&#39;: [55, 40, 84, 31]})
    &gt;&gt;&gt; df
       month  year  sale
    0      1  2012    55
    1      4  2014    40
    2      7  2013    84
    3     10  2014    31
    Set the index to become the &#39;month&#39; column:
    &gt;&gt;&gt; df.set_index(&#39;month&#39;)
           year  sale
    month
    1      2012    55
    4      2014    40
    7      2013    84
    10     2014    31
    Create a MultiIndex using columns &#39;year&#39; and &#39;month&#39;:
    &gt;&gt;&gt; df.set_index([&#39;year&#39;, &#39;month&#39;])
                sale
    year  month
    2012  1     55
    2014  4     40
    2013  7     84
    2014  10    31
    Create a MultiIndex using an Index and a column:
    &gt;&gt;&gt; df.set_index([pd.Index([1, 2, 3, 4]), &#39;year&#39;])
             month  sale
       year
    1  2012  1      55
    2  2014  4      40
    3  2013  7      84
    4  2014  10     31
    Create a MultiIndex using two Series:
    &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
    &gt;&gt;&gt; df.set_index([s, s**2])
          month  year  sale
    1 1       1  2012    55
    2 4       4  2014    40
    3 9       7  2013    84
    4 16     10  2014    31
    &#34;&#34;&#34;
    # todo this is not a final implementation
    index_keys = []
    index_keys.extend(keys)

    if append:
        for c in self._index_columns:
            if not c in index_keys:
                index_keys.append(c)

    if inplace:
        self._index_columns = index_keys
        self._table.set_index(index_keys, drop=drop)
        return None
    else:
        new_df = DataFrame(self._table)
        new_df._table.set_index(index_keys, drop=drop)
        new_df._index_columns = index_keys
        return new_df</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.sort_values"><code class="name flex">
<span>def <span class="ident">sort_values</span></span>(<span>self, by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None, env: <a title="frame.CylonEnv" href="#frame.CylonEnv">CylonEnv</a> = None) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Sort by the values along either axis.
Parameters</p>
<hr>
<dl>
<dt><strong><code>axis</code></strong> :&ensp;<code>%(axes_single_arg)s</code>, default <code>0</code></dt>
<dd>Axis to be sorted.</dd>
<dt><strong><code>ascending</code></strong> :&ensp;<code>bool</code> or <code>list</code> of <code>bool</code>, default <code>True</code></dt>
<dd>Sort ascending vs. descending. Specify list for multiple sort
orders.
If this is a list of bools, must match the length of
the by.</dd>
</dl>
<p>inplace(Unsupported) : bool, default False
If True, perform operation in-place.
kind(Unsupported) : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'
Choice of sorting algorithm. See also :func:<code>numpy.sort</code> for more
information. <code>mergesort</code> and <code>stable</code> are the only stable algorithms. For
DataFrames, this option is only applied when sorting on a single
column or label.
na_position(Unsupported) : {'first', 'last'}, default 'last'
Puts NaNs at the beginning if <code>first</code>; <code>last</code> puts NaNs at the
end.
ignore_index(Unsupported) : bool, default False
If True, the resulting axis will be labeled 0, 1, …, n - 1.
!!! versionadded "Added in version:&ensp;1.0.0"</p>
<p>key(Unsupported) : callable, optional
Apply the key function to the values
before sorting. This is similar to the <code>key</code> argument in the
builtin :meth:<code>sorted</code> function, with the notable difference that
this <code>key</code> function should be <em>vectorized</em>. It should expect a
<code>Series</code> and return a Series with the same shape as the input.
It will be applied to each column in <code>by</code> independently.
!!! versionadded "Added in version:&ensp;1.1.0"</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code> or <code>None</code></dt>
<dd>DataFrame with sorted values or None if <code>inplace=True</code>.</dd>
</dl>
<h2 id="see-also">See Also</h2>
<dl>
<dt><code>DataFrame.sort_index</code></dt>
<dd>Sort a DataFrame by the index.</dd>
<dt><code>Series.sort_values</code></dt>
<dd>Similar method for a Series.
Examples</dd>
</dl>
<hr>
<pre><code class="language-python-repl">&gt;&gt;&gt; df = DataFrame({
...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],
...     'col2': [2, 1, 9, 8, 7, 4],
...     'col3': [0, 1, 9, 4, 2, 3],
...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']
... })
&gt;&gt;&gt; df
  col1  col2  col3 col4
0    A     2     0    a
1    A     1     1    B
2    B     9     9    c
3  NaN     8     4    D
4    D     7     2    e
5    C     4     3    F
Sort by col1
&gt;&gt;&gt; df.sort_values(by=['col1'])
  col1  col2  col3 col4
0    A     2     0    a
1    A     1     1    B
2    B     9     9    c
5    C     4     3    F
4    D     7     2    e
3  NaN     8     4    D
Sort by multiple columns
&gt;&gt;&gt; df.sort_values(by=['col1', 'col2'])
  col1  col2  col3 col4
1    A     1     1    B
0    A     2     0    a
2    B     9     9    c
5    C     4     3    F
4    D     7     2    e
3  NaN     8     4    D
Sort Descending
&gt;&gt;&gt; df.sort_values(by='col1', ascending=False)
  col1  col2  col3 col4
4    D     7     2    e
5    C     4     3    F
2    B     9     9    c
0    A     2     0    a
1    A     1     1    B
3  NaN     8     4    D
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sort_values(
    self,
    by,
    axis=0,
    ascending=True,
    inplace=False,
    kind=&#34;quicksort&#34;,
    na_position=&#34;last&#34;,
    ignore_index=False,
    key=None,
    env: CylonEnv = None
) -&gt; DataFrame:
    &#34;&#34;&#34;
    Sort by the values along either axis.
    Parameters
    ----------

    axis : %(axes_single_arg)s, default 0
         Axis to be sorted.
    ascending : bool or list of bool, default True
         Sort ascending vs. descending. Specify list for multiple sort
         orders.  If this is a list of bools, must match the length of
         the by.
    inplace(Unsupported) : bool, default False
         If True, perform operation in-place.
    kind(Unsupported) : {&#39;quicksort&#39;, &#39;mergesort&#39;, &#39;heapsort&#39;, &#39;stable&#39;}, default &#39;quicksort&#39;
         Choice of sorting algorithm. See also :func:`numpy.sort` for more
         information. `mergesort` and `stable` are the only stable algorithms. For
         DataFrames, this option is only applied when sorting on a single
         column or label.
    na_position(Unsupported) : {&#39;first&#39;, &#39;last&#39;}, default &#39;last&#39;
         Puts NaNs at the beginning if `first`; `last` puts NaNs at the
         end.
    ignore_index(Unsupported) : bool, default False
         If True, the resulting axis will be labeled 0, 1, …, n - 1.
         .. versionadded:: 1.0.0
    key(Unsupported) : callable, optional
        Apply the key function to the values
        before sorting. This is similar to the `key` argument in the
        builtin :meth:`sorted` function, with the notable difference that
        this `key` function should be *vectorized*. It should expect a
        ``Series`` and return a Series with the same shape as the input.
        It will be applied to each column in `by` independently.
        .. versionadded:: 1.1.0
    Returns
    -------
    DataFrame or None
        DataFrame with sorted values or None if ``inplace=True``.
    See Also
    --------
    DataFrame.sort_index : Sort a DataFrame by the index.
    Series.sort_values : Similar method for a Series.
    Examples
    --------
    &gt;&gt;&gt; df = DataFrame({
    ...     &#39;col1&#39;: [&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, np.nan, &#39;D&#39;, &#39;C&#39;],
    ...     &#39;col2&#39;: [2, 1, 9, 8, 7, 4],
    ...     &#39;col3&#39;: [0, 1, 9, 4, 2, 3],
    ...     &#39;col4&#39;: [&#39;a&#39;, &#39;B&#39;, &#39;c&#39;, &#39;D&#39;, &#39;e&#39;, &#39;F&#39;]
    ... })
    &gt;&gt;&gt; df
      col1  col2  col3 col4
    0    A     2     0    a
    1    A     1     1    B
    2    B     9     9    c
    3  NaN     8     4    D
    4    D     7     2    e
    5    C     4     3    F
    Sort by col1
    &gt;&gt;&gt; df.sort_values(by=[&#39;col1&#39;])
      col1  col2  col3 col4
    0    A     2     0    a
    1    A     1     1    B
    2    B     9     9    c
    5    C     4     3    F
    4    D     7     2    e
    3  NaN     8     4    D
    Sort by multiple columns
    &gt;&gt;&gt; df.sort_values(by=[&#39;col1&#39;, &#39;col2&#39;])
      col1  col2  col3 col4
    1    A     1     1    B
    0    A     2     0    a
    2    B     9     9    c
    5    C     4     3    F
    4    D     7     2    e
    3  NaN     8     4    D
    Sort Descending
    &gt;&gt;&gt; df.sort_values(by=&#39;col1&#39;, ascending=False)
      col1  col2  col3 col4
    4    D     7     2    e
    5    C     4     3    F
    2    B     9     9    c
    0    A     2     0    a
    1    A     1     1    B
    3  NaN     8     4    D
    &#34;&#34;&#34;
    if env is None:
        return DataFrame(self._table.sort(order_by=by, ascending=ascending))
    else:
        return DataFrame(self._change_context(env)._table.distributed_sort(order_by=by, ascending=ascending))</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.to_arrow"><code class="name flex">
<span>def <span class="ident">to_arrow</span></span>(<span>self) ‑> pyarrow.lib.Table</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_arrow(self) -&gt; pa.Table:
    return self._table.to_arrow()</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.to_cpu"><code class="name flex">
<span>def <span class="ident">to_cpu</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Move the dataframe from it's current device to random access memory</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_cpu(self):
    &#34;&#34;&#34;
    Move the dataframe from it&#39;s current device to random access memory
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.to_csv"><code class="name flex">
<span>def <span class="ident">to_csv</span></span>(<span>self, path, csv_write_options: CSVWriteOptions)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_csv(self, path, csv_write_options: CSVWriteOptions):
    self._table.to_csv(path=path, csv_write_options=csv_write_options)</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.to_device"><code class="name flex">
<span>def <span class="ident">to_device</span></span>(<span>self, device=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Move the dataframe from it's current device to the specified device</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_device(self, device=None):
    &#34;&#34;&#34;
    Move the dataframe from it&#39;s current device to the specified device
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.to_dict"><code class="name flex">
<span>def <span class="ident">to_dict</span></span>(<span>self) ‑> Dict</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_dict(self) -&gt; Dict:
    return self._table.to_pydict()</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.to_numpy"><code class="name flex">
<span>def <span class="ident">to_numpy</span></span>(<span>self, order: str = 'F', zero_copy_only: bool = True, writable: bool = False) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_numpy(self, order: str = &#39;F&#39;, zero_copy_only: bool = True, writable: bool = False) -&gt; \
        np.ndarray:
    return self._table.to_numpy(order=order, zero_copy_only=zero_copy_only,
                                writable=writable)</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.to_pandas"><code class="name flex">
<span>def <span class="ident">to_pandas</span></span>(<span>self) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_pandas(self) -&gt; pd.DataFrame:
    return self._table.to_pandas()</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.to_table"><code class="name flex">
<span>def <span class="ident">to_table</span></span>(<span>self) ‑> pycylon.data.table.Table</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_table(self) -&gt; cn.Table:
    return self._table</code></pre>
</details>
</dd>
<dt id="frame.DataFrame.where"><code class="name flex">
<span>def <span class="ident">where</span></span>(<span>self, condition: <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a> = None, other=None) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Experimental version of Where operation.
Replace values where condition is False</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>condition</code></strong></dt>
<dd>bool DataFrame</dd>
<dt><strong><code>other</code></strong></dt>
<dd>Scalar</dd>
</dl>
<p>Returns: PyCylon DataFrame</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df
       col-1  col-2  col-3
    0      1      5      9
    1      2      6     10
    2      3      7     11
    3      4      8     12
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.where(df &gt; 2)
        col-1  col-2  col-3
    0    NaN      5      9
    1    NaN      6     10
    2    3.0      7     11
    3    4.0      8     12
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.where(df &gt; 2, 10)
       col-1  col-2  col-3
    0     10      5      9
    1     10      6     10
    2      3      7     11
    3      4      8     12
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def where(self, condition: DataFrame = None, other=None) -&gt; DataFrame:
    &#39;&#39;&#39;
    Experimental version of Where operation.
    Replace values where condition is False
    Args:
        condition: bool DataFrame
        other: Scalar

    Returns: PyCylon DataFrame

    Examples
    --------
    &gt;&gt;&gt; df
           col-1  col-2  col-3
        0      1      5      9
        1      2      6     10
        2      3      7     11
        3      4      8     12

    &gt;&gt;&gt; df.where(df &gt; 2)
            col-1  col-2  col-3
        0    NaN      5      9
        1    NaN      6     10
        2    3.0      7     11
        3    4.0      8     12

    &gt;&gt;&gt; df.where(df &gt; 2, 10)
           col-1  col-2  col-3
        0     10      5      9
        1     10      6     10
        2      3      7     11
        3      4      8     12
    &#39;&#39;&#39;
    if condition is None:
        raise ValueError(&#34;Condition must be provided&#34;)
    return DataFrame(self._table.where(condition, other))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="frame.GroupByDataFrame"><code class="flex name class">
<span>class <span class="ident">GroupByDataFrame</span></span>
<span>(</span><span>df: <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a>, by=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GroupByDataFrame(object):
    def __init__(self, df: DataFrame, by=None) -&gt; None:
        super().__init__()
        self.df = df
        self.by = by
        self.by_diff = set(df.columns) - set(by)

    def __do_groupby(self, op_dict) -&gt; DataFrame:
        return DataFrame(self.df.to_table().groupby(self.by, op_dict))

    def __apply_on_remaining_columns(self, op: str) -&gt; DataFrame:
        op_dict = {}
        for c in self.by_diff:
            op_dict[c] = op
        return self.__do_groupby(op_dict)

    def min(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply min operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;min&#34;)

    def max(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply max operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;max&#34;)

    def sum(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply sum operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;sum&#34;)

    def count(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply count operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;count&#34;)

    def mean(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply mean operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;mean&#34;)

    def std(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply standard deviation operator on each remaining column  which has not been used for grouping
        &#34;&#34;&#34;
        return self.__apply_on_remaining_columns(&#34;std&#34;)

    def agg(self, dic: dict) -&gt; DataFrame:
        &#34;&#34;&#34;
        Apply different aggregation operations on each remainign column
        which has not been used for grouping

        Args:
            dic : A dictionary specifying aggregation operation for each column
        &#34;&#34;&#34;
        return self.__do_groupby(dic)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="frame.GroupByDataFrame.agg"><code class="name flex">
<span>def <span class="ident">agg</span></span>(<span>self, dic: dict) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Apply different aggregation operations on each remainign column
which has not been used for grouping</p>
<h2 id="args">Args</h2>
<p>dic : A dictionary specifying aggregation operation for each column</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def agg(self, dic: dict) -&gt; DataFrame:
    &#34;&#34;&#34;
    Apply different aggregation operations on each remainign column
    which has not been used for grouping

    Args:
        dic : A dictionary specifying aggregation operation for each column
    &#34;&#34;&#34;
    return self.__do_groupby(dic)</code></pre>
</details>
</dd>
<dt id="frame.GroupByDataFrame.count"><code class="name flex">
<span>def <span class="ident">count</span></span>(<span>self) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Apply count operator on each remaining column
which has not been used for grouping</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Apply count operator on each remaining column  which has not been used for grouping
    &#34;&#34;&#34;
    return self.__apply_on_remaining_columns(&#34;count&#34;)</code></pre>
</details>
</dd>
<dt id="frame.GroupByDataFrame.max"><code class="name flex">
<span>def <span class="ident">max</span></span>(<span>self) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Apply max operator on each remaining column
which has not been used for grouping</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Apply max operator on each remaining column  which has not been used for grouping
    &#34;&#34;&#34;
    return self.__apply_on_remaining_columns(&#34;max&#34;)</code></pre>
</details>
</dd>
<dt id="frame.GroupByDataFrame.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Apply mean operator on each remaining column
which has not been used for grouping</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Apply mean operator on each remaining column  which has not been used for grouping
    &#34;&#34;&#34;
    return self.__apply_on_remaining_columns(&#34;mean&#34;)</code></pre>
</details>
</dd>
<dt id="frame.GroupByDataFrame.min"><code class="name flex">
<span>def <span class="ident">min</span></span>(<span>self) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Apply min operator on each remaining column
which has not been used for grouping</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def min(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Apply min operator on each remaining column  which has not been used for grouping
    &#34;&#34;&#34;
    return self.__apply_on_remaining_columns(&#34;min&#34;)</code></pre>
</details>
</dd>
<dt id="frame.GroupByDataFrame.std"><code class="name flex">
<span>def <span class="ident">std</span></span>(<span>self) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Apply standard deviation operator on each remaining column
which has not been used for grouping</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def std(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Apply standard deviation operator on each remaining column  which has not been used for grouping
    &#34;&#34;&#34;
    return self.__apply_on_remaining_columns(&#34;std&#34;)</code></pre>
</details>
</dd>
<dt id="frame.GroupByDataFrame.sum"><code class="name flex">
<span>def <span class="ident">sum</span></span>(<span>self) ‑> <a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Apply sum operator on each remaining column
which has not been used for grouping</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sum(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Apply sum operator on each remaining column  which has not been used for grouping
    &#34;&#34;&#34;
    return self.__apply_on_remaining_columns(&#34;sum&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="frame.read_csv" href="#frame.read_csv">read_csv</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="frame.CylonEnv" href="#frame.CylonEnv">CylonEnv</a></code></h4>
<ul class="two-column">
<li><code><a title="frame.CylonEnv.barrier" href="#frame.CylonEnv.barrier">barrier</a></code></li>
<li><code><a title="frame.CylonEnv.context" href="#frame.CylonEnv.context">context</a></code></li>
<li><code><a title="frame.CylonEnv.finalize" href="#frame.CylonEnv.finalize">finalize</a></code></li>
<li><code><a title="frame.CylonEnv.is_distributed" href="#frame.CylonEnv.is_distributed">is_distributed</a></code></li>
<li><code><a title="frame.CylonEnv.rank" href="#frame.CylonEnv.rank">rank</a></code></li>
<li><code><a title="frame.CylonEnv.world_size" href="#frame.CylonEnv.world_size">world_size</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="frame.DataFrame" href="#frame.DataFrame">DataFrame</a></code></h4>
<ul class="two-column">
<li><code><a title="frame.DataFrame.add_prefix" href="#frame.DataFrame.add_prefix">add_prefix</a></code></li>
<li><code><a title="frame.DataFrame.columns" href="#frame.DataFrame.columns">columns</a></code></li>
<li><code><a title="frame.DataFrame.concat" href="#frame.DataFrame.concat">concat</a></code></li>
<li><code><a title="frame.DataFrame.drop" href="#frame.DataFrame.drop">drop</a></code></li>
<li><code><a title="frame.DataFrame.drop_duplicates" href="#frame.DataFrame.drop_duplicates">drop_duplicates</a></code></li>
<li><code><a title="frame.DataFrame.fillna" href="#frame.DataFrame.fillna">fillna</a></code></li>
<li><code><a title="frame.DataFrame.groupby" href="#frame.DataFrame.groupby">groupby</a></code></li>
<li><code><a title="frame.DataFrame.is_cpu" href="#frame.DataFrame.is_cpu">is_cpu</a></code></li>
<li><code><a title="frame.DataFrame.is_device" href="#frame.DataFrame.is_device">is_device</a></code></li>
<li><code><a title="frame.DataFrame.isna" href="#frame.DataFrame.isna">isna</a></code></li>
<li><code><a title="frame.DataFrame.isnull" href="#frame.DataFrame.isnull">isnull</a></code></li>
<li><code><a title="frame.DataFrame.join" href="#frame.DataFrame.join">join</a></code></li>
<li><code><a title="frame.DataFrame.merge" href="#frame.DataFrame.merge">merge</a></code></li>
<li><code><a title="frame.DataFrame.notna" href="#frame.DataFrame.notna">notna</a></code></li>
<li><code><a title="frame.DataFrame.notnull" href="#frame.DataFrame.notnull">notnull</a></code></li>
<li><code><a title="frame.DataFrame.rename" href="#frame.DataFrame.rename">rename</a></code></li>
<li><code><a title="frame.DataFrame.reset_index" href="#frame.DataFrame.reset_index">reset_index</a></code></li>
<li><code><a title="frame.DataFrame.set_index" href="#frame.DataFrame.set_index">set_index</a></code></li>
<li><code><a title="frame.DataFrame.shape" href="#frame.DataFrame.shape">shape</a></code></li>
<li><code><a title="frame.DataFrame.sort_values" href="#frame.DataFrame.sort_values">sort_values</a></code></li>
<li><code><a title="frame.DataFrame.to_arrow" href="#frame.DataFrame.to_arrow">to_arrow</a></code></li>
<li><code><a title="frame.DataFrame.to_cpu" href="#frame.DataFrame.to_cpu">to_cpu</a></code></li>
<li><code><a title="frame.DataFrame.to_csv" href="#frame.DataFrame.to_csv">to_csv</a></code></li>
<li><code><a title="frame.DataFrame.to_device" href="#frame.DataFrame.to_device">to_device</a></code></li>
<li><code><a title="frame.DataFrame.to_dict" href="#frame.DataFrame.to_dict">to_dict</a></code></li>
<li><code><a title="frame.DataFrame.to_numpy" href="#frame.DataFrame.to_numpy">to_numpy</a></code></li>
<li><code><a title="frame.DataFrame.to_pandas" href="#frame.DataFrame.to_pandas">to_pandas</a></code></li>
<li><code><a title="frame.DataFrame.to_table" href="#frame.DataFrame.to_table">to_table</a></code></li>
<li><code><a title="frame.DataFrame.where" href="#frame.DataFrame.where">where</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="frame.GroupByDataFrame" href="#frame.GroupByDataFrame">GroupByDataFrame</a></code></h4>
<ul class="two-column">
<li><code><a title="frame.GroupByDataFrame.agg" href="#frame.GroupByDataFrame.agg">agg</a></code></li>
<li><code><a title="frame.GroupByDataFrame.count" href="#frame.GroupByDataFrame.count">count</a></code></li>
<li><code><a title="frame.GroupByDataFrame.max" href="#frame.GroupByDataFrame.max">max</a></code></li>
<li><code><a title="frame.GroupByDataFrame.mean" href="#frame.GroupByDataFrame.mean">mean</a></code></li>
<li><code><a title="frame.GroupByDataFrame.min" href="#frame.GroupByDataFrame.min">min</a></code></li>
<li><code><a title="frame.GroupByDataFrame.std" href="#frame.GroupByDataFrame.std">std</a></code></li>
<li><code><a title="frame.GroupByDataFrame.sum" href="#frame.GroupByDataFrame.sum">sum</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>